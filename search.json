[{"title":"Opencv-python","url":"/2023/03/14/Opencv-python/","content":"点击此处访问github仓库 \n图像读取和保存读取img = cv2.imread(&quot;参数一&quot;, 参数二)\n\n参数一为读取的图像地址，参数二为读取的方式1为默认，以彩色模式读取0为灰度加载-1为以alpha通道加载  \n\n保存cv2.imwrite(&quot;参数一&quot;, 参数二)\n\n参数一为保存的位置以文件名参数二为保存的图像\n\n输出以cv2输出cv2.imshow(&quot;1&quot;,img)cv2.waitKey(0)cv2.destroyAllWindows()\n以plt输出plt.imshow(img[:,:,::-1])plt.show()\n\n视频视频读取cap = cv2.VideoCapture(0)\n\nVideoCapture()中参数是0，表示打开笔记本的内置摄像头参数是视频文件路径则打开视频如cap = cv2.VideoCapture(“../test.avi”)\n\n视频属性修改cap.set(propId，value)\n\npropId: 从0到18的数字，每个数字表示视频的属性\n\n\n算数操作相加img = cv2.add(rain, view) 像素相同才可相加\n混合img = cv2.addWeighted(view, 0.7, rain, 0.3, 0)按照7：3进行混合，最后的参数为伽马值，作为图像的补充\n\n像素点的获取与修改获取img[100,100])获取（100，100）处像素点的值\n修改img[100,100] = (0,0,255)修改（100，100）处的像素值为（0，0，255）\n像素层的拆分与合并b,g,r = cv2.split(img)拆分bgrcv2.merge((b,g,r))合并bgr\n\n图像绘制cv2.line(img, (0,0), (511, 511), (255, 0, 0), 5)直线cv2.circle(img, (256, 256), 60, (50, 50,150), 3)圆形cv2.rectangle(img, (100, 100), (400, 400), (100, 100, 70), 4)矩形cv2.putText(img, &quot;loloo&quot;, (160, 480), cv2.FONT_HERSHEY_SIMPLEX, 3, (40,20,100), 3)文字\n\n图像操作图像缩放cv2.resize()\n图像平移M = np.float32([[1,0,100],[0,1,50]])#平移矩阵，(先列后行?)，即x方向移动100，y方向移动50cv2.warpAffine(img, M, (2*cols, 2*rows))#第三个元素为结果图像的尺寸，先列后行，表现为先增行再增列\n图像旋转M = cv2.getRotationMatrix2D((cols/2, rows/2),90,1)制造旋转矩阵cv2.warpAffine(img,M,(cols,rows))利用“类平移”使其与原图像进行矩阵乘法  \n仿射变换pts1 = np.float32([[50,50],[200,50],[50,200]])#原图像中选取三个点pts2 = np.float32([[100,100],[200,50],[100,250]])对应到仿射变换后的三个点M = cv2.getAffineTransform(pts1, pts2)构造出仿射的变换矩阵cv2.warpAffine(img,M,(cols,rows))\n透射变换pst1 = np.float32([[56,65],[368,95],[28,387],[389,390]])pst2 = np.float32([[100,145],[300,100],[80,290],[310,300]])T = cv2.getPerspectiveTransform(pst1,pst2)res = cv2.warpPerspective(img, T, (cols, rows))\n图像金字塔下采样cv2.pyrDown(img)\n上采样cv2.pyrUp(img)\n\n形态学操作腐蚀\n用于消除目标边界点，使目标缩小，消除小于结构元素的噪声点  \n\nkernel = np.ones((5,5), np.uint8, iterations = 1)创建5*5的卷积核用于操作  \n\n参数三iterations为模糊程度（腐蚀次数），其值越高，腐蚀程度越大\n\nimg1 = cv2.erode(img, kernel)腐蚀\n膨胀\n用于讲与物体接触到的所欲背景点合并到物体中，使目标增大，可填补目标中的孔洞  \n\nkernel = np.ones((5,5), np.uint8, iterations = 1)创建5*5的卷积核用于操作  \n\n参数三iterations为膨胀程度（膨胀次数），其值越高，膨胀程度越大\n\nimg2 = cv2.dilate(img, kernel)膨胀\n开运算\n先腐蚀后膨胀，用于分离物体，消除小区域消除噪点，去除小干扰块，而不影响原来的图像  \n\nkernel = np.ones((10, 10), np.uint8)cvopen = cv2.morphologyEx(img, cv2.MORPH_OPEN,kernel)\n闭运算\n先膨胀后腐蚀，用于消除闭合物体里的孔洞可以填补闭合区域  \n\nkernel = np.ones((10, 10), np.uint8)cvclose = cv2.morphologyEx(img, cv2.MORPH_CLOSE,kernel)\n礼帽运算\n原图像和开运算结果图的差用来分离一些比临近点亮一些的斑块当一副图像具有大幅的背景而微笑物品比较有规律时，用礼帽进行背景提取  \n\nkernel = np.ones((10, 10), np.uint8)cvopen = cv2.morphologyEx(img, cv2.MORPH_TOPHAT,kernel)\n黑帽运算\n闭运算结果图和原图像的差用来分离比临近点暗一些的斑块突出比原图轮廓周围更暗的区域于选择的核的大小有关  \n\nkernel = np.ones((10, 10), np.uint8)cvopen = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT,kernel) \n\n图像噪声椒盐噪声（脉冲噪声）\n随机出现的白点或黑点可能为讯号收到的强烈干扰而产生的  \n\n高斯噪声\n噪声密度函数服从高斯分布易于清除\n\n\n图像平滑均值滤波\n算法简单，计算速度块，但去噪的用时去除了部分细节，将图像变得模糊  \n\nimg2 = cv2.blur(img,(5,5)) \n高斯滤波img2 = cv2.GaussianBlur(img, (3,3), 1)  \n\n参数二为高斯卷积核的大小，应均为奇数且可以不同参数三为水平方向标准差可有参数四，为竖直方向标准差，默认值为0，可有参数五，为填充边界类型  \n\n中值滤波\n不依赖于邻域内于典型值差别很大的值，对椒盐噪声尤其有用  \n\nimg2 = cv2.medianBlur(img, 5)  \n\n参数二为核的大小\n\n\n直方图直方图绘制hist = cv2.calcHist([img], [0], None, [256], [0,256])plt.figure(figsize=(10,10))  \n\n参数二代表传入的图像类型对于灰度图[0]为默认值对于彩色图[0]为B [1]为G [2]为R参数三为掩模图像，设置为None为整幅图参数四为BIN数目参数五为像素值范围\n\n掩膜应用mask = np.zeros(img.shape[:2],np.uint8())创建掩膜 mask[100:250,100:400] = 1 设置感兴趣区域\nmask_img = cv2.bitwise_and(img,img,mask = mask)将掩膜与图像混合\n直方图均衡化\n将灰度直方图进行拉伸可提高图像对比度，在曝光过度或不足时可以更好的突出细节dst = cv2.equalizeHist(img)\n\n自适应直方图均衡化\n将整幅图像分成小块，分别进行直方图均衡化，若直方图中bin超过对比度上限，就将其中像素点均匀分散到其他bins中，然后再进行直方图均衡化最后使用双线性差值，对每一小块进行拼接，可去除小块间的边界\n\ncl = cv2.createCLAHE(2.0, (8,8)) 对比度阈值2.0，分成8*8clahe = cl.apply(img)将其应用到图像上\n\n边缘检测Sobel算子\n利用搜索的方法获取边界（一阶导数为最大值）效率高于canny边缘检测，但准确度不如canny其抗噪声能力强，用途较多\n\nx = cv2.Sobel(img, cv2.CV_16S, 1, 0)边缘检测y = cv2.Sobel(img, cv2.CV_16S, 0, 1)边缘检测\\\n\n参数二为图像的深度参数三、四分别为对x，y上的求导，1为对该方向求导，0为不导可有参数五表示Sobel算子大小（卷积核大小），必须为奇数1，3，5，7，默认为3\n\nabsx = cv2.convertScaleAbs(x)格式转化absy = cv2.convertScaleAbs(y)格式转化\nres = cv2.addWeighted(absx, 0.5, absy, 0.5, 0)图像混合\nLaplacian算子\n利用零穿越的方式获取边界（二阶导数为0）  \n\nres = cv2.Laplacian(img, cv2.CV_16S)边缘检测res = cv2.convertScaleAbs(res)图像混合\nCanny边缘检测res = cv2.Canny(img, 0, 100)  \n\n参数二、三分别为两个阈值，二为较小的阈值，三为较大的阈值流程：噪声去除：高斯滤波计算图像梯度：sobel算子，计算梯度大小及方向非极大值抑制：利用梯度方向判断当前像素是否为边界点滞后阈值：设置两个阈值，确定最终边界\n\n\n模板匹配res = cv2.matchTemplate(img, temp, cv2.TM_CCORR)\n\n参数三为匹配的算法 有：平方查匹配(cv2.TM_SQDIFF)相关匹配(cv2.TM_CCORR利用相关系数匹配(cv2.TM_CCOEFF)\n\nmin_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)top_left = max_loc左上角h,w = temp.shape[:2]bottom_right = (top_left[0] + w, top_left[1] + h)右下角\ncv2.rectangle(img, top_left, bottom_right, (0,255,0), 2)画矩形框\n\n霍夫变换霍夫线检测\n调用霍夫变换前硬先进行二值化或者进行Canny边缘检测\n\nedges = cv2.Canny(img, 50, 150)Canny边缘检测\nlines = cv2.HoughLines(edges, 0.8, np.pi/180, 150)\n\n参数二、三为ρ和θ的精确度参数四为阈值，在累加器中高于该值才被认定为直线\n\nfor line in lines:rho,theta = line[0]a = np.cos(theta)b = np.sin(theta)x0 = rho * ay0 = rho * bx1 = int (x0 + 1000*(-b))y1 = int (y0 + 1000*a)x2 = int (x0 - 1000*(-b))y2 = int (y0 - 1000*a)cv.line(img, (x1, y1), (x2, y2), (50, 250, 50))画出对应直线\n霍夫圆检测\n由于霍夫圆检测对噪声比较敏感，所以首先对图像进行中值滤波\n\nimg = cv.medianBlur(gay_img, 7)中值滤波\ncircles = cv.HoughCircles(image, method, dp, minDist, param1=100, param2=100, minRadius=0,maxRadius=0 )\n\nmethod：使用霍夫变换圆检测的算法，它的参数是CV_HOUGH_GRADIENTdp：霍夫空间的分辨率，dp&#x3D;1时表示霍夫空间与输入图像空间的大小一致，dp&#x3D;2时霍夫空间是输入图像空间的一半，以此类推minDist为圆心之间的最小距离，如果检测到的两个圆心之间距离小于该值，则认为它们是同一个圆心param1：边缘检测时使用Canny算子的高阈值，低阈值是高阈值的一半。param2：检测圆心和确定半径时所共有的阈值minRadius和maxRadius为所检测到的圆半径的最小值和最大值\\\n\n\n特征提取Harris角点检测dst=cv2.cornerHarris(src, blockSize, ksize, k)\n\nimg：数据类型为 ﬂoat32 的输入图像。blockSize：角点检测中要考虑的邻域大小。ksize：sobel求导使用的核大小k ：角点检测方程中的自由参数，取值参数为 [0.04，0.06]\n\n\n优缺点：\n\n\n优点：旋转不变性，椭圆转过一定角度但是其形状保持不变（特征值保持不变）对于图像灰度的仿射变化具有部分的不变性，由于仅仅使用了图像的一介导数，对于图像灰度平移变化不变；对于图像灰度尺度变化不变\n\n\n缺点：对尺度很敏感，不具备几何尺度不变性。提取的角点是像素级的\n\nShi-Tomas角点检测\nCorners: 搜索到的角点，在这里所有低于质量水平的角点被排除掉，然后把合格的角点按质量排序，然后将质量较好的角点附近（小于最小欧式距离）的角点删掉，最后找到maxCorners个角点返回。\n\n\n具有旋转不变性，但不具备几何尺度不变性\n\ncorners = cv2.goodFeaturesToTrack ( image, maxcorners, qualityLevel, minDistance )\n\nImage: 输入灰度图像maxCorners : 获取角点数的数目。qualityLevel：该参数指出最低可接受的角点质量水平，在0-1之间。minDistance：角点之间最小的欧式距离，避免得到相邻特征点。\n\n尺度不变特征转换-&gt;SIFT算法\n在不同的尺度空间上查找关键点(特征点)，并计算出关键点的方向。SIFT所查找到的关键点是一些十分突出，不会因光照，仿射变换和噪音等因素而变化的点，如角点、边缘点、暗区的亮点及亮区的暗点等。\n\n\n可具有尺度不变性和旋转不变性\n\nsift = cv.xfeatures2d.SIFT_create()kp,des = sift.detectAndCompute(gray,None)cv.drawKeypoints(image, keypoints, outputimage, color, flags)\n\nimage: 原始图像keypoints：关键点信息，将其绘制在图像上outputimage：输出图片，可以是原始图像color：颜色设置，通过修改（b,g,r）的值,更改画笔的颜色，b&#x3D;蓝色，g&#x3D;绿色，r&#x3D;红色。flags：绘图功能的标识设置cv2.DRAW_MATCHES_FLAGS_DEFAULT：创建输出图像矩阵，使用现存的输出图像绘制匹配对和特征点，对每一个关键点只绘制中间点cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG：不创建输出图像矩阵，而是在输出图像上绘制匹配对cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS：对每一个特征点绘制带大小和方向的关键点图形cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS：单点的特征点不被绘制\n\nSIFT算法的增强版-&gt;SIFT算法\n计算量小，运算速度快，提取的特征与SIFT几乎相同\n\n\n其他mask = cv2.inRange(image,low,high)\n\n设置阈值去除背景，高于或低于对应阈值图象值变为0\n\ncnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n\n用于搜索轮廓\n\n\n参数二表示轮廓的检索模式，有四种：    cv2.RETR_EXTERNAL表示只检测外轮廓    cv2.RETR_LIST检测的轮廓不建立等级关系    cv2.RETR_CCOMP建立两个等级的轮廓，上面的一层为外边界，里面的一层为内孔的边界信息。如果内孔内还有一个连通物体，这个物体的边界也在顶层。    cv2.RETR_TREE建立一个等级树结构的轮廓。\\\n\n\n参数三method为轮廓的近似办法    cv2.CHAIN_APPROX_NONE存储所有的轮廓点，相邻的两个点的像素位置差不超过1，即max（abs（x1-x2），abs（y2-y1））&#x3D;&#x3D;1    cv2.CHAIN_APPROX_SIMPLE压缩水平方向，垂直方向，对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需4个点来保存轮廓信息    cv2.CHAIN_APPROX_TC89_L1，CV_CHAIN_APPROX_TC89_KCOS使用teh-Chinl chain 近似算法\n\nfor c in range(len(contours)):area = cv2.contourArea(contours[c])\n\n使用格林公式计算轮廓内面积面积\n\nfor c in range(len(contours)):arclen = cv2.arcLength(contours[c], True)\n\n计算周长\n\nrect = cv2.minAreaRect(are_max)\n\ncv2.findContours()找轮廓函数返回轮廓数组后，绘制每个轮廓的最小外接矩形的方法\n\n\n返回的是一个叫Box2D 结构,如((81.0,288),(22.0,10.0),-0.0)\\其表示的意义是（中心点坐标，（宽度，高度）,旋转的角度）\n\nbox = cv2.boxPoints(rect)\n\n获取矩形的四个顶点坐标\n\ncv2.drawContours(image, [np.int0(box)], -1, (0, 255, 255), 2)\n\n轮廓绘制\n\n\n第一个参数是指明在哪幅图像上绘制轮廓；image为三通道才能显示轮廓\n\n\n第二个参数是轮廓本身，在Python中是一个list\n\n\n第三个参数指定绘制轮廓list中的哪条轮廓，如果是-1，则绘制其中的所有轮廓。后面的参数很简单。其中thickness表明轮廓线的宽度，如果是-1（cv2.FILLED），则为填充模式\n\nimgHSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n将图像从一种颜色空间转换为另一种颜色空间 \n\n","categories":["学习笔记"],"tags":["计算机视觉","Opencv"]},{"title":"Machine-Learning-Sklearn","url":"/2023/03/14/Machine-Learning-Sklearn/","content":"Python中库的调用import sklearn\n数据集的划分sklearn.model_selection.train_test_split(arrays, *options)\nx 数据集的特征值y 数据集的标签值test_size 测试集的大小，一般为floatrandom_state 随机数种子,不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。return 测试集特征训练集特征值值，训练标签，测试标签(默认随机取)一般使用为\nx_train, x_test, y_train, y_test = train_test_split(data, target, random_state = 22)\n其中 data为自变量集 target为因变量\n特征工程字典特征提取from sklearn.feature_extraction import DictVectorizertransfer = DictVectorizer(sparse=True) # 实例化转换器类data = transfer.fit_transform(data) # 类似独热编码\nsparse为True为使用传统独热编码为False为使用向量说明当前位置 用于节省空间 加快运行效率\ndata_dure = pd.get_dummies(data2, columns=[&#x27;...&#x27;]) # 独热编码 columns为剔除无关项\n文本特征提取英文from sklearn.feature_extraction import DictVectorizertransfer = CountVectorizer() # 实例化 sparse 默认为Truedata = transfer.fit_transform(data) # 调用\n例如\ntransfer = CountVectorizer()data = transfer.fit_transform(data) # 调用fit_transform\n对于\ndata = [&quot;life is short,i like like python&quot;, &quot;life is too long,i dislike python&quot;]\n输出结果为\n\n文本特征抽取的结果：[[0 1 1 2 0 1 1 0][1 1 1 0 1 1 0 1]]返回特征名字：[‘dislike’, ‘is’, ‘life’, ‘like’, ‘long’, ‘python’, &gt; ‘short’, ‘too’]\n\n即对应字母在句子中出现的次数\n中文 jieba分词处理对于\ndata = [&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。&quot;,&quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;,&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;]\n对其进行\ntext_list = []for sent in data:    text_list.append(cut_word(sent))\ntext = &quot; &quot;.join(list(jieba.cut(text))) # 使用jieba对中文字符串进行分词\ntransfer = CountVectorizer() # 实例化转换器data = transfer.fit_transform(text_list)\n类似地得到\n文本特征抽取的结果：[[2 0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 1 0][0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 0 1][1 1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0 0]]返回特征名字：[&#x27;一种&#x27;, &#x27;不会&#x27;, &#x27;不要&#x27;, &#x27;之前&#x27;, &#x27;了解&#x27;, &#x27;事物&#x27;, &#x27;今天&#x27;, &#x27;光是在&#x27;, &#x27;几百万年&#x27;, &#x27;发出&#x27;,&#x27;取决于&#x27;, &#x27;只用&#x27;, &#x27;后天&#x27;, &#x27;含义&#x27;, &#x27;大部分&#x27;, &#x27;如何&#x27;, &#x27;如果&#x27;, &#x27;宇宙&#x27;, &#x27;我们&#x27;, &#x27;所以&#x27;, &#x27;放弃&#x27;, &#x27;方式&#x27;, &#x27;明天&#x27;, &#x27;星系&#x27;, &#x27;晚上&#x27;, &#x27;某样&#x27;, &#x27;残酷&#x27;, &#x27;每个&#x27;, &#x27;看到&#x27;, &#x27;真正&#x27;, &#x27;秘密&#x27;, &#x27;绝对&#x27;, &#x27;美好&#x27;, &#x27;联系&#x27;, &#x27;过去&#x27;, &#x27;还是&#x27;, &#x27;这样&#x27;]\nTf-idf文本特征提取能够自动获取关键词TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。可提取出更具有分类意义的词对于\ndata = [&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。&quot;,&quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;,&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;]\n对其进行\n# 使用jieba处理文本import jiebatext_list = []for sent in data:    text_list.append&quot; &quot;.join(list(jieba.cut(sent))))\nfrom sklearn.feature_extraction.text import TfidfVectorizertransfer = TfidfVectorizer(stop_words=[&#x27;一种&#x27;, &#x27;不会&#x27;, &#x27;不要&#x27;]) # 实例化转换器 stop为去掉的词?data = transfer.fit_transform(text_list)\n其结果为\n文本特征抽取的结果：[[ 0. 0. 0. 0.43643578 0. 0. 0.0. 0. 0.21821789 0. 0.21821789 0. 0.0. 0. 0.21821789 0.21821789 0. 0.436435780. 0.21821789 0. 0.43643578 0.21821789 0. 0.0. 0.21821789 0.21821789 0. 0. 0.218217890. ][ 0.2410822 0. 0. 0. 0.2410822 0.24108220.2410822 0. 0. 0. 0. 0. 0.0. 0.2410822 0.55004769 0. 0. 0. 0.0.2410822 0. 0. 0. 0. 0.482164410. 0. 0. 0. 0. 0.24108220. 0.2410822 ][ 0. 0.644003 0.48300225 0. 0. 0. 0.0.16100075 0.16100075 0. 0.16100075 0. 0.161000750.16100075 0. 0.12244522 0. 0. 0.161000750. 0. 0. 0.16100075 0. 0. 0.0.3220015 0.16100075 0. 0. 0.16100075 0. 0.0. ]]返回特征名字：[&#x27;之前&#x27;, &#x27;了解&#x27;, &#x27;事物&#x27;, &#x27;今天&#x27;, &#x27;光是在&#x27;, &#x27;几百万年&#x27;, &#x27;发出&#x27;, &#x27;取决于&#x27;, &#x27;只用&#x27;, &#x27;后天&#x27;,&#x27;含义&#x27;, &#x27;大部分&#x27;, &#x27;如何&#x27;, &#x27;如果&#x27;, &#x27;宇宙&#x27;, &#x27;我们&#x27;, &#x27;所以&#x27;, &#x27;放弃&#x27;, &#x27;方式&#x27;, &#x27;明天&#x27;, &#x27;星系&#x27;, &#x27;晚上&#x27;, &#x27;某样&#x27;, &#x27;残酷&#x27;, &#x27;每个&#x27;, &#x27;看到&#x27;, &#x27;真正&#x27;, &#x27;秘密&#x27;, &#x27;绝对&#x27;, &#x27;美好&#x27;, &#x27;联系&#x27;, &#x27;过去&#x27;, &#x27;还是&#x27;, &#x27;这样&#x27;]\n特征预处理归一化通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程将数据压缩至一个既定范围内使得特征都能被学习到\nsklearn.preprocessing.MinMaxScaler()\nimport pandas as pdfrom sklearn.preprocessing import MinMaxScalerdata = pd.read_csv(&quot;dating.txt&quot;)transfer = MinMaxScaler(feature_range=(2, 3)) # 实例化转换器类data = transfer.fit_transform(data[[&#x27;milage&#x27;, &#x27;Liters&#x27;, &#x27;Consumtime&#x27;]])\n标准化剔除异常值的影响适合目前大数据场景\nsklearn.preprocessing.StandardScaler( )\ntransfer = StandardScaler()data = transfer.fit_transform(data[[&#x27;milage&#x27;,&#x27;Liters&#x27;,&#x27;Consumtime&#x27;]])\n特征降维降维是指在某些限定条件下，降低随机变量(特征)个数，得到一组“不相关”主变量的过程降低随机变量的个数\nsklearn.feature_selection\n特征选择Filter过滤式主要探究特征本身特点、特征与特征和目标值之间关联方差选择法：低方差特征过滤\nsklearn.feature_selection.VarianceThreshold(threshold = 0.0) # 删除所有低方差特征\n使用例如\ntransfer = VarianceThreshold(threshold=1)data = transfer.fit_transform(data.iloc[:, 1:10])\niloc为指定位置 先行再列\n相关系数皮尔逊相关系数(Pearson Correlation Coefficient)\nfrom scipy.stats import pearsonrpearsonr(data[i], data[j])[0])) # 得到相关系数\n例如\ndata = pd.read_csv(&quot;factor_returns.csv&quot;)factor = [&#x27;pe_ratio&#x27;, &#x27;pb_ratio&#x27;, &#x27;market_cap&#x27;,&#x27;return_on_asset_net_profit&#x27;, &#x27;du_return_on_equity&#x27;, &#x27;ev&#x27;,&#x27;earnings_per_share&#x27;, &#x27;revenue&#x27;, &#x27;total_expense&#x27;]for i in range(len(factor)):    for j in range(i, len(factor) - 1):        print(&quot;指标%s与指标%s之间的相关性大小为%f&quot; % (factor[i], factor[j + 1],         pearsonr(data[factor[i]], data[factor[j + 1]])[0]))\n此处可使用图像进行观察revenue与total_expense的关系\nimport matplotlib.pyplot as pltplt.figure(figsize=(20, 8), dpi=100)plt.scatter(data[&#x27;revenue&#x27;], data[&#x27;total_expense&#x27;])plt.show()\n可得到其相关系数高可以进行合成\n主成分分析(PCA) PCA降维定义：高维数据转化为低维数据的过程，在此过程中可能会舍弃原有数据、创造新的变量作用：是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息。应用：回归分析或者聚类分析当中\nsklearn.decomposition.PCA(n_components = None)\n对于n_components：小数：表示保留百分之多少的信息整数：减少到多少特征例如\nfrom sklearn.decomposition import PCAtransfer = PCA(n_components = 0.9) # 保留90%的信息data1 = transfer.fit_transform(data)transfer2 = PCA(n_components=3) # 减少到3个特征data2 = transfer2.fit_transform(data)\n合并表import pandas as pdresult = pd.merge(csv1, csv2, on = [test1, test2]) # 将csv1中的tset1和csv2的test2在一张表中 按索引进行合并\nsklearn转换器和预估器转换器特征工程的接口称之为转换器有以下三种fit_transformfittransform其差别如以下\nIn [1]: from sklearn.preprocessing import StandardScalerIn [2]: std1 = StandardScaler()In [3]: a = [[1,2,3], [4,5,6]]In [4]: std1.fit_transform(a)Out[4]:array([[-1., -1., -1.],[ 1., 1., 1.]])In [5]: std2 = StandardScaler()In [6]: std2.fit(a)Out[6]: StandardScaler(copy=True, with_mean=True, with_std=True)In [7]: std2.transform(a)Out[7]:array([[-1., -1., -1.],[ 1., 1., 1.]])\n可知fit_transform的作用相当于transform加上fitfit方法可看作训练\n估计器sklearn机器学习算法的实现调用.fit()进行计算 生成model\\\n模型评估方法:1)直接对比真实值与预测值\\\ny_predict = estimator.predict(x_test)if y_test == y_predict\n2)利用公式计算\\\naccurary = estimator.score(x_test, y_test)\n分类算法KNN算法核心思想:根据邻居确定类别可能出现的问题:k过小容易收到异常点影响k过大容易收到样本不均匀影响需要做无量纲化处理——标准化\nsklearn.neighbors.KNeighborsClassifier(n_neighbors = 5, algorithm = &#x27;auto&#x27;)\n· n_neighbors：int,可选（默认&#x3D; 5），k_neighbors查询默认使用的邻居数· algorithm：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，可选用于计算最近邻居的算法：‘ball_tree’将会使用 BallTree，‘kd_tree’将使用 KDTree。‘auto’将尝试根据传递给fit方法的值来决定最合适的算法。 (不同实现方式影响效率)\n使用案例——鸢尾花分类-&gt; knn_demo.ipynb\n模型选择和调优交叉验证将拿到的训练数据，分为训练和验证集。以下图为例：将数据分成5份，其中一份作为验证集。然后经过5次(组)的测试，每次都更换不同的验证集。即得到5组模型的结果，取平均值作为最终结果。又称5折交叉验证。交叉验证目的：为了让被评估的模型更加准确可信\n超参数搜索——网格搜索获取最佳参数(超参数)-(如KNN中的K值)\\\nsklearn.model_selection.GridSearchCV(estimator, param_grid = None,cv = None)\n对估计器的指定参数值进行详尽搜索estimator：估计器对象param_grid：估计器参数(dict){“n_neighbors”:[1,3,5]}cv：指定几折交叉验证 类似epochfit：输入训练数据score：准确率输出结果为\nbestscore:在交叉验证中验证的最好结果bestestimator：最好的参数模型cvresults:每次交叉验证后的验证集准确率结果和训练集准确率结果\n例如\nknn = KNeighborsClassifier()param = &#123;&quot;n_neighbors&quot;: [3, 5, 10]&#125;gc = GridSearchCV(knn, param_grid=param, cv=2)gc.fit(x_train, y_train)print(&quot;选择了某个模型测试集当中预测的准确率为：&quot;, gc.score(x_test, y_test))# 训练验证集的结果print(&quot;在交叉验证当中验证的最好结果：&quot;, gc.best_score_)print(&quot;gc选择了的模型K值是：&quot;, gc.best_estimator_)print(&quot;每次交叉验证的结果为：&quot;, gc.cv_results_)\n朴素贝叶斯算法sklearn.naive_bayes.MultinomialNB(alpha = 1.0)朴素贝叶斯分类各结论之间相互独立 使用贝叶斯公式alpha：拉普拉斯平滑系数优点：朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。对缺失数据不太敏感，算法也比较简单，常用于文本分类。分类准确度高，速度快缺点：朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。对缺失数据不太敏感，算法也比较简单，常用于文本分类。分类准确度高，速度快\n决策树决策树class sklearn.tree.DecisionTreeClassifier(criterion = &#x27;gini&#x27;, max_depth=None, random_state=None)\ncriterion:默认是’gini’系数，也可以选择信息增益的熵’entropy’max_depth:树的深度大小random_state:随机数种子其中会有些超参数如max_depth:树的深度大小等优点：简单的理解和解释，树木可视化。可解释能力强缺点：决策树学习者可以创建不能很好地推广数据的过于复杂的树，这被称为过拟合。\n决策树可视化sklearn.tree.export_graphviz() 例如\ntree.export_graphviz(estimator,out_file=&#x27;tree.dot&#x27;,feature_names=[&quot;,&quot;])\n此处可使用graphviz工具进行树可视化ubuntu下使用sudo apt-get install graphviz Mac:brew install graphviz使用dot -Tpng tree.dot -o tree.png将dot转换为png或jpg\n随机森林包含多个决策树的分类器训练集随机 特征随机\nclass sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion = &#x27;gini&#x27;, max_depth = None, bootstrap = True, random_state = None, min_samples_split = 2)\nn_estimators：integer，optional（default &#x3D; 10）森林里的树木数量120,200,300,500,800,1200criteria：string，可选（default &#x3D;“gini”）分割特征的测量方法max_depth：integer或None，可选（默认&#x3D;无）树的最大深度 5,8,15,25,30max_features&#x3D;”auto”,每个决策树的最大特征数量If “auto”, then max_features&#x3D;sqrt(n_features) .If “sqrt”, then max_features&#x3D;sqrt(n_features) (same as “auto”).If “log2”, then max_features&#x3D;log2(n_features) .If None, then max_features&#x3D;n_features .bootstrap：boolean，optional（default &#x3D; True）是否在构建树时使用放回抽样min_samples_split:节点划分最少样本数min_samples_leaf:叶子节点的最小样本数其中存在超参数：n_estimator, max_depth, min_samples_split, min_samples_leaf优点：在当前所有算法中，具有极好的准确率能够有效地运行在大数据集上，处理具有高维特征的输入样本，而且不需要降维能够评估各个特征在分类问题上的重要性\n回归和聚类算法线性回归线性回归概念线性模型：自变量为一次或参数为一次但仅参数为一次非线性关系线性关系一定为线性模型线性模型不一定为线性关系\n优化算法正规方程公式求解缺点：当特征过多过复杂时，求解速度太慢并且得不到结果\n梯度下降面对训练数据规模十分庞大的任务 ，能够找到较好的结果\nAPI# 正规方程sklearn.linear_model.LinearRegression(fit_intercept = True)\nfit_intercept：是否计算偏置LinearRegression.coef_：回归系数LinearRegression.intercept_：偏置\n# 梯度下降sklearn.linear_model.SGDRegressor(loss = &quot;squared_loss&quot;, fit_intercept = True, learning_rate = &#x27;invscaling&#x27;, eta0=0.01)\nloss:损失类型loss&#x3D;”squared_loss”: 普通最小二乘法fit_intercept：是否计算偏置learning_rate : string, optional 学习率算法\n\n学习率填充：‘constant’: eta &#x3D; eta0‘optimal’: eta &#x3D; 1.0 &#x2F; (alpha * (t + t0)) [default]‘invscaling’: eta &#x3D; eta0 &#x2F; pow(t, power_t) power_t&#x3D;0.25:存在父类当中对于一个常数值的学习率来说，可以使用learning_rate&#x3D;’constant’ ，并使用eta0来指定学习率。\n\nSGDRegressor.coef_：回归系数SGDRegressor.intercept_：偏置\n性能评估sklearn.metrics.mean_squared_error(y_true, y_pred)\n\n均方误差回归损失y_true:真实值y_pred:预测值return:浮点数结果\n\n例如\ndef mylinearregression():&quot;&quot;&quot;线性回归预测房子价格:return:&quot;&quot;&quot;lb = load_boston()# print(lb.data)# print(lb.target)# 对数据集进行划分x_train, x_test, y_train, y_test = train_test_split(lb.data, lb.target,test_size=0.3, random_state=24)# 需要做标准化处理对于特征值处理std_x = StandardScaler()x_train = std_x.fit_transform(x_train)x_test = std_x.fit_transform(x_test)# print(x_train)# 对于目标值进行标准化std_y = StandardScaler()y_train = std_y.fit_transform(y_train)y_test = std_y.transform(y_test)y_test = std_y.inverse_transform(y_test)# 使用线性模型进行预测# 使用正规方程求解lr = LinearRegression()# # 此时在干什么？lr.fit(x_train, y_train)y_lr_predict = std_y.inverse_transform(lr.predict(x_test))print(lr.coef_)print(&quot;正规方程预测的结果为：&quot;, y_lr_predict)print(&quot;正规方程的均方误差为：&quot;, mean_squared_error(y_test, y_lr_predict))# 梯度下降进行预测sgd = SGDRegressor()sgd.fit(x_train, y_train)print(&quot;SGD的权重参数为：&quot;, sgd.coef_)y_sgd_predict = std_y.inverse_transform(sgd.predict(x_test))print(&quot;SGD的预测的结果为：&quot;, y_sgd_predict)print(&quot;SGD的均方误差为：&quot;, mean_squared_error(y_test, y_sgd_predict))\n\n欠拟合和过拟合概念欠拟合一个假设在训练数据上能够获得比其他假设更好的拟合， 但是在测试数据集上却不能很好地拟合数据，此时认为这个假设出现了过拟合的现象。(模型过于复杂)\n过拟合一个假设在训练数据上不能获得更好的拟合，并且在测试数据集上也不能很好地拟合数据，此时认为这个假设出现了欠拟合的现象。(模型过于简单)\n解决正则化L2正则化 - 更常用\n\n作用：可以使得其中一些W的都很小，都接近于0，削弱某个特征的影响优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象Ridge回归 岭回归\n\nL1正则化\n\n作用：可以使得其中一些W的值直接为0，删除这个特征的影响LASSO回归\n\n岭回归带L2正则化的线性回归\nsklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True,solver=&quot;auto&quot;, normalize=False)\n\nalpha:正则化力度 也叫λ λ取值：01 110solver:会根据数据自动选择优化方法 sag:如果数据集、特征都比较大，选择该随机梯度下降优化normalize:数据是否进行标准化normalize&#x3D;False:可以在fit之前调用preprocessing.StandardScaler标准化数据Ridge.coef_:回归权重Ridge.intercept_:回归偏置\n\n逻辑回归(分类算法)逻辑回归概念逻辑回归是一种分类算法，虽然名字中带有回归，但是它与回归之间有一定的联系。由于算法的简单和高效，在实际中应用非常广泛。利于解决二分类问题线性回归的输出作为逻辑回归的输入\nsigmoid激活函数回归的结果输入到sigmoid函数当中输出结果：[0, 1]区间中的一个概率值，默认为0.5为阈值\n\n逻辑回归最终的分类是通过属于某个类别的概率值来判断是否属于某个类别，并且这个类别默认标记为1(正例),另外的一个类别会标记为0(反例)。（方便损失计算）\n\n\n输出结果解释(重要)：假设有两个类别A，B，并且假设我们的概率值为属于A(1)这个类别的概率值。现在有一个样本的输入到逻辑回归输出结果0.6，那么这个概率值超过0.5，意味着我们训练或者预测的结果就是A(1)类别。\n\n对数似然损失APIsklearn.linear_model.LogisticRegression(solver = &#x27;liblinear&#x27;, penalty=‘l2’, C = 1.0)\n\nsolver:优化求解方式（默认开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数） sag：根据数据集自动选择，随机平均梯度下降penalty：正则化的种类C：正则化力度\n\n代码举例def logisticregression():&quot;&quot;&quot;逻辑回归进行癌症预测:return: None&quot;&quot;&quot;# 1、读取数据，处理缺失值以及标准化column_name = [&#x27;Sample code number&#x27;, &#x27;Clump Thickness&#x27;, &#x27;Uniformity of CellSize&#x27;, &#x27;Uniformity of Cell Shape&#x27;,&#x27;Marginal Adhesion&#x27;, &#x27;Single Epithelial Cell Size&#x27;, &#x27;BareNuclei&#x27;, &#x27;Bland Chromatin&#x27;,&#x27;Normal Nucleoli&#x27;, &#x27;Mitoses&#x27;, &#x27;Class&#x27;]data = pd.read_csv(&quot;https://archive.ics.uci.edu/ml/machine-learning\u0002databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;, names=column_name)# 删除缺失值data = data.replace(to_replace=&#x27;?&#x27;, value=np.nan)data = data.dropna()# 取出特征值x = data[column_name[1:10]]y = data[column_name[10]]# 分割数据集x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)# 进行标准化std = StandardScaler()x_train = std.fit_transform(x_train)x_test = std.transform(x_test)# 使用逻辑回归lr = LogisticRegression()lr.fit(x_train, y_train)print(&quot;得出来的权重：&quot;, lr.coef_)# 预测类别print(&quot;预测的类别：&quot;, lr.predict(x_test))# 得出准确率print(&quot;预测的准确率:&quot;, lr.score(x_test, y_test))return None\n分类的评估方法精确率与召回率混淆矩阵精确率(Precision)与召回率(Recall)精确率：预测结果为正例样本中真实为正例的比例（了解）召回率(查全率)：真实为正例的样本中预测结果为正例的比例（查的全，对正样本的区分能力）\nF1-score 反应模型稳健型分类评估报告APIsklearn.metrics.classification_report(y_true, y_pred, labels = [], target_names = None)\n\ny_true：真实目标值y_pred：估计器预测目标值labels:指定类别对应的数字target_names：目标类别名称return：每个类别精确率与召回率\n\n例如\nprint(&quot;精确率和召回率为：&quot;, classification_report(y_test, lr.predict(x_test), labels=[2, 4], target_names = [&#x27;良性&#x27;, &#x27;恶性&#x27;]))\nROC曲线与AUC指标ROC曲线ROC曲线的横轴就是FPRate，纵轴就是TPRate，当二者相等时，表示的意义则是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的，此时AUC为0.5\nAUC指标AUC只能用来评价二分类AUC非常适合评价样本不平衡中的分类器性能\nAUC的概率意义是随机取一对正负样本，正样本得分大于负样本的概率AUC的最小值为0.5，最大值为1，取值越高越好AUC&#x3D;1，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。\n\n最终AUC的范围在[0.5, 1]之间，并且越接近1越好\n\nAUC计算APIfrom sklearn.metrics import roc_auc_scoresklearn.metrics.roc_auc_score(y_true, y_score)\n\n计算ROC曲线面积，即AUC值y_true:每个样本的真实类别，必须为0(反例),1(正例)标记y_score:每个样本预测的概率值\n\n例如\n# 0.5~1之间，越接近于1约好y_test = np.where(y_test &gt; 2.5, 1, 0)print(&quot;AUC指标：&quot;, roc_auc_score(y_test, lr.predict(x_test)))\n\n模型保存与加载from sklearn.externals import joblib# 保存joblib.dump(rf, &#x27;test.pkl&#x27;)# 加载estimator = joblib.load(&#x27;test.pkl&#x27;)\n例如\n# 使用线性模型进行预测# 使用正规方程求解lr = LinearRegression()# 此时在干什么？lr.fit(x_train, y_train)# 保存训练完结束的模型joblib.dump(lr, &quot;test.pkl&quot;)\n及\n# 通过已有的模型去预测房价model = joblib.load(&quot;test.pkl&quot;)print(&quot;从文件加载进来的模型预测房价的结果：&quot;,std_y.inverse_transform(model.predict(x_test)))\n\n无监督学习 k-means算法特点分析：采用迭代式算法，直观易懂并且非常实用缺点：容易收敛到局部最优解(多次聚类)\nk-means算法聚类步骤1、随机设置K个特征空间内的点作为初始的聚类中心2、对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别3、接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）4、如果计算得出的新中心点与原中心点一样，那么结束，否则重新进行第二步过程\nAPIsklearn.cluster.KMeans(n_clusters=8,init=‘k-means++’)\n\nk-means聚类n_clusters:开始的聚类中心数量init:初始化方法，默认为’k-means ++’labels_:默认标记的类型，可以和真实值比较（不是值比较）\n\nKmeans性能评估指标轮廓系数及轮廓系数值分析如果b_i&gt;&gt;a_i:趋近于1效果越好， b_i &lt;&lt; a_i:趋近于-1，效果不好。轮廓系数的值是介于 [-1,1] ，越趋近于1代表内聚度和分离度都相对较优。\n轮廓系数APIsklearn.metrics.silhouette_score(X, labels)\n计算所有样本的平均轮廓系数X：特征值labels：被聚类标记的目标值\n用户聚类结果评估silhouette_score(cust, pre)\n\n使用数据处理方法缩小数据范围使用query()方法进行数据挑选如\ndata = data.query(&quot;x &lt; 2.5 &amp; x &gt; 2 &amp; y &lt; 1 &amp; 1&quot;)\n处理时间特征使用pd.to_datatime()如\ntime_value = pd.to_datatime(data[&quot;time&quot;], unit = &quot;s&quot;)\nunit为单位 此处为秒\n为了方便得到时间 可使用pd.DatetimeIndex()例如\ndate = pd.DatetimeIndex(time_value)\n\n分组并统计使用groupby().count()例如\ncount = data.groupby(&quot;place_id&quot;).count()\n对place_id进行统计\n布尔索引place_count[place_count &gt; 3]\n","categories":["学习笔记"],"tags":["机器学习","人工智能","Sklearn"]},{"title":"Matlab","url":"/2023/03/14/Matlab/","content":"常用函数三角函数sin % 正弦函数cos % 余弦tan % 正切sinh % 双曲正弦cosh % 双曲余弦tanh % 双曲正切asin % 反正弦acos % 反余弦atan % 反正切asinh % 反双曲正弦acosh % 反双曲余弦atanh % 反双曲正切\n指数与对数函数exp % 指数log % e为底的对数log10 % lgsqrt % 平方根\n与复数有关的函数abs % 模angle % 幅角conj % 复共轭imag % 虚部real % 实部\n舍入函数与其他数值函数fix % 向0舍入floor % 向负无穷舍入ceil % 向正无穷舍入round % 四舍五入rem(a, b) % 计算a/b余数\n有关向量的函数min(x) % 向量x的元素最小值max(x) % 向量x的元素最大值mean(x) % 向量x的元素平均值median(x) % 向量x的元素中位数std(x) % 向量x的元素标准差diff(x) % 向量x的相邻元素差sort(x) % 对向量x进行排序length(x) % 向量x的元素个数norm(x) % 向量x的Euclidean长度sum(x) % 向量x的元素和prod(x) % 向量x的元素连乘积cunsum(x) % 向量x的累计元素总和dot(x) % 向量x的内积cross(x) % 向量x的外积cumprod(x) % 向量x的累计元素总乘积\n关于矩阵矩阵的表示如\nA = [1, 2, 2; 2, 4, 2; 5, 3, 1]\n矩阵转置使用&#39;来表示如\nB = A&#x27;\n矩阵加减+,-\n矩阵乘法*\n求行列式det(A)\n矩阵求逆inv(A)\n“除法”如AX = b可用X = A \\ b求解同时X = A \\ b可用于解矛盾方程组\n矩阵特征值eig(A)\n函数作图二维平面曲线作图plot(x, y, s) % x、y为长度相同的向量，s表示线型及颜色\n\n若作多曲线在同一图上，则用函数\nplot(x1, x2, s1, x2, y2, s2,.., xn, yn, sn)\n\n取某一区间为x = 0:0.1:2*pi 表示取[0, 2Π] 间隔为0.1\n多窗口作图将屏幕分为多个窗口分别作图\nsubplot(m, n, k) % 将窗口分为m*n个，当前图在第k个\n\n直方图作图count = hist(x) % 将向量x中的元素放入等距10条形中，且返回每个条形中的元素个数count = hist(x, center) % 参量x为向量，将x中元素放到m(m = length(center))个由center中元素指定的位置为中心的直方图中count = hist(x, number) % 参量number为标量，用于指定条形数目[count, center] = hist(x) % 返回向量x中包含频率计数的count与条形的位置向量center，可以用bar(center, count) % 对center, count画出条形直方图 条之间有间隔hist(x) % 直接对传入的x进行作图\nx = normrnd(10, 5, 1000, 1) 表示传入均值为10 标准差为5的正态分布曲线 产生一千行一列的数据\n二维图形注释grid功能：给图形坐标面增加分割线 但会对当前坐标轴的属性有影响\ngrid on % 给当前坐标轴增加分隔线grid off % 从当前坐标轴去掉分隔线grid % 转换分割线的显示与否状态grid(axes_handle, on|off) % 对指定坐标轴axes_handle更改显示分割线状态\n\n空间曲线作图三维曲线作图plot3(x, y, z, s) % x、y、z为长度相同的向量，s表示线型及颜色\n如 做空间螺旋线\nt = 0:0.01:8*pi;x = cos(t);y = sin(t);z = t;plot3(x, y, z, &#x27;r&#x27;);\n三维曲面作图mesh(x, y, z) % 生成由x, y, z指定的网线面surf(x, y, z) % 在矩形区域内显示三维带阴影曲面图\n如\n% 作z = cosx.*siny曲面图[x, y] = meshgrid(-3:0.1:3, -4:0.1:4);z = cos(x) .* sin(y);mesh(x, y, z); % 网线面xlabel(&#x27;x&#x27;);ylabel(&#x27;y&#x27;);zlabel(&#x27;z&#x27;);surf(x, y, z) % 带阴影曲面图xlabel(&#x27;x&#x27;);ylabel(&#x27;y&#x27;);zlabel(&#x27;z&#x27;);\n\n基本语句forfor x = a:d:b % a为起始点 b为终止点 d为区间间隔    (command) % 循环体end\n如\n% 求100以内奇数相加和for i 1:2:99    s = s + i;ends % 输出结果\nwhilewhile expression    (command)end\nif-else-endif expression    (command)elseif expression    (command)else    (command)end\n\n脚本文件与函数文件函数文件开头需为例如\nfunction z = fun(x)\n以方便脚本文件调用在命令窗口输入例如\nx = [1, 2]z = fun(x)\n即可调用\n状态转移模型","categories":["学习笔记"],"tags":["数学建模","Matlab"]},{"title":"Lingo","url":"/2023/03/14/Lingo/","content":"lingolingo编写格式集合部分(SETS)以SETS开始，以ENDSETS结束用于定义必要变量有两类集合\n**原始集合:**其定义格式为:\nSETENME/member list(or 1..n)/: attribute, attribute, etc.\n导出集合引用其他集合定义的集合 其定义格式为:\nSENTNAME(set1, set2, etc.): attribute, attribute, etc.\n\n若要在程序中使用数组，则必须在该部分定义如\nPerson/1..10/:A;Task/1..12/:B;Link(Person, Task):X;\n目标与约束定义目标函数、约束条件等\n数据部分(DATA)以DATA: 开始，以END DATA结束用于数据的输入格式为：\nattribute = value_list\n\n初始化部分(INIT)以INIT: 开始，以END INIT结束用于对集合属性（数组）定义初值格式为\nattribute=value_list\n\n内部函数以@开头\\\n数学函数常用数学函数如下\n@ABS(X) 返回绝对值@COS(X) 返回余弦值@EXP(X) 返回e指数值@FLOOR(X) 返回靠近0的整数部分@LGM(X) 返回Γ函数自然对数值@LOG(X) 返回x自然对数值@SIGN(X) 返回符号值 负数为-1 正数为1@SIN(X)  返回正弦 x为弧度制@SMAX(X1, X2···, Xn) 返回最大值@SMIN(X) (X1, X2···, Xn) 返回最小值@TAN(X) 返回正切值\n集合函数集合函数格式如下\nset_operator(set_name|condition:expression)\n其中set_operator为集合函数名set_name为数据集合名 condition为表达式|expression为条件，用逻辑表达式描述（无条件可省略）\n逻辑表达式中 有如下运算符\n#AND# 与#OR# 或#NOT# 非#EQ# 等于#NE# 不等于#GT# 大于#GE# 大于等于#LT# 小于#LE# 小于等于\n常见集合函数如下：\n@FOR(set_name: constraint) 对集合set_name的每个元素独立生成约束 由约束表达式constraint描述@MAX(set_name: exoression) 返回集合上最大值@MIN(set_name: exoression) 返回集合上最小值@SUN(set_name: exoression) 返回集合上的表达式exoression的和@SIZE(set_name) 返回元素个数@IN(set_name, set_element) 若set_name中包含set_element则返回1，反之返回0\n\n变量界定函数变量函数对变量的取值范围的附加限制 由如下四种\n@BND(L, X, U)限制L≤X≤U@BIN(X) 限制x为1或0@FREE(X) 取消对x的符号限制(可取任意实数)@GIN(X) 限制x为整数值","categories":["学习笔记"],"tags":["Lingo","数学建模"]},{"title":"Deep-Learning-Pytorch","url":"/2023/03/14/Deep-Learning-Pytorch/","content":"此为本人学习深度学习及Pytorch基础知识时所作，可能存在部分错误之处，敬请谅解。\nTensorBoard代码from torch.utils.tensorboard import SummaryWriterimport cv2writer = SummaryWriter(&quot;logs&quot;) # 创建实例，将事件文件储存到logs文件夹下img_path = &quot;./training_dataset/train/ants_image/0013035.jpg&quot;img = cv2.imread(img_path)img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)writer.add_image(&quot;test&quot;, img, 1, dataformats = &quot;HWC&quot;) # 图像工具for i in range(100):    writer.add_scalar(&quot;y = 3x&quot;, 3*i, i) # 画函数工具writer.close()\n其中，对writer.add_image(&quot;test&quot;, img, 1, dataformats = &quot;HWC&quot;) 1为步数，dataformats为格式\nTerminaltensorboard --logdir=logs# 其中logdir=事件文件所在文件夹名\n输出内容为TensorBoard 2.10.0 at http://localhost:6006/ (Press CTRL+C to quit)表示在端口6006训练\\\n可用tensorboard --logdir=logs --port=6007指定端口\nTransForms代码from torchvision import transformsimg_path = &quot;./training_dataset/train/ants_image/0013035.jpg&quot;img = Image.open(img_path)# Totensortrans_totensor = transforms.ToTensor() # 创建对应工具tensor_img = trans_totensor(img) # 转化为tensor数据类型writer.add_image(&quot;ToTensor&quot;, tensor_img)# Normalizetrans_norm = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])img_norm = trans_norm(tensor_img) # 归一化writer.add_image(&quot;Normalize&quot;, img_norm)# Resizetrans_resize = transforms.Resize((512, 512))img_resize = trans_resize(img)img_resize = trans_totensor(img_resize) # 改变大小writer.add_image(&quot;Resize&quot;, img_resize, 0)# Compose - resize - 2trans_resize_2 = transforms.Resize(512)trans_compose = transforms.Compose([trans_resize_2, trans_totensor])img_resize_2 = trans_compose(img) # 按比例改变大小writer.add_image(&quot;Resize2&quot;, img_resize_2, 0)# RandomCroptrans_random = transforms.RandomCrop(512) # 括号内用于指定大小，可分别指定长宽trans_conpose_2 = transforms.Compose([trans_random, trans_totensor])for i in range(10):    img_crop = trans_conpose_2(img)    writer.add_image(&quot;RandomCrop&quot;, img_crop, i) # 随机裁剪writer.close()\n\ntorchvision官方数据集下载train_data = torchvision.datasets.CIFAR10(root = &quot;./dataset_test&quot;, train = True, transform = dataset_transform, download = True)test_set = torchvision.datasets.CIFAR10(root = &quot;./dataset_test&quot;, train = False, transform = dataset_transform, download = True)\nroot为本地下载存放地址train为True为下载训练集 为False为下载测试集transform为图片转化的工具 如dataset_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])download为是否下载该数据集\n数据集内容 例img, target = test_set[0]\n对应输出为(&lt;PIL.Image.Image image mode=RGB size=32x32 at 0x106B06F4E50&gt;, 3)(此处前部分为不经过transform进行变换的默认PIL格式照片)前部分为图片，后部分为该图片对应的对象在classes(test_set.classes)中的下标若为\ntest_set.classes[target]\n则输出对应为cat\ndataloader数据加载器\ntest_loader = DataLoader(dataset = test_data, batch_size = 4, shuffle = True, num_workers = 0, drop_last = False)\ndataset为指定数据集(测试集)batch_size为指定每次从dataset中去除n个数据进行打包shuffle若为True则每次训练会打乱顺序 一般为Truenum_work为主进程数量drop_last为保存最后一次取的数据\n代码# 准备测试集test_data = torchvision.datasets.CIFAR10(root = &quot;./dataset_test&quot;, train = False, transform = torchvision.transforms.ToTensor())test_loader = DataLoader(dataset = test_data, batch_size = 4, shuffle = True, num_workers = 0, drop_last = False)# 测试集中第一张照片及targetimg, target = test_data[0]# 得到总的imgs与targetswriter = SummaryWriter(&quot;dataloader_logs&quot;)step = 0for data in test_loader:    imgs, targets = data    writer.add_images(&quot;test_data&quot;, imgs, step)    step += 1writer.close()\n\nconvolution functional卷积层 代码import torchimport torch.nn.functional as F # 卷积函数input = torch.tensor([[1, 2, 0, 3, 1],                      [0, 1, 2, 3, 1],                      [1, 2, 1, 0, 0],                      [5, 2, 3, 1, 1],                      [2, 1, 0, 1, 1]])    kernel = torch.tensor([[1, 2, 1],                       [0, 1, 0],                       [2, 1, 0]])input = torch.reshape(input,(1, 1, 5, 5)) # 更改尺寸为(1, 1, 5, 5)kernel = torch.reshape(kernel,(1, 1, 3, 3)) # 更改尺寸为(1, 1, 3, 3)output = F.conv2d(input, kernel, stride = 1, padding = 0)print(output)\n对于torch.reshape(input,(1, 1, 5, 5))shape为四通道第一位为channel通道数量第二位为输入channel&#x2F;group(batch_size)三四位分别为高和宽及有dilation 空洞卷积\nF.conv2d意为二维卷积stride为卷积核移动步数，padding为填充情况\nconv2d小历程import torchimport torchvisionfrom torch.utils.data import DataLoaderfrom torch import nnfrom torch.nn import Conv2dfrom torch.utils.tensorboard import SummaryWriterimport cv2dataset = torchvision.datasets.CIFAR10(&quot;./conv2d_dataset&quot;, train = False, transform = torchvision.transforms.ToTensor(),download = True)dataloader = DataLoader(dataset, batch_size = 64)class Fun(nn.Module):    def __init__(self):        super(Fun, self).__init__()        self.conv1 = Conv2d(in_channels = 3, out_channels = 6, kernel_size = 3, stride = 1, padding = 1)    def forward(self, x):        x = self.conv1(x)        return xtest = Fun()writer = SummaryWriter(&quot;con2d_logs&quot;)step = 0for data in dataloader:    imgs, targets = data    output = test(imgs)    writer.add_images(&quot;input&quot;, imgs, step)    output = torch.reshape(output, (-1, 3, 32, 32))    writer.add_images(&quot;output&quot;,output, step)    step += 1\n将数据集中的图片进行卷积操作，即卷积层\n池化层最大池化import torchfrom torch import nnimport torchvisionfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterdataset = torchvision.datasets.CIFAR10(&quot;maxpool_data&quot;, train = False, download = True, transform = torchvision.transforms.ToTensor())dataLoader = DataLoader(dataset, batch_size= 64)class Test(nn.Module):    def __init__(self):        super(Test, self).__init__()        self.maxpool1 = nn.MaxPool2d(kernel_size = 3, ceil_mode = True)    def forward(self,input):        output = self.maxpool1(input)        return outputtest = Test()step = 0writer = SummaryWriter(&quot;maxpool_logs&quot;)for data in dataLoader:    imgs, targets = data    writer.add_images(&quot;input&quot;, imgs, step)    output = test(imgs)    writer.add_images(&quot;output&quot;, output, step)    step += 1\n其中self.maxpool1 = nn.MaxPool2d()(kernel_size = 3, ceil_mode = True)中的ceil_mode 为补全，为True即当kernel加载到不满九个数据的位置时仍然计\n池化可以缩减目标空间 增加运行速度\n非线性激活import torchimport torchvisionfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterdataset = torchvision.datasets.CIFAR10(&quot;maxpool_data&quot;, train = False, download = True, transform = torchvision.transforms.ToTensor())dataloader = DataLoader(dataset, batch_size = 64)class test(torch.nn.Module):    def __init__(self):        super(test, self).__init__()        self.relu1 = torch.nn.ReLU()        self.sigmoid1 = torch.nn.Sigmoid()    def forward(self, input):        output = self.relu1(input)        return outputtest = test()writer = SummaryWriter(&quot;relu_logs&quot;)step = 0for  data in dataloader:    imgs, targets = data    writer.add_images(&quot;input&quot;, imgs, step)    output = test(imgs)    writer.add_images(&quot;output&quot;, output, step)    step += 1writer.close()\n\n线性层from modulefinder import Moduleimport torchvisionfrom torch.utils.data import DataLoaderimport torchdataset = torchvision.datasets.CIFAR10(&quot;maxpool_data&quot;, train = False, download = True, transform = torchvision.transforms.ToTensor())dataloader = DataLoader(dataset, batch_size = 64)class test(torch.nn.Module):    def __init__(self):        super(test, self).__init__()        self.linear1 = torch.nn.Linear(196608, 10)    def forward(self, input):        output = self.linear1(input)        return outputtest = test()for data in dataloader:    imgs, targets = data    print(imgs.shape)    # output = torch.reshape(imgs, (1, 1, 1, -1))    output = torch.flatten(imgs) # 将矩阵展开成一行    print(output.shape)    output = test(output)    print(output.shape)\n也作为全连接层？\nSequential及网络搭建小历程import torchfrom torch.utils.tensorboard import SummaryWriterclass test(torch.nn.Module):    def __init__(self):        super(test, self).__init__()        # self.conv1 = torch.nn.Conv2d(3, 32, 5, padding = 2)        # self.maxpool1 = torch.nn.MaxPool2d(2)        # self.conv2 = torch.nn.Conv2d(32, 32, 5, padding = 2)        # self.maxpool2 = torch.nn.MaxPool2d(2)        # self.conv3 = torch.nn.Conv2d(32, 64, 5, padding = 2)        # self.maxpool3 = torch.nn.MaxPool2d(2)        # self.flatten = torch.nn.Flatten()        # self.linear1 = torch.nn.Linear(1024, 64)        # self.linear2 = torch.nn.Linear(64, 10)        self.model1 = torch.nn.Sequential(                                torch.nn.Conv2d(3, 32, 5, padding = 2),                                torch.nn.MaxPool2d(2),                                torch.nn.Conv2d(32, 32, 5, padding = 2),                                torch.nn.MaxPool2d(2),                                torch.nn.Conv2d(32, 64, 5, padding = 2),                                torch.nn.MaxPool2d(2),                                torch.nn.Flatten(),                                torch.nn.Linear(1024, 64),                                torch.nn.Linear(64, 10)                                )    def forward(self, x):        # x = self.conv1(x)        # x = self.maxpool1(x)        # x = self.conv2(x)        # x = self.maxpool2(x)        # x = self.conv3(x)        # x = self.maxpool3(x)        # x = self.flatten(x)        # x = self.linear1(x)        # x = self.linear2(x)        x = self.model1(x)        return xtest = test()print(test)input = torch.ones((64, 3, 32, 32))output = test(input)print(output.shape)write = SummaryWriter(&quot;seq_logs&quot;)write.add_graph(test, input) # 输出运行的树图write.close()\n\n损失函数inputs = torch.tensor([1, 2, 3], dtype = torch.float32)targets = torch.tensor([1, 2, 5], dtype = torch.float32)inputs = torch.reshape(input, (1, 1, 1, 3))targets = torch.reshape(targets, (1, 1, 3, 1))loss = torch.nn.L1loss(reduction = &#x27;sum&#x27;)result = loss(inputs, targets)","categories":["学习笔记"],"tags":["计算机视觉","深度学习","Pytorch","人工智能"]},{"title":"LanQiao","url":"/2023/03/14/LanQiao/","content":"蓝桥杯基本准备LED指示灯基本原理\n锁存器(M74HC573MIR)用io控制对应led，三八译码器控制y4(0)以控制y4c以控制锁存器使能\n\n蜂鸣器与继电器ULN2003达林顿管\\\n\n输出为输入的非\n\n\n通过三八译码器控制y5(低电平有效)控制y5c以控制锁存器使能，在通过锁存器及达林顿管(类非门)控制端口达到控制蜂鸣器及继电器作用\n\n数码管\n\n\n共阳数码管段位表0\t--\t0xC01\t--\t0xF92\t--\t0xA43\t--\t0xB04\t--\t0x995\t--\t0x926\t--\t0x827\t--\t0xF88\t--\t0x809\t--\t0x90\n列表形式为\n// 共阳unsigned char smg_yang = [0xC0, 0xF9, 0xA4, 0xB0, 0x99, 0x92, 0x82, 0xF8, 0x80, 0x90] // 对应0-9unsigned char smg_dot[10] = &#123;0x40, 0x79, 0x24, 0x30, 0x19, 0x12, 0x02, 0x78, 0x00, 0x10&#125;; // 带小数点\n共阴数码管段位表0\t--\t0x3F1\t--\t0x062\t--\t0x5B3\t--\t0x4F4\t--\t0x665\t--\t0x6D6\t--\t0x7D7\t--\t0x078\t--\t0x7F9\t--\t0x6F\n列表形式为\n// 共阴unsigned char smg_yin = [0x3F, 0x06, 0x5B, 0x4F, 0x66, 0x6D, 0x7D, 0x07, 0x7F, 0x6F] // 对应0-9\n\n按键\n对于蓝桥板子 P37换为P44 P36换为P42\n\n独立按键需将J5的跳帽接到2~3引脚0为按下\n矩阵键盘需将J5的跳帽接到1~2引脚\n中断\n需将J5的跳帽接到2~3引脚即s5接到p32&#x2F;int0 s4接到p33&#x2F;int1\n\nDB18B20\n依据流程图 相关代码如下\n\nvoid read_ds18b20()&#123;\tunsigned char LSB, MSB;\tinit_ds18b20();\tWrite_DS18B20(0xcc); // 跳过rom操作\tWrite_DS18B20(0x44); // 开始读\tdelay_ds18b20(1000);\tinit_ds18b20();\tWrite_DS18B20(0xcc); // 跳过rom操作\tWrite_DS18B20(0xbe);\tLSB = Read_DS18B20(); // 低八位\tMSB = Read_DS18B20(); // 高八位\ttemp = MSB;\ttemp = (temp &lt;&lt; 8) | LSB;\tif(temp &amp; 0xf800 == 0x0000) // 判断高五位（符号位）此处为判断正数\t&#123;\t\ttemp &gt;&gt;= 4;\t\ttemp = temp * 10;\t\ttemp = temp + (LSB &amp; 0x0f) * 0.625;\t\t\t\t\t\t\t\t\t\t\t\t\t\t \t\t&#125;\t&#125;\n\nDS1302采用三线spi接口\n\n日历时钟寄存器\n\n","categories":["学习笔记"],"tags":["蓝桥杯"]},{"title":"conda常用指令","url":"/2023/03/22/Conda%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/","content":"conda 环境管理创建环境conda activate -n name python=3.x\n\nname为环境名3.x为指定python版本\n\n删除环境conda remove -n name --all\n\n激活环境conda activate name\n\n关闭环境 返回默认环境conda deactivate name\n\n查看当前有哪些环境conda info -e\n或\nconda env list\nconda包管理查看当前环境的包conda list\n\n安装指定package到当前环境conda install package\n\npackage 为所需包名字 可在后加入==指定版本或输入url指定安装源\n\n也可以使用pip等进行安装\n安装package到指定的环境conda install -n name package\n\n更新packageconda update -n name package\n\n移除packageconda remove -n name package\n或\nconda uninstall package\n\nconda版本更新conda版本conda update conda\n\n更新python版本conda update python\n\n假设当前环境是python 3.6 执行命令后conda会将python升级为3.6.x系列的当前最新版本\n\n","categories":["环境配置及相关工具"],"tags":["conda","python"]},{"title":"Ubuntu20.04换源","url":"/2023/03/22/Ubuntu20.04%E6%8D%A2%E6%BA%90/","content":"备份环境变量文件sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak\n\nsources.list 即储存环境变量的文件\n\n更换源sudo vim /etc/apt/sources.list\n\n进入文件后按i或insert启动输入模式 删除原有内容\n\n\n可在进入输入模式前在航首按dd删除当前行 或dG删除光标以后所有内容\n\n删除内容后使用新源进行替换\n阿里源\ndeb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse\n清华源\ndeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse\n中科大源\ndeb https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse\n网易163源\ndeb http://mirrors.163.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiverse\n\n还源完成后\nsudo apt-get updatesudo apt-get upgrade\n让计算机根据源进行更新\n","categories":["环境配置及相关工具"],"tags":["Ubuntu20.04"]},{"title":"使用mmdet快速搭建识别模型网络","url":"/2023/03/22/%E4%BD%BF%E7%94%A8mmdet%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C/","content":"点击此处访问openmmdetection源码仓库 \n","tags":["计算机视觉","openmmlab","人工智能"]}]