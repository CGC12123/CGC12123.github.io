[{"title":"Opencv-python","url":"/2023/03/14/Opencv-python/","content":"点击此处访问github仓库 \n图像读取和保存读取img = cv2.imread(&quot;参数一&quot;, 参数二)\n\n参数一为读取的图像地址，参数二为读取的方式1为默认，以彩色模式读取0为灰度加载-1为以alpha通道加载  \n\n保存cv2.imwrite(&quot;参数一&quot;, 参数二)\n\n参数一为保存的位置以文件名参数二为保存的图像\n\n输出以cv2输出cv2.imshow(&quot;1&quot;,img)cv2.waitKey(0)cv2.destroyAllWindows()\n以plt输出plt.imshow(img[:,:,::-1])plt.show()\n\n视频视频读取cap = cv2.VideoCapture(0)\n\nVideoCapture()中参数是0，表示打开笔记本的内置摄像头参数是视频文件路径则打开视频如cap = cv2.VideoCapture(“../test.avi”)\n\n视频属性修改cap.set(propId，value)\n\npropId: 从0到18的数字，每个数字表示视频的属性\n\n\n算数操作相加img = cv2.add(rain, view) 像素相同才可相加\n混合img = cv2.addWeighted(view, 0.7, rain, 0.3, 0)按照7：3进行混合，最后的参数为伽马值，作为图像的补充\n\n像素点的获取与修改获取img[100,100])获取（100，100）处像素点的值\n修改img[100,100] = (0,0,255)修改（100，100）处的像素值为（0，0，255）\n像素层的拆分与合并b,g,r = cv2.split(img)拆分bgrcv2.merge((b,g,r))合并bgr\n\n图像绘制cv2.line(img, (0,0), (511, 511), (255, 0, 0), 5)直线cv2.circle(img, (256, 256), 60, (50, 50,150), 3)圆形cv2.rectangle(img, (100, 100), (400, 400), (100, 100, 70), 4)矩形cv2.putText(img, &quot;loloo&quot;, (160, 480), cv2.FONT_HERSHEY_SIMPLEX, 3, (40,20,100), 3)文字\n\n图像操作图像缩放cv2.resize()\n图像平移M = np.float32([[1,0,100],[0,1,50]])#平移矩阵，(先列后行?)，即x方向移动100，y方向移动50cv2.warpAffine(img, M, (2*cols, 2*rows))#第三个元素为结果图像的尺寸，先列后行，表现为先增行再增列\n图像旋转M = cv2.getRotationMatrix2D((cols/2, rows/2),90,1)制造旋转矩阵cv2.warpAffine(img,M,(cols,rows))利用“类平移”使其与原图像进行矩阵乘法  \n仿射变换pts1 = np.float32([[50,50],[200,50],[50,200]])#原图像中选取三个点pts2 = np.float32([[100,100],[200,50],[100,250]])对应到仿射变换后的三个点M = cv2.getAffineTransform(pts1, pts2)构造出仿射的变换矩阵cv2.warpAffine(img,M,(cols,rows))\n透射变换pst1 = np.float32([[56,65],[368,95],[28,387],[389,390]])pst2 = np.float32([[100,145],[300,100],[80,290],[310,300]])T = cv2.getPerspectiveTransform(pst1,pst2)res = cv2.warpPerspective(img, T, (cols, rows))\n图像金字塔下采样cv2.pyrDown(img)\n上采样cv2.pyrUp(img)\n\n形态学操作腐蚀\n用于消除目标边界点，使目标缩小，消除小于结构元素的噪声点  \n\nkernel = np.ones((5,5), np.uint8, iterations = 1)创建5*5的卷积核用于操作  \n\n参数三iterations为模糊程度（腐蚀次数），其值越高，腐蚀程度越大\n\nimg1 = cv2.erode(img, kernel)腐蚀\n膨胀\n用于讲与物体接触到的所欲背景点合并到物体中，使目标增大，可填补目标中的孔洞  \n\nkernel = np.ones((5,5), np.uint8, iterations = 1)创建5*5的卷积核用于操作  \n\n参数三iterations为膨胀程度（膨胀次数），其值越高，膨胀程度越大\n\nimg2 = cv2.dilate(img, kernel)膨胀\n开运算\n先腐蚀后膨胀，用于分离物体，消除小区域消除噪点，去除小干扰块，而不影响原来的图像  \n\nkernel = np.ones((10, 10), np.uint8)cvopen = cv2.morphologyEx(img, cv2.MORPH_OPEN,kernel)\n闭运算\n先膨胀后腐蚀，用于消除闭合物体里的孔洞可以填补闭合区域  \n\nkernel = np.ones((10, 10), np.uint8)cvclose = cv2.morphologyEx(img, cv2.MORPH_CLOSE,kernel)\n礼帽运算\n原图像和开运算结果图的差用来分离一些比临近点亮一些的斑块当一副图像具有大幅的背景而微笑物品比较有规律时，用礼帽进行背景提取  \n\nkernel = np.ones((10, 10), np.uint8)cvopen = cv2.morphologyEx(img, cv2.MORPH_TOPHAT,kernel)\n黑帽运算\n闭运算结果图和原图像的差用来分离比临近点暗一些的斑块突出比原图轮廓周围更暗的区域于选择的核的大小有关  \n\nkernel = np.ones((10, 10), np.uint8)cvopen = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT,kernel) \n\n图像噪声椒盐噪声（脉冲噪声）\n随机出现的白点或黑点可能为讯号收到的强烈干扰而产生的  \n\n高斯噪声\n噪声密度函数服从高斯分布易于清除\n\n\n图像平滑均值滤波\n算法简单，计算速度块，但去噪的用时去除了部分细节，将图像变得模糊  \n\nimg2 = cv2.blur(img,(5,5)) \n高斯滤波img2 = cv2.GaussianBlur(img, (3,3), 1)  \n\n参数二为高斯卷积核的大小，应均为奇数且可以不同参数三为水平方向标准差可有参数四，为竖直方向标准差，默认值为0，可有参数五，为填充边界类型  \n\n中值滤波\n不依赖于邻域内于典型值差别很大的值，对椒盐噪声尤其有用  \n\nimg2 = cv2.medianBlur(img, 5)  \n\n参数二为核的大小\n\n\n直方图直方图绘制hist = cv2.calcHist([img], [0], None, [256], [0,256])plt.figure(figsize=(10,10))  \n\n参数二代表传入的图像类型对于灰度图[0]为默认值对于彩色图[0]为B [1]为G [2]为R参数三为掩模图像，设置为None为整幅图参数四为BIN数目参数五为像素值范围\n\n掩膜应用mask = np.zeros(img.shape[:2],np.uint8())创建掩膜 mask[100:250,100:400] = 1 设置感兴趣区域\nmask_img = cv2.bitwise_and(img,img,mask = mask)将掩膜与图像混合\n直方图均衡化\n将灰度直方图进行拉伸可提高图像对比度，在曝光过度或不足时可以更好的突出细节dst = cv2.equalizeHist(img)\n\n自适应直方图均衡化\n将整幅图像分成小块，分别进行直方图均衡化，若直方图中bin超过对比度上限，就将其中像素点均匀分散到其他bins中，然后再进行直方图均衡化最后使用双线性差值，对每一小块进行拼接，可去除小块间的边界\n\ncl = cv2.createCLAHE(2.0, (8,8)) 对比度阈值2.0，分成8*8clahe = cl.apply(img)将其应用到图像上\n\n边缘检测Sobel算子\n利用搜索的方法获取边界（一阶导数为最大值）效率高于canny边缘检测，但准确度不如canny其抗噪声能力强，用途较多\n\nx = cv2.Sobel(img, cv2.CV_16S, 1, 0)边缘检测y = cv2.Sobel(img, cv2.CV_16S, 0, 1)边缘检测\\\n\n参数二为图像的深度参数三、四分别为对x，y上的求导，1为对该方向求导，0为不导可有参数五表示Sobel算子大小（卷积核大小），必须为奇数1，3，5，7，默认为3\n\nabsx = cv2.convertScaleAbs(x)格式转化absy = cv2.convertScaleAbs(y)格式转化\nres = cv2.addWeighted(absx, 0.5, absy, 0.5, 0)图像混合\nLaplacian算子\n利用零穿越的方式获取边界（二阶导数为0）  \n\nres = cv2.Laplacian(img, cv2.CV_16S)边缘检测res = cv2.convertScaleAbs(res)图像混合\nCanny边缘检测res = cv2.Canny(img, 0, 100)  \n\n参数二、三分别为两个阈值，二为较小的阈值，三为较大的阈值流程：噪声去除：高斯滤波计算图像梯度：sobel算子，计算梯度大小及方向非极大值抑制：利用梯度方向判断当前像素是否为边界点滞后阈值：设置两个阈值，确定最终边界\n\n\n模板匹配res = cv2.matchTemplate(img, temp, cv2.TM_CCORR)\n\n参数三为匹配的算法 有：平方查匹配(cv2.TM_SQDIFF)相关匹配(cv2.TM_CCORR利用相关系数匹配(cv2.TM_CCOEFF)\n\nmin_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)top_left = max_loc左上角h,w = temp.shape[:2]bottom_right = (top_left[0] + w, top_left[1] + h)右下角\ncv2.rectangle(img, top_left, bottom_right, (0,255,0), 2)画矩形框\n\n霍夫变换霍夫线检测\n调用霍夫变换前硬先进行二值化或者进行Canny边缘检测\n\nedges = cv2.Canny(img, 50, 150)Canny边缘检测\nlines = cv2.HoughLines(edges, 0.8, np.pi/180, 150)\n\n参数二、三为ρ和θ的精确度参数四为阈值，在累加器中高于该值才被认定为直线\n\nfor line in lines:rho,theta = line[0]a = np.cos(theta)b = np.sin(theta)x0 = rho * ay0 = rho * bx1 = int (x0 + 1000*(-b))y1 = int (y0 + 1000*a)x2 = int (x0 - 1000*(-b))y2 = int (y0 - 1000*a)cv.line(img, (x1, y1), (x2, y2), (50, 250, 50))画出对应直线\n霍夫圆检测\n由于霍夫圆检测对噪声比较敏感，所以首先对图像进行中值滤波\n\nimg = cv.medianBlur(gay_img, 7)中值滤波\ncircles = cv.HoughCircles(image, method, dp, minDist, param1=100, param2=100, minRadius=0,maxRadius=0 )\n\nmethod：使用霍夫变换圆检测的算法，它的参数是CV_HOUGH_GRADIENTdp：霍夫空间的分辨率，dp&#x3D;1时表示霍夫空间与输入图像空间的大小一致，dp&#x3D;2时霍夫空间是输入图像空间的一半，以此类推minDist为圆心之间的最小距离，如果检测到的两个圆心之间距离小于该值，则认为它们是同一个圆心param1：边缘检测时使用Canny算子的高阈值，低阈值是高阈值的一半。param2：检测圆心和确定半径时所共有的阈值minRadius和maxRadius为所检测到的圆半径的最小值和最大值\\\n\n\n特征提取Harris角点检测dst=cv2.cornerHarris(src, blockSize, ksize, k)\n\nimg：数据类型为 ﬂoat32 的输入图像。blockSize：角点检测中要考虑的邻域大小。ksize：sobel求导使用的核大小k ：角点检测方程中的自由参数，取值参数为 [0.04，0.06]\n\n\n优缺点：\n\n\n优点：旋转不变性，椭圆转过一定角度但是其形状保持不变（特征值保持不变）对于图像灰度的仿射变化具有部分的不变性，由于仅仅使用了图像的一介导数，对于图像灰度平移变化不变；对于图像灰度尺度变化不变\n\n\n缺点：对尺度很敏感，不具备几何尺度不变性。提取的角点是像素级的\n\nShi-Tomas角点检测\nCorners: 搜索到的角点，在这里所有低于质量水平的角点被排除掉，然后把合格的角点按质量排序，然后将质量较好的角点附近（小于最小欧式距离）的角点删掉，最后找到maxCorners个角点返回。\n\n\n具有旋转不变性，但不具备几何尺度不变性\n\ncorners = cv2.goodFeaturesToTrack ( image, maxcorners, qualityLevel, minDistance )\n\nImage: 输入灰度图像maxCorners : 获取角点数的数目。qualityLevel：该参数指出最低可接受的角点质量水平，在0-1之间。minDistance：角点之间最小的欧式距离，避免得到相邻特征点。\n\n尺度不变特征转换-&gt;SIFT算法\n在不同的尺度空间上查找关键点(特征点)，并计算出关键点的方向。SIFT所查找到的关键点是一些十分突出，不会因光照，仿射变换和噪音等因素而变化的点，如角点、边缘点、暗区的亮点及亮区的暗点等。\n\n\n可具有尺度不变性和旋转不变性\n\nsift = cv.xfeatures2d.SIFT_create()kp,des = sift.detectAndCompute(gray,None)cv.drawKeypoints(image, keypoints, outputimage, color, flags)\n\nimage: 原始图像keypoints：关键点信息，将其绘制在图像上outputimage：输出图片，可以是原始图像color：颜色设置，通过修改（b,g,r）的值,更改画笔的颜色，b&#x3D;蓝色，g&#x3D;绿色，r&#x3D;红色。flags：绘图功能的标识设置cv2.DRAW_MATCHES_FLAGS_DEFAULT：创建输出图像矩阵，使用现存的输出图像绘制匹配对和特征点，对每一个关键点只绘制中间点cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG：不创建输出图像矩阵，而是在输出图像上绘制匹配对cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS：对每一个特征点绘制带大小和方向的关键点图形cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS：单点的特征点不被绘制\n\nSIFT算法的增强版-&gt;SIFT算法\n计算量小，运算速度快，提取的特征与SIFT几乎相同\n\n\n其他mask = cv2.inRange(image,low,high)\n\n设置阈值去除背景，高于或低于对应阈值图象值变为0\n\ncnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n\n用于搜索轮廓\n\n\n参数二表示轮廓的检索模式，有四种：    cv2.RETR_EXTERNAL表示只检测外轮廓    cv2.RETR_LIST检测的轮廓不建立等级关系    cv2.RETR_CCOMP建立两个等级的轮廓，上面的一层为外边界，里面的一层为内孔的边界信息。如果内孔内还有一个连通物体，这个物体的边界也在顶层。    cv2.RETR_TREE建立一个等级树结构的轮廓。\\\n\n\n参数三method为轮廓的近似办法    cv2.CHAIN_APPROX_NONE存储所有的轮廓点，相邻的两个点的像素位置差不超过1，即max（abs（x1-x2），abs（y2-y1））&#x3D;&#x3D;1    cv2.CHAIN_APPROX_SIMPLE压缩水平方向，垂直方向，对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需4个点来保存轮廓信息    cv2.CHAIN_APPROX_TC89_L1，CV_CHAIN_APPROX_TC89_KCOS使用teh-Chinl chain 近似算法\n\nfor c in range(len(contours)):area = cv2.contourArea(contours[c])\n\n使用格林公式计算轮廓内面积面积\n\nfor c in range(len(contours)):arclen = cv2.arcLength(contours[c], True)\n\n计算周长\n\nrect = cv2.minAreaRect(are_max)\n\ncv2.findContours()找轮廓函数返回轮廓数组后，绘制每个轮廓的最小外接矩形的方法\n\n\n返回的是一个叫Box2D 结构,如((81.0,288),(22.0,10.0),-0.0)\\其表示的意义是（中心点坐标，（宽度，高度）,旋转的角度）\n\nbox = cv2.boxPoints(rect)\n\n获取矩形的四个顶点坐标\n\ncv2.drawContours(image, [np.int0(box)], -1, (0, 255, 255), 2)\n\n轮廓绘制\n\n\n第一个参数是指明在哪幅图像上绘制轮廓；image为三通道才能显示轮廓\n\n\n第二个参数是轮廓本身，在Python中是一个list\n\n\n第三个参数指定绘制轮廓list中的哪条轮廓，如果是-1，则绘制其中的所有轮廓。后面的参数很简单。其中thickness表明轮廓线的宽度，如果是-1（cv2.FILLED），则为填充模式\n\nimgHSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n将图像从一种颜色空间转换为另一种颜色空间 \n\n","categories":["学习笔记"],"tags":["计算机视觉","Opencv"]},{"title":"Matlab","url":"/2023/03/14/Matlab/","content":"常用函数三角函数sin % 正弦函数cos % 余弦tan % 正切sinh % 双曲正弦cosh % 双曲余弦tanh % 双曲正切asin % 反正弦acos % 反余弦atan % 反正切asinh % 反双曲正弦acosh % 反双曲余弦atanh % 反双曲正切\n指数与对数函数exp % 指数log % e为底的对数log10 % lgsqrt % 平方根\n与复数有关的函数abs % 模angle % 幅角conj % 复共轭imag % 虚部real % 实部\n舍入函数与其他数值函数fix % 向0舍入floor % 向负无穷舍入ceil % 向正无穷舍入round % 四舍五入rem(a, b) % 计算a/b余数\n有关向量的函数min(x) % 向量x的元素最小值max(x) % 向量x的元素最大值mean(x) % 向量x的元素平均值median(x) % 向量x的元素中位数std(x) % 向量x的元素标准差diff(x) % 向量x的相邻元素差sort(x) % 对向量x进行排序length(x) % 向量x的元素个数norm(x) % 向量x的Euclidean长度sum(x) % 向量x的元素和prod(x) % 向量x的元素连乘积cunsum(x) % 向量x的累计元素总和dot(x) % 向量x的内积cross(x) % 向量x的外积cumprod(x) % 向量x的累计元素总乘积\n关于矩阵矩阵的表示如\nA = [1, 2, 2; 2, 4, 2; 5, 3, 1]\n矩阵转置使用&#39;来表示如\nB = A&#x27;\n矩阵加减+,-\n矩阵乘法*\n求行列式det(A)\n矩阵求逆inv(A)\n“除法”如AX = b可用X = A \\ b求解同时X = A \\ b可用于解矛盾方程组\n矩阵特征值eig(A)\n函数作图二维平面曲线作图plot(x, y, s) % x、y为长度相同的向量，s表示线型及颜色\n\n若作多曲线在同一图上，则用函数\nplot(x1, x2, s1, x2, y2, s2,.., xn, yn, sn)\n\n取某一区间为x = 0:0.1:2*pi 表示取[0, 2Π] 间隔为0.1\n多窗口作图将屏幕分为多个窗口分别作图\nsubplot(m, n, k) % 将窗口分为m*n个，当前图在第k个\n\n直方图作图count = hist(x) % 将向量x中的元素放入等距10条形中，且返回每个条形中的元素个数count = hist(x, center) % 参量x为向量，将x中元素放到m(m = length(center))个由center中元素指定的位置为中心的直方图中count = hist(x, number) % 参量number为标量，用于指定条形数目[count, center] = hist(x) % 返回向量x中包含频率计数的count与条形的位置向量center，可以用bar(center, count) % 对center, count画出条形直方图 条之间有间隔hist(x) % 直接对传入的x进行作图\nx = normrnd(10, 5, 1000, 1) 表示传入均值为10 标准差为5的正态分布曲线 产生一千行一列的数据\n二维图形注释grid功能：给图形坐标面增加分割线 但会对当前坐标轴的属性有影响\ngrid on % 给当前坐标轴增加分隔线grid off % 从当前坐标轴去掉分隔线grid % 转换分割线的显示与否状态grid(axes_handle, on|off) % 对指定坐标轴axes_handle更改显示分割线状态\n\n空间曲线作图三维曲线作图plot3(x, y, z, s) % x、y、z为长度相同的向量，s表示线型及颜色\n如 做空间螺旋线\nt = 0:0.01:8*pi;x = cos(t);y = sin(t);z = t;plot3(x, y, z, &#x27;r&#x27;);\n三维曲面作图mesh(x, y, z) % 生成由x, y, z指定的网线面surf(x, y, z) % 在矩形区域内显示三维带阴影曲面图\n如\n% 作z = cosx.*siny曲面图[x, y] = meshgrid(-3:0.1:3, -4:0.1:4);z = cos(x) .* sin(y);mesh(x, y, z); % 网线面xlabel(&#x27;x&#x27;);ylabel(&#x27;y&#x27;);zlabel(&#x27;z&#x27;);surf(x, y, z) % 带阴影曲面图xlabel(&#x27;x&#x27;);ylabel(&#x27;y&#x27;);zlabel(&#x27;z&#x27;);\n\n基本语句forfor x = a:d:b % a为起始点 b为终止点 d为区间间隔    (command) % 循环体end\n如\n% 求100以内奇数相加和for i 1:2:99    s = s + i;ends % 输出结果\nwhilewhile expression    (command)end\nif-else-endif expression    (command)elseif expression    (command)else    (command)end\n\n脚本文件与函数文件函数文件开头需为例如\nfunction z = fun(x)\n以方便脚本文件调用在命令窗口输入例如\nx = [1, 2]z = fun(x)\n即可调用\n状态转移模型","categories":["学习笔记"],"tags":["数学建模","Matlab"]},{"title":"Lingo","url":"/2023/03/14/Lingo/","content":"lingo编写格式集合部分(SETS)以SETS开始，以ENDSETS结束用于定义必要变量有两类集合\n**原始集合:**其定义格式为:\nSETENME/member list(or 1..n)/: attribute, attribute, etc.\n导出集合引用其他集合定义的集合 其定义格式为:\nSENTNAME(set1, set2, etc.): attribute, attribute, etc.\n\n若要在程序中使用数组，则必须在该部分定义如\nPerson/1..10/:A;Task/1..12/:B;Link(Person, Task):X;\n目标与约束定义目标函数、约束条件等\n数据部分(DATA)以DATA: 开始，以END DATA结束用于数据的输入格式为：\nattribute = value_list\n\n初始化部分(INIT)以INIT: 开始，以END INIT结束用于对集合属性（数组）定义初值格式为\nattribute=value_list\n\n内部函数以@开头\\\n数学函数常用数学函数如下\n@ABS(X) 返回绝对值@COS(X) 返回余弦值@EXP(X) 返回e指数值@FLOOR(X) 返回靠近0的整数部分@LGM(X) 返回Γ函数自然对数值@LOG(X) 返回x自然对数值@SIGN(X) 返回符号值 负数为-1 正数为1@SIN(X)  返回正弦 x为弧度制@SMAX(X1, X2···, Xn) 返回最大值@SMIN(X) (X1, X2···, Xn) 返回最小值@TAN(X) 返回正切值\n集合函数集合函数格式如下\nset_operator(set_name|condition:expression)\n其中set_operator为集合函数名set_name为数据集合名 condition为表达式|expression为条件，用逻辑表达式描述（无条件可省略）\n逻辑表达式中 有如下运算符\n#AND# 与#OR# 或#NOT# 非#EQ# 等于#NE# 不等于#GT# 大于#GE# 大于等于#LT# 小于#LE# 小于等于\n常见集合函数如下：\n@FOR(set_name: constraint) 对集合set_name的每个元素独立生成约束 由约束表达式constraint描述@MAX(set_name: exoression) 返回集合上最大值@MIN(set_name: exoression) 返回集合上最小值@SUN(set_name: exoression) 返回集合上的表达式exoression的和@SIZE(set_name) 返回元素个数@IN(set_name, set_element) 若set_name中包含set_element则返回1，反之返回0\n\n变量界定函数变量函数对变量的取值范围的附加限制 由如下四种\n@BND(L, X, U)限制L≤X≤U@BIN(X) 限制x为1或0@FREE(X) 取消对x的符号限制(可取任意实数)@GIN(X) 限制x为整数值","categories":["学习笔记"],"tags":["Lingo","数学建模"]},{"title":"Ubuntu20.04换源","url":"/2023/03/22/Ubuntu20.04%E6%8D%A2%E6%BA%90/","content":"备份环境变量文件sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak\n\nsources.list 即储存环境变量的文件\n\n更换源sudo vim /etc/apt/sources.list\n\n进入文件后按i或insert启动输入模式 删除原有内容\n\n\n可在进入输入模式前在航首按dd删除当前行 或dG删除光标以后所有内容\n\n删除内容后使用新源进行替换\n阿里源\ndeb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse\n清华源\ndeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse\n中科大源\ndeb https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse\n网易163源\ndeb http://mirrors.163.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiverse\n\n还源完成后\nsudo apt-get updatesudo apt-get upgrade\n让计算机根据源进行更新\n","categories":["环境配置及相关工具"],"tags":["Ubuntu20.04","Ubuntu"]},{"title":"使用mmdet快速搭建识别模型网络","url":"/2023/03/22/%E4%BD%BF%E7%94%A8mmdet%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C/","content":"点击此处访问openmmdetection源码仓库 \n选择模型使用命令行下载配置文件和模型权重文件\nmim download mmyolo --config yolov5_s-v61_syncbn_fast_8xb16-300e_coco --dest .\n\n搭建识别网络from mmdet.apis import init_detector, inference_detectorconfig_file = &#x27;configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py&#x27;checkpoint_file = &#x27;checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth&#x27;device = &#x27;cuda:0&#x27;# 初始化检测器model = init_detector(config_file, checkpoint_file, device=device)# 推理演示图像inference_detector(model, &#x27;demo.jpg&#x27;)","categories":["深度学习模型"],"tags":["计算机视觉","openmmlab","深度学习","人工智能"]},{"title":"使用mmyolo快速搭建yolo网络","url":"/2023/03/26/%E4%BD%BF%E7%94%A8mmyolo%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAyolo%E7%BD%91%E7%BB%9C/","content":"\n说明：此为根据实践搭建并从官方文档中整理而来，官方源码及文档如下官方开源项目源码 官方使用文档 \n\n环境搭建使用conda创建新环境并安装pytorchconda create -n mmyolo python=3.8 -yconda activate mmyolo# 如果你有 GPUconda install pytorch torchvision -c pytorch# 如果你是 CPU# conda install pytorch torchvision cpuonly -c pytorch\n安装 MMYOLO 和依赖库git clone https://github.com/open-mmlab/mmyolo.gitcd mmyolopip install -U openmimmim install -r requirements/mminstall.txt# Install albumentationsmim install -r requirements/albu.txt# Install MMYOLOmim install -v -e .# &quot;-v&quot; 指详细说明，或更多的输出# &quot;-e&quot; 表示在可编辑模式下安装项目，因此对代码所做的任何本地修改都会生效，从而无需重新安装。\n\n准备数据集此处数据集为官方文档中演示所用的Cat 数据集，为包括144张图片的单类别数据集在上一步中克隆的mmyolo源码中，使用如下命令即可自动下载目标数据集\npython tools/misc/download_dataset.py --dataset-name cat --save-dir ./data/cat --unzip --delete\n\ndata/cat/annotations 中存放的是 COCO 格式的标注，data/cat/images 中存放的是所有图片\n\n文件配置官方源码中已经为我们提供了yolov5等的配置文件，位于configs中，我们只需要继承这些配置文件，并按照需求进行相应修改即可官方所给的配置案例为\n# 基于该配置进行继承并重写部分配置_base_ = &#x27;./configs/yolov5/yolov5_s-v61_syncbn_fast_8xb16-300e_coco.py&#x27;data_root = &#x27;./data/cat/&#x27; # 数据集根路径class_name = (&#x27;cat&#x27;, ) # 数据集类别名称num_classes = len(class_name) # 数据集类别数# metainfo 必须要传给后面的 dataloader 配置，否则无效# palette 是可视化时候对应类别的显示颜色# palette 长度必须大于或等于 classes 长度metainfo = dict(classes=class_name, palette=[(20, 220, 60)])# 基于 tools/analysis_tools/optimize_anchors.py 自适应计算的 anchoranchors = [    [(68, 69), (154, 91), (143, 162)],  # P3/8    [(242, 160), (189, 287), (391, 207)],  # P4/16    [(353, 337), (539, 341), (443, 432)]  # P5/32]# 最大训练 40 epochmax_epochs = 40# bs 为 12train_batch_size_per_gpu = 12# dataloader 加载进程数train_num_workers = 4# 加载 COCO 预训练权重load_from = &#x27;https://download.openmmlab.com/mmyolo/v0/yolov5/yolov5_s-v61_syncbn_fast_8xb16-300e_coco/yolov5_s-v61_syncbn_fast_8xb16-300e_coco_20220918_084700-86e02187.pth&#x27;  # noqamodel = dict(    # 固定整个 backbone 权重，不进行训练    backbone=dict(frozen_stages=4),    bbox_head=dict(        head_module=dict(num_classes=num_classes),        prior_generator=dict(base_sizes=anchors)    ))train_dataloader = dict(    batch_size=train_batch_size_per_gpu,    num_workers=train_num_workers,    dataset=dict(        data_root=data_root,        metainfo=metainfo,        # 数据集标注文件 json 路径        ann_file=&#x27;annotations/trainval.json&#x27;,        # 数据集前缀        data_prefix=dict(img=&#x27;images/&#x27;)))val_dataloader = dict(    dataset=dict(        metainfo=metainfo,        data_root=data_root,        ann_file=&#x27;annotations/test.json&#x27;,        data_prefix=dict(img=&#x27;images/&#x27;)))test_dataloader = val_dataloader_base_.optim_wrapper.optimizer.batch_size_per_gpu = train_batch_size_per_gpuval_evaluator = dict(ann_file=data_root + &#x27;annotations/test.json&#x27;)test_evaluator = val_evaluatordefault_hooks = dict(    # 每隔 10 个 epoch 保存一次权重，并且最多保存 2 个权重    # 模型评估时候自动保存最佳模型    checkpoint=dict(interval=10, max_keep_ckpts=2, save_best=&#x27;auto&#x27;),    # warmup_mim_iter 参数非常关键，因为 cat 数据集非常小，默认的最小 warmup_mim_iter 是 1000，导致训练过程学习率偏小    param_scheduler=dict(max_epochs=max_epochs, warmup_mim_iter=10),    # 日志打印间隔为 5    logger=dict(type=&#x27;LoggerHook&#x27;, interval=5))# 评估间隔为 10train_cfg = dict(max_epochs=max_epochs, val_interval=10)\n可以直接复制使用，也可以进行进一步修改\n\n其中 _base_ = &#39;yolov5_s-v61_syncbn_fast_8xb16-300e_coco.py&#39; 修改所继承的配置文件，从 configs 中选取\n\n将如上继承后的文件另行保存至任意位置即可（需记下路径）\n模型训练训练在命令行中使用指令运行如\npython tools/train.py configs/yolov5/yolov5_s-v61_fast_1xb12-40e_cat.py\n\ntools/train.py 为训练脚本configs/yolov5/yolov5_s-v61_fast_1xb12-40e_cat.py 为上一步中所说的配置文件，可直接使用官方所给，也可以使用自己所集成修改的，将此参数改为上一步中继承后的文件的路径即可\n\n\n运行以上训练命令 work_dirs/yolov5_s-v61_fast_1xb12-40e_cat 文件夹会被自动生成，权重文件以及此次的训练配置文件将会保存在此文件夹中。\n\n注意事项在训练过程中会打印如下两个关键警告：\nYou are using YOLOv5Head with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\\The model and loaded state dict do not match exactly\n这两个警告都不会对性能有任何影响。第一个警告是说明由于当前训练的类别数是 1，根据 YOLOv5 算法的社区， 分类分支的 loss 始终是 0，这是正常现象。第二个警告是因为目前是采用微调模式进行训练，我们加载了 COCO 80 个类的预训练权重， 这会导致最后的 Head 模块卷积通道数不对应，从而导致这部分权重无法加载，这也是正常现象。\n训练中断后恢复训练如果训练中途停止，可以在训练命令最后加上 --resume ,程序会自动从 work_dirs 中加载最新的权重文件恢复训练。例如\npython tools/train.py configs/yolov5/yolov5_s-v61_fast_1xb12-40e_cat.py --resume\n\n节约显存策略如果显存不够，可以考虑开启混合精度训练--amp\npython tools/train.py configs/yolov5/yolov5_s-v61_fast_1xb12-40e_cat.py --amp\n\n训练可视化官方文档中展示了多种可视化方案，在此处我们使用tensorboard在先前我们已经配置好的配置文件中的最后加入\nvisualizer = dict(vis_backends=[dict(type=&#x27;LocalVisBackend&#x27;), dict(type=&#x27;TensorboardVisBackend&#x27;)])\n重新运行训练命令后，Tensorboard 文件会生成在可视化文件夹 work_dirs/yolov5_s-v61_fast_1xb12-40e_cat.py/&#123;timestamp&#125;/vis_data 下， 运行下面的命令便可以在网页链接使用 Tensorboard 查看 loss、学习率和 coco&#x2F;bbox_mAP 等可视化数据了：\ntensorboard --logdir=work_dirs/yolov5_s-v61_fast_1xb12-40e_cat.py\n\n其中最后一个.py文件参数为配置文件\n\n模型测试及预测模型测试运行如下\npython tools/test.py configs/yolov5/yolov5_s-v61_fast_1xb12-40e_cat.py \\                     work_dirs/yolov5_s-v61_fast_1xb12-40e_cat/epoch_40.pth \\                     --show-dir show_results\n\n两个文件参数分别为配置文件、权重文件\n\n运行以上测试命令， 不仅可以得到模型训练部分所打印的 AP 性能，还可以将推理结果图片自动保存至 work_dirs/yolov5_s-v61_fast_1xb12-40e_cat/&#123;timestamp&#125;/show_results 文件夹中。\n如果使用了 WandbVisBackend 或者 TensorboardVisBackend，则还可以在浏览器窗口可视化模型推理结果。\n","categories":["深度学习模型"],"tags":["计算机视觉","openmmlab","深度学习","人工智能","yolo"]},{"title":"Yolov8初体验","url":"/2023/03/26/Yolov8%E5%88%9D%E4%BD%93%E9%AA%8C/","content":"\nUltralytics YOLOv8 是由 Ultralytics 开发的一个前沿的 SOTA 模型。它在以前成功的 YOLO 版本基础上，引入了新的功能和改进，进一步提升了其性能和灵活性。YOLOv8 基于快速、准确和易于使用的设计理念，使其成为广泛的目标检测、图像分割和图像分类任务的绝佳选择。官方源码 \n\nYolov8的快速部署使用使用命令行基础调用如\nyolo predict model=yolov8n.pt source=&#x27;https://ultralytics.com/images/bus.jpg&#x27;\n\npredict 为任务模式，可选择detect, classify, segment 分别对应检测、分类、分割model 为所使用模型 主要有YOLOv8n, YOLOv8s,\tYOLOv8m,\tYOLOv8l, YOLOv8xsource 为目标，可指向图片或视频，填 0 为调用摄像头完整参数配置可点击此处查看 \n\nPython调用和使用命令行相似例如\nfrom ultralytics import YOLO# 加载模型model = YOLO(&quot;yolov8n.yaml&quot;)  # 从头开始构建新模型model = YOLO(&quot;yolov8n.pt&quot;)  # 加载预训练模型（推荐用于训练）# Use the modelresults = model.train(data=&quot;coco128.yaml&quot;, epochs=3)  # 训练模型results = model.val()  # 在验证集上评估模型性能results = model(&quot;https://ultralytics.com/images/bus.jpg&quot;)  # 预测图像success = model.export(format=&quot;onnx&quot;)  # 将模型导出为 ONNX 格式","categories":["深度学习模型"],"tags":["计算机视觉","深度学习","人工智能","yolo"]},{"title":"关于蓝桥杯","url":"/2023/03/14/%E5%85%B3%E4%BA%8E%E8%93%9D%E6%A1%A5%E6%9D%AF/","content":"基本原理LED指示灯基本原理\n锁存器(M74HC573MIR)用io控制对应led，三八译码器控制y4(0)以控制y4c以控制锁存器使能\n\n蜂鸣器与继电器ULN2003达林顿管\n\n输出为输入的非\n\n\n通过三八译码器控制y5(低电平有效)控制y5c以控制锁存器使能，在通过锁存器及达林顿管(类非门)控制端口达到控制蜂鸣器及继电器作用\n\n数码管\n\n\n共阳数码管段位表0\t--\t0xC01\t--\t0xF92\t--\t0xA43\t--\t0xB04\t--\t0x995\t--\t0x926\t--\t0x827\t--\t0xF88\t--\t0x809\t--\t0x90\n列表形式为\n// 共阳unsigned char smg_yang = [0xC0, 0xF9, 0xA4, 0xB0, 0x99, 0x92, 0x82, 0xF8, 0x80, 0x90] // 对应0-9unsigned char smg_dot[10] = &#123;0x40, 0x79, 0x24, 0x30, 0x19, 0x12, 0x02, 0x78, 0x00, 0x10&#125;; // 带小数点 由不带小数点的段码减去0x80\n共阴数码管段位表0\t--\t0x3F1\t--\t0x062\t--\t0x5B3\t--\t0x4F4\t--\t0x665\t--\t0x6D6\t--\t0x7D7\t--\t0x078\t--\t0x7F9\t--\t0x6F\n列表形式为\n// 共阴unsigned char smg_yin = [0x3F, 0x06, 0x5B, 0x4F, 0x66, 0x6D, 0x7D, 0x07, 0x7F, 0x6F] // 对应0-9\n\n按键\n对于蓝桥板子 P37换为P44 P36换为P42\n\n独立按键需将J5的跳帽接到2~3引脚0为按下\n矩阵键盘\n需将J5的跳帽接到1~2引脚\n\n中断\n需将J5的跳帽接到2~3引脚即s5接到p32&#x2F;int0 s4接到p33&#x2F;int1\n\nDB18B20\n依据流程图 相关代码如下\n\nvoid read_ds18b20()&#123;\tunsigned char LSB, MSB;\tinit_ds18b20();\tWrite_DS18B20(0xcc); // 跳过rom操作\tWrite_DS18B20(0x44); // 开始读\tdelay_ds18b20(1000);\tinit_ds18b20();\tWrite_DS18B20(0xcc); // 跳过rom操作\tWrite_DS18B20(0xbe);\tLSB = Read_DS18B20(); // 低八位\tMSB = Read_DS18B20(); // 高八位\ttemp = MSB;\ttemp = (temp &lt;&lt; 8) | LSB;\tif(temp &amp; 0xf800 == 0x0000) // 判断高五位（符号位）此处为判断正数\t&#123;\t\ttemp &gt;&gt;= 4;\t\ttemp = temp * 10;\t\ttemp = temp + (LSB &amp; 0x0f) * 0.625;\t\t\t\t\t\t\t\t\t\t\t\t\t\t \t\t&#125;\t&#125;\nDS1302\n采用三线spi接口\n\n\n日历时钟寄存器\n\n\n备赛更新HC138模块选择void selete_hc138(u8 num)&#123;\tswitch (num)\t&#123;\t\tcase 0:\t\t\tHC138_A = 0;\t\t\tHC138_B = 0;\t\t\tHC138_C = 0;\t\t\tbreak;\t\tcase 4:\t\t\tHC138_A = 0;\t\t\tHC138_B = 0;\t\t\tHC138_C = 1;\t\t\tbreak;\t\tcase 5:\t\t\tHC138_A = 1;\t\t\tHC138_B = 0;\t\t\tHC138_C = 1;\t\t\tbreak;\t\tcase 6:\t\t\tHC138_A = 0;\t\t\tHC138_B = 1;\t\t\tHC138_C = 1;\t\t\tbreak;\t\tcase 7:\t\t\tHC138_A = 1;\t\t\tHC138_B = 1;\t\t\tHC138_C = 1;\t\t\t\tbreak;\t&#125;&#125;\n\n其中4 为LED5 为继电器及蜂鸣器 0x10为继电器闭合 亮灯(L10)6 为数码管位选7 为数码管段选\n\n数码管显示void fmq_display(u8 pos,u8 num)&#123;\tselete_hc138(6);\tP0 = (0X01 &lt;&lt; pos) ;\tselete_hc138(7);\tP0 = num;&#125;\n\n系统初始化进行关灯等\nvoid system_init()&#123;\tselete_hc138(0);\tP0 = 0x00;\tselete_hc138(4);\tP0 = 0xff;\t&#125;\n\n温度模块-DS18B20驱动文件修改\n对于蓝桥杯的板子，由于其运行速度较快，官方给的驱动文件需要进行修改，将内部延时函数改为如下\nvoid Delay_OneWire(unsigned int t)  &#123;t *= 10;while(t --);&#125;\n即 将输入的延时时间放大十倍\n\n温度读取float temp_f;u16 temp_i;void rd_tempture()&#123;\tu16 temp;\tu8 high, low;\tinit_ds18b20();\tWrite_DS18B20(0xcc);\tWrite_DS18B20(0x44);\tinit_ds18b20();\tWrite_DS18B20(0xcc);\tWrite_DS18B20(0xbe);\t\tlow = Read_DS18B20();\thigh = Read_DS18B20();\t\tinit_ds18b20();\ttemp = (high &lt;&lt; 8) | low;\ttemp_f = temp * 0.0625;\ttemp_i = temp_f * 10;&#125;\n\n其中temp_f为当前温度值，以float储存，在使用时根据所需进行放大并转为int储存在temp_i中便于数码管显示\n\n内置日历时钟定时器-ds1302寄存器表\n注意高四位及第四位以bcd码储存以读秒为例子，取出81H地址中的值时，高八位储存的为十位，即time[0] / 16为十位，time[0] % 16为个位。\n\n日历读取及使用u8 code READ_RTC_ADDR[7] = &#123;0x81, 0x83, 0x85, 0x87, 0x89, 0x8b, 0x8d&#125;; // 对应寄存器地址u8 code WRITE_RTC_ADDR[7] = &#123;0x80, 0x82, 0x84, 0x86, 0x88, 0x8a, 0x8c&#125;;u8 time[] = &#123;0x50, 0x59, 0x20, 0x05, 0x03, 0x05, 0x23&#125;; // 用于初始化void ds1302_init() // 初始化&#123;\tu8 i; \tWrite_Ds1302_Byte(0x8e, 0x00);\tfor(i = 0; i &lt; 7; i++)\t&#123;\t\tWrite_Ds1302_Byte(WRITE_RTC_ADDR[i], time[i]);\t\t&#125;\tWrite_Ds1302_Byte(0x8e, 0x80);&#125;void rd_ds1302() // 读取&#123;\tu8 i;\tfor(i = 0; i &lt; 7; i ++)\t&#123;\t\ttime[i] = Read_Ds1302_Byte(READ_RTC_ADDR[i]); // 储存于对应地址中\t\t\t&#125;&#125;//以下为调用示例 输出小时及分钟数void ds1302_display_1()\t// 时分&#123;\trd_ds1302();\tfmq_display(0, 0xc1); // U\tdelay(200);\tfmq_display(0, 0xff);\tfmq_display(1, num_nodot[2]);\tdelay(200);\tfmq_display(1, 0xff);\tfmq_display(3, num_nodot[time[2] / 16]);\tdelay(200);\tfmq_display(3, 0xff);\tfmq_display(4, num_nodot[time[2] % 16]);\tdelay(200);\tfmq_display(4, 0xff);\tfmq_display(5, 0xbf);\tdelay(200);\tfmq_display(5, 0xff);\tfmq_display(6, num_nodot[time[1] / 16]);\tdelay(200);\tfmq_display(6, 0xff);\tfmq_display(7, num_nodot[time[1] % 16]);\tdelay(200);\tfmq_display(7, 0xff);&#125;\nPCF8591\n关于IIC的使用\n\n模数转换-ad// 驱动如下unsigned char Ad_Read(unsigned char addr)&#123;\tunsigned char temp;\tIIC_Start();\tIIC_SendByte(0x90);\tIIC_WaitAck();\tIIC_SendByte(addr);\tIIC_WaitAck();\tIIC_Start();\t\tIIC_SendByte(0x91);\tIIC_WaitAck();\ttemp = IIC_RecByte();\tIIC_SendAck(1);\tIIC_Stop();\treturn temp;&#125;\n以下为使用该接口读取滑动变阻器的值\nvoid ad_display(u8 dat)&#123;\tdat = Ad_Read(0x03); // 滑动变阻器的对应地址 光敏电阻为01\t// dat = Ad_Read(0x01); // 光敏电阻\tfmq_display(0, num_nodot[dat / 100]);\tdelay(500);\tfmq_display(0, 0xff);\tfmq_display(1, num_nodot[dat / 10 % 10]);\t\tdelay(500);\tfmq_display(1, 0xff);\tfmq_display(2, num_nodot[dat % 10]);\t\tdelay(500);\tfmq_display(2, 0xff);&#125;\n\n需要注意的是 读取的值均有稳定倍数关系 需要 * 5 / 255 即 / 51 即得到正常值\n\n数模转换-da\n输出值为板子D&#x2F;A输出口的电压(有换算关系 为 *5 &#x2F; 255)\n\nvoid Da_Write(unsigned char dat)&#123;\tIIC_Start();\tIIC_SendByte(0x90);\tIIC_WaitAck();\tIIC_SendByte(0x41);//使能\tIIC_WaitAck();\tIIC_SendByte(dat);\tIIC_WaitAck();\t\tIIC_Stop();&#125;\nAT24C02\n集成EEPROM\n\n向EEPROM写入数据void EEPROM_Write(unsigned char * string, unsigned char addr, unsigned char num)&#123;\tIIC_Start();\tIIC_SendByte(0xA0);\tIIC_WaitAck();\t\tIIC_SendByte(addr); // 标记为对应EEPROM地址\tIIC_WaitAck();\t\twhile(num --)\t&#123;\t\tIIC_SendByte(*string ++); \t\tIIC_WaitAck();\t\tIIC_Delay(200);\t\t&#125;\t\tIIC_Stop();&#125;\n调用即\nEEPROM_Write(temp, 0x01, 2); // 0x01为对应地址\n读取EEPROM数据void EEPROM_Read(unsigned char* string, unsigned char addr, unsigned char num)&#123;\tIIC_Start();\tIIC_SendByte(0xA0);\tIIC_WaitAck();\t\tIIC_SendByte(addr);\tIIC_WaitAck();\t\tIIC_Start();\tIIC_SendByte(0xA1);\tIIC_WaitAck();\t\twhile(num --)\t&#123;\t\t*string ++ = IIC_RecByte();\t\tif(num)\t\t&#123;\t\t\tIIC_SendAck(0);\t\t\t&#125;\t\telse\t\t&#123;\t\t\tIIC_SendAck(1);\t\t&#125;\t&#125;\tIIC_Stop();&#125;\n调用即\nEEPROM_Read(date, 0x01, 2); // 从0x01地址中读取值存入date数组\n\n\n赛后更新4.8一点小牢骚\n\n总的来说 尽力了剩下一个ne555赌它不考来着。。。您猜怎么着？上来就给我来一手ne555看到程序框图的第一反应人是傻的。。。\n官方给的文件和原来手上的不一样也是想不到的幸好 c语言没白学 头文件没忘记怎么写\n_nop()_在哪个头文件里我忘记了…。看着报错人也麻麻的还是幸好 知道这个函数是干嘛用的 自己手写了一个延时函数大概能代替它了\n幸好的幸好，除了用ne555做的湿度之外基本上都功能实现了 虽然有些地方好像写法很复杂\n其实做完能做的之后还剩下一个小时的样子看着ne555的手册和stc15的手册 本来想现学一手 想想 算了于是又去检查前面的题目有没有问题了\n这次比赛嘛 也不清楚到底比之前的难还是简单了有幸运也有遗憾我的建议是 尽力了 下次一定 如果有下次的话\n\n","categories":["学习笔记"],"tags":["蓝桥杯"]},{"title":"机器学习-Sklearn","url":"/2023/03/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Sklearn/","content":"Python中库的调用import sklearn\n数据集的划分sklearn.model_selection.train_test_split(arrays, *options)\nx 数据集的特征值y 数据集的标签值test_size 测试集的大小，一般为floatrandom_state 随机数种子,不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。return 测试集特征训练集特征值值，训练标签，测试标签(默认随机取)一般使用为\nx_train, x_test, y_train, y_test = train_test_split(data, target, random_state = 22)\n其中 data为自变量集 target为因变量\n特征工程字典特征提取from sklearn.feature_extraction import DictVectorizertransfer = DictVectorizer(sparse=True) # 实例化转换器类data = transfer.fit_transform(data) # 类似独热编码\nsparse为True为使用传统独热编码为False为使用向量说明当前位置 用于节省空间 加快运行效率\ndata_dure = pd.get_dummies(data2, columns=[&#x27;...&#x27;]) # 独热编码 columns为剔除无关项\n文本特征提取英文from sklearn.feature_extraction import DictVectorizertransfer = CountVectorizer() # 实例化 sparse 默认为Truedata = transfer.fit_transform(data) # 调用\n例如\ntransfer = CountVectorizer()data = transfer.fit_transform(data) # 调用fit_transform\n对于\ndata = [&quot;life is short,i like like python&quot;, &quot;life is too long,i dislike python&quot;]\n输出结果为\n\n文本特征抽取的结果：[[0 1 1 2 0 1 1 0][1 1 1 0 1 1 0 1]]返回特征名字：[‘dislike’, ‘is’, ‘life’, ‘like’, ‘long’, ‘python’, &gt; ‘short’, ‘too’]\n\n即对应字母在句子中出现的次数\n中文 jieba分词处理对于\ndata = [&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。&quot;,&quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;,&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;]\n对其进行\ntext_list = []for sent in data:    text_list.append(cut_word(sent))\ntext = &quot; &quot;.join(list(jieba.cut(text))) # 使用jieba对中文字符串进行分词\ntransfer = CountVectorizer() # 实例化转换器data = transfer.fit_transform(text_list)\n类似地得到\n文本特征抽取的结果：[[2 0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 1 0][0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 0 1][1 1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0 0]]返回特征名字：[&#x27;一种&#x27;, &#x27;不会&#x27;, &#x27;不要&#x27;, &#x27;之前&#x27;, &#x27;了解&#x27;, &#x27;事物&#x27;, &#x27;今天&#x27;, &#x27;光是在&#x27;, &#x27;几百万年&#x27;, &#x27;发出&#x27;,&#x27;取决于&#x27;, &#x27;只用&#x27;, &#x27;后天&#x27;, &#x27;含义&#x27;, &#x27;大部分&#x27;, &#x27;如何&#x27;, &#x27;如果&#x27;, &#x27;宇宙&#x27;, &#x27;我们&#x27;, &#x27;所以&#x27;, &#x27;放弃&#x27;, &#x27;方式&#x27;, &#x27;明天&#x27;, &#x27;星系&#x27;, &#x27;晚上&#x27;, &#x27;某样&#x27;, &#x27;残酷&#x27;, &#x27;每个&#x27;, &#x27;看到&#x27;, &#x27;真正&#x27;, &#x27;秘密&#x27;, &#x27;绝对&#x27;, &#x27;美好&#x27;, &#x27;联系&#x27;, &#x27;过去&#x27;, &#x27;还是&#x27;, &#x27;这样&#x27;]\nTf-idf文本特征提取能够自动获取关键词TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。可提取出更具有分类意义的词对于\ndata = [&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。&quot;,&quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;,&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;]\n对其进行\n# 使用jieba处理文本import jiebatext_list = []for sent in data:    text_list.append&quot; &quot;.join(list(jieba.cut(sent))))\nfrom sklearn.feature_extraction.text import TfidfVectorizertransfer = TfidfVectorizer(stop_words=[&#x27;一种&#x27;, &#x27;不会&#x27;, &#x27;不要&#x27;]) # 实例化转换器 stop为去掉的词?data = transfer.fit_transform(text_list)\n其结果为\n文本特征抽取的结果：[[ 0. 0. 0. 0.43643578 0. 0. 0.0. 0. 0.21821789 0. 0.21821789 0. 0.0. 0. 0.21821789 0.21821789 0. 0.436435780. 0.21821789 0. 0.43643578 0.21821789 0. 0.0. 0.21821789 0.21821789 0. 0. 0.218217890. ][ 0.2410822 0. 0. 0. 0.2410822 0.24108220.2410822 0. 0. 0. 0. 0. 0.0. 0.2410822 0.55004769 0. 0. 0. 0.0.2410822 0. 0. 0. 0. 0.482164410. 0. 0. 0. 0. 0.24108220. 0.2410822 ][ 0. 0.644003 0.48300225 0. 0. 0. 0.0.16100075 0.16100075 0. 0.16100075 0. 0.161000750.16100075 0. 0.12244522 0. 0. 0.161000750. 0. 0. 0.16100075 0. 0. 0.0.3220015 0.16100075 0. 0. 0.16100075 0. 0.0. ]]返回特征名字：[&#x27;之前&#x27;, &#x27;了解&#x27;, &#x27;事物&#x27;, &#x27;今天&#x27;, &#x27;光是在&#x27;, &#x27;几百万年&#x27;, &#x27;发出&#x27;, &#x27;取决于&#x27;, &#x27;只用&#x27;, &#x27;后天&#x27;,&#x27;含义&#x27;, &#x27;大部分&#x27;, &#x27;如何&#x27;, &#x27;如果&#x27;, &#x27;宇宙&#x27;, &#x27;我们&#x27;, &#x27;所以&#x27;, &#x27;放弃&#x27;, &#x27;方式&#x27;, &#x27;明天&#x27;, &#x27;星系&#x27;, &#x27;晚上&#x27;, &#x27;某样&#x27;, &#x27;残酷&#x27;, &#x27;每个&#x27;, &#x27;看到&#x27;, &#x27;真正&#x27;, &#x27;秘密&#x27;, &#x27;绝对&#x27;, &#x27;美好&#x27;, &#x27;联系&#x27;, &#x27;过去&#x27;, &#x27;还是&#x27;, &#x27;这样&#x27;]\n特征预处理归一化通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程将数据压缩至一个既定范围内使得特征都能被学习到\nsklearn.preprocessing.MinMaxScaler()\nimport pandas as pdfrom sklearn.preprocessing import MinMaxScalerdata = pd.read_csv(&quot;dating.txt&quot;)transfer = MinMaxScaler(feature_range=(2, 3)) # 实例化转换器类data = transfer.fit_transform(data[[&#x27;milage&#x27;, &#x27;Liters&#x27;, &#x27;Consumtime&#x27;]])\n标准化剔除异常值的影响适合目前大数据场景\nsklearn.preprocessing.StandardScaler( )\ntransfer = StandardScaler()data = transfer.fit_transform(data[[&#x27;milage&#x27;,&#x27;Liters&#x27;,&#x27;Consumtime&#x27;]])\n特征降维降维是指在某些限定条件下，降低随机变量(特征)个数，得到一组“不相关”主变量的过程降低随机变量的个数\nsklearn.feature_selection\n特征选择Filter过滤式主要探究特征本身特点、特征与特征和目标值之间关联方差选择法：低方差特征过滤\nsklearn.feature_selection.VarianceThreshold(threshold = 0.0) # 删除所有低方差特征\n使用例如\ntransfer = VarianceThreshold(threshold=1)data = transfer.fit_transform(data.iloc[:, 1:10])\niloc为指定位置 先行再列\n相关系数皮尔逊相关系数(Pearson Correlation Coefficient)\nfrom scipy.stats import pearsonrpearsonr(data[i], data[j])[0])) # 得到相关系数\n例如\ndata = pd.read_csv(&quot;factor_returns.csv&quot;)factor = [&#x27;pe_ratio&#x27;, &#x27;pb_ratio&#x27;, &#x27;market_cap&#x27;,&#x27;return_on_asset_net_profit&#x27;, &#x27;du_return_on_equity&#x27;, &#x27;ev&#x27;,&#x27;earnings_per_share&#x27;, &#x27;revenue&#x27;, &#x27;total_expense&#x27;]for i in range(len(factor)):    for j in range(i, len(factor) - 1):        print(&quot;指标%s与指标%s之间的相关性大小为%f&quot; % (factor[i], factor[j + 1],         pearsonr(data[factor[i]], data[factor[j + 1]])[0]))\n此处可使用图像进行观察revenue与total_expense的关系\nimport matplotlib.pyplot as pltplt.figure(figsize=(20, 8), dpi=100)plt.scatter(data[&#x27;revenue&#x27;], data[&#x27;total_expense&#x27;])plt.show()\n可得到其相关系数高可以进行合成\n主成分分析(PCA) PCA降维定义：高维数据转化为低维数据的过程，在此过程中可能会舍弃原有数据、创造新的变量作用：是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息。应用：回归分析或者聚类分析当中\nsklearn.decomposition.PCA(n_components = None)\n对于n_components：小数：表示保留百分之多少的信息整数：减少到多少特征例如\nfrom sklearn.decomposition import PCAtransfer = PCA(n_components = 0.9) # 保留90%的信息data1 = transfer.fit_transform(data)transfer2 = PCA(n_components=3) # 减少到3个特征data2 = transfer2.fit_transform(data)\n合并表import pandas as pdresult = pd.merge(csv1, csv2, on = [test1, test2]) # 将csv1中的tset1和csv2的test2在一张表中 按索引进行合并\nsklearn转换器和预估器转换器特征工程的接口称之为转换器有以下三种fit_transformfittransform其差别如以下\nIn [1]: from sklearn.preprocessing import StandardScalerIn [2]: std1 = StandardScaler()In [3]: a = [[1,2,3], [4,5,6]]In [4]: std1.fit_transform(a)Out[4]:array([[-1., -1., -1.],[ 1., 1., 1.]])In [5]: std2 = StandardScaler()In [6]: std2.fit(a)Out[6]: StandardScaler(copy=True, with_mean=True, with_std=True)In [7]: std2.transform(a)Out[7]:array([[-1., -1., -1.],[ 1., 1., 1.]])\n可知fit_transform的作用相当于transform加上fitfit方法可看作训练\n估计器sklearn机器学习算法的实现调用.fit()进行计算 生成model\\\n模型评估方法:1)直接对比真实值与预测值\\\ny_predict = estimator.predict(x_test)if y_test == y_predict\n2)利用公式计算\\\naccurary = estimator.score(x_test, y_test)\n分类算法KNN算法核心思想:根据邻居确定类别可能出现的问题:k过小容易收到异常点影响k过大容易收到样本不均匀影响需要做无量纲化处理——标准化\nsklearn.neighbors.KNeighborsClassifier(n_neighbors = 5, algorithm = &#x27;auto&#x27;)\n· n_neighbors：int,可选（默认&#x3D; 5），k_neighbors查询默认使用的邻居数· algorithm：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，可选用于计算最近邻居的算法：‘ball_tree’将会使用 BallTree，‘kd_tree’将使用 KDTree。‘auto’将尝试根据传递给fit方法的值来决定最合适的算法。 (不同实现方式影响效率)\n使用案例——鸢尾花分类-&gt; knn_demo.ipynb\n模型选择和调优交叉验证将拿到的训练数据，分为训练和验证集。以下图为例：将数据分成5份，其中一份作为验证集。然后经过5次(组)的测试，每次都更换不同的验证集。即得到5组模型的结果，取平均值作为最终结果。又称5折交叉验证。交叉验证目的：为了让被评估的模型更加准确可信\n超参数搜索——网格搜索获取最佳参数(超参数)-(如KNN中的K值)\\\nsklearn.model_selection.GridSearchCV(estimator, param_grid = None,cv = None)\n对估计器的指定参数值进行详尽搜索estimator：估计器对象param_grid：估计器参数(dict){“n_neighbors”:[1,3,5]}cv：指定几折交叉验证 类似epochfit：输入训练数据score：准确率输出结果为\nbestscore:在交叉验证中验证的最好结果bestestimator：最好的参数模型cvresults:每次交叉验证后的验证集准确率结果和训练集准确率结果\n例如\nknn = KNeighborsClassifier()param = &#123;&quot;n_neighbors&quot;: [3, 5, 10]&#125;gc = GridSearchCV(knn, param_grid=param, cv=2)gc.fit(x_train, y_train)print(&quot;选择了某个模型测试集当中预测的准确率为：&quot;, gc.score(x_test, y_test))# 训练验证集的结果print(&quot;在交叉验证当中验证的最好结果：&quot;, gc.best_score_)print(&quot;gc选择了的模型K值是：&quot;, gc.best_estimator_)print(&quot;每次交叉验证的结果为：&quot;, gc.cv_results_)\n朴素贝叶斯算法sklearn.naive_bayes.MultinomialNB(alpha = 1.0)朴素贝叶斯分类各结论之间相互独立 使用贝叶斯公式alpha：拉普拉斯平滑系数优点：朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。对缺失数据不太敏感，算法也比较简单，常用于文本分类。分类准确度高，速度快缺点：朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。对缺失数据不太敏感，算法也比较简单，常用于文本分类。分类准确度高，速度快\n决策树决策树class sklearn.tree.DecisionTreeClassifier(criterion = &#x27;gini&#x27;, max_depth=None, random_state=None)\ncriterion:默认是’gini’系数，也可以选择信息增益的熵’entropy’max_depth:树的深度大小random_state:随机数种子其中会有些超参数如max_depth:树的深度大小等优点：简单的理解和解释，树木可视化。可解释能力强缺点：决策树学习者可以创建不能很好地推广数据的过于复杂的树，这被称为过拟合。\n决策树可视化sklearn.tree.export_graphviz() 例如\ntree.export_graphviz(estimator,out_file=&#x27;tree.dot&#x27;,feature_names=[&quot;,&quot;])\n此处可使用graphviz工具进行树可视化ubuntu下使用sudo apt-get install graphviz Mac:brew install graphviz使用dot -Tpng tree.dot -o tree.png将dot转换为png或jpg\n随机森林包含多个决策树的分类器训练集随机 特征随机\nclass sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion = &#x27;gini&#x27;, max_depth = None, bootstrap = True, random_state = None, min_samples_split = 2)\nn_estimators：integer，optional（default &#x3D; 10）森林里的树木数量120,200,300,500,800,1200criteria：string，可选（default &#x3D;“gini”）分割特征的测量方法max_depth：integer或None，可选（默认&#x3D;无）树的最大深度 5,8,15,25,30max_features&#x3D;”auto”,每个决策树的最大特征数量If “auto”, then max_features&#x3D;sqrt(n_features) .If “sqrt”, then max_features&#x3D;sqrt(n_features) (same as “auto”).If “log2”, then max_features&#x3D;log2(n_features) .If None, then max_features&#x3D;n_features .bootstrap：boolean，optional（default &#x3D; True）是否在构建树时使用放回抽样min_samples_split:节点划分最少样本数min_samples_leaf:叶子节点的最小样本数其中存在超参数：n_estimator, max_depth, min_samples_split, min_samples_leaf优点：在当前所有算法中，具有极好的准确率能够有效地运行在大数据集上，处理具有高维特征的输入样本，而且不需要降维能够评估各个特征在分类问题上的重要性\n回归和聚类算法线性回归线性回归概念线性模型：自变量为一次或参数为一次但仅参数为一次非线性关系线性关系一定为线性模型线性模型不一定为线性关系\n优化算法正规方程公式求解缺点：当特征过多过复杂时，求解速度太慢并且得不到结果\n梯度下降面对训练数据规模十分庞大的任务 ，能够找到较好的结果\nAPI# 正规方程sklearn.linear_model.LinearRegression(fit_intercept = True)\nfit_intercept：是否计算偏置LinearRegression.coef_：回归系数LinearRegression.intercept_：偏置\n# 梯度下降sklearn.linear_model.SGDRegressor(loss = &quot;squared_loss&quot;, fit_intercept = True, learning_rate = &#x27;invscaling&#x27;, eta0=0.01)\nloss:损失类型loss&#x3D;”squared_loss”: 普通最小二乘法fit_intercept：是否计算偏置learning_rate : string, optional 学习率算法\n\n学习率填充：‘constant’: eta &#x3D; eta0‘optimal’: eta &#x3D; 1.0 &#x2F; (alpha * (t + t0)) [default]‘invscaling’: eta &#x3D; eta0 &#x2F; pow(t, power_t) power_t&#x3D;0.25:存在父类当中对于一个常数值的学习率来说，可以使用learning_rate&#x3D;’constant’ ，并使用eta0来指定学习率。\n\nSGDRegressor.coef_：回归系数SGDRegressor.intercept_：偏置\n性能评估sklearn.metrics.mean_squared_error(y_true, y_pred)\n\n均方误差回归损失y_true:真实值y_pred:预测值return:浮点数结果\n\n例如\ndef mylinearregression():&quot;&quot;&quot;线性回归预测房子价格:return:&quot;&quot;&quot;lb = load_boston()# print(lb.data)# print(lb.target)# 对数据集进行划分x_train, x_test, y_train, y_test = train_test_split(lb.data, lb.target,test_size=0.3, random_state=24)# 需要做标准化处理对于特征值处理std_x = StandardScaler()x_train = std_x.fit_transform(x_train)x_test = std_x.fit_transform(x_test)# print(x_train)# 对于目标值进行标准化std_y = StandardScaler()y_train = std_y.fit_transform(y_train)y_test = std_y.transform(y_test)y_test = std_y.inverse_transform(y_test)# 使用线性模型进行预测# 使用正规方程求解lr = LinearRegression()# # 此时在干什么？lr.fit(x_train, y_train)y_lr_predict = std_y.inverse_transform(lr.predict(x_test))print(lr.coef_)print(&quot;正规方程预测的结果为：&quot;, y_lr_predict)print(&quot;正规方程的均方误差为：&quot;, mean_squared_error(y_test, y_lr_predict))# 梯度下降进行预测sgd = SGDRegressor()sgd.fit(x_train, y_train)print(&quot;SGD的权重参数为：&quot;, sgd.coef_)y_sgd_predict = std_y.inverse_transform(sgd.predict(x_test))print(&quot;SGD的预测的结果为：&quot;, y_sgd_predict)print(&quot;SGD的均方误差为：&quot;, mean_squared_error(y_test, y_sgd_predict))\n\n欠拟合和过拟合概念欠拟合一个假设在训练数据上能够获得比其他假设更好的拟合， 但是在测试数据集上却不能很好地拟合数据，此时认为这个假设出现了过拟合的现象。(模型过于复杂)\n过拟合一个假设在训练数据上不能获得更好的拟合，并且在测试数据集上也不能很好地拟合数据，此时认为这个假设出现了欠拟合的现象。(模型过于简单)\n解决正则化L2正则化 - 更常用\n\n作用：可以使得其中一些W的都很小，都接近于0，削弱某个特征的影响优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象Ridge回归 岭回归\n\nL1正则化\n\n作用：可以使得其中一些W的值直接为0，删除这个特征的影响LASSO回归\n\n岭回归带L2正则化的线性回归\nsklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True,solver=&quot;auto&quot;, normalize=False)\n\nalpha:正则化力度 也叫λ λ取值：01 110solver:会根据数据自动选择优化方法 sag:如果数据集、特征都比较大，选择该随机梯度下降优化normalize:数据是否进行标准化normalize&#x3D;False:可以在fit之前调用preprocessing.StandardScaler标准化数据Ridge.coef_:回归权重Ridge.intercept_:回归偏置\n\n逻辑回归(分类算法)逻辑回归概念逻辑回归是一种分类算法，虽然名字中带有回归，但是它与回归之间有一定的联系。由于算法的简单和高效，在实际中应用非常广泛。利于解决二分类问题线性回归的输出作为逻辑回归的输入\nsigmoid激活函数回归的结果输入到sigmoid函数当中输出结果：[0, 1]区间中的一个概率值，默认为0.5为阈值\n\n逻辑回归最终的分类是通过属于某个类别的概率值来判断是否属于某个类别，并且这个类别默认标记为1(正例),另外的一个类别会标记为0(反例)。（方便损失计算）\n\n\n输出结果解释(重要)：假设有两个类别A，B，并且假设我们的概率值为属于A(1)这个类别的概率值。现在有一个样本的输入到逻辑回归输出结果0.6，那么这个概率值超过0.5，意味着我们训练或者预测的结果就是A(1)类别。\n\n对数似然损失APIsklearn.linear_model.LogisticRegression(solver = &#x27;liblinear&#x27;, penalty=‘l2’, C = 1.0)\n\nsolver:优化求解方式（默认开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数） sag：根据数据集自动选择，随机平均梯度下降penalty：正则化的种类C：正则化力度\n\n代码举例def logisticregression():&quot;&quot;&quot;逻辑回归进行癌症预测:return: None&quot;&quot;&quot;# 1、读取数据，处理缺失值以及标准化column_name = [&#x27;Sample code number&#x27;, &#x27;Clump Thickness&#x27;, &#x27;Uniformity of CellSize&#x27;, &#x27;Uniformity of Cell Shape&#x27;,&#x27;Marginal Adhesion&#x27;, &#x27;Single Epithelial Cell Size&#x27;, &#x27;BareNuclei&#x27;, &#x27;Bland Chromatin&#x27;,&#x27;Normal Nucleoli&#x27;, &#x27;Mitoses&#x27;, &#x27;Class&#x27;]data = pd.read_csv(&quot;https://archive.ics.uci.edu/ml/machine-learning\u0002databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;, names=column_name)# 删除缺失值data = data.replace(to_replace=&#x27;?&#x27;, value=np.nan)data = data.dropna()# 取出特征值x = data[column_name[1:10]]y = data[column_name[10]]# 分割数据集x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)# 进行标准化std = StandardScaler()x_train = std.fit_transform(x_train)x_test = std.transform(x_test)# 使用逻辑回归lr = LogisticRegression()lr.fit(x_train, y_train)print(&quot;得出来的权重：&quot;, lr.coef_)# 预测类别print(&quot;预测的类别：&quot;, lr.predict(x_test))# 得出准确率print(&quot;预测的准确率:&quot;, lr.score(x_test, y_test))return None\n分类的评估方法精确率与召回率混淆矩阵精确率(Precision)与召回率(Recall)精确率：预测结果为正例样本中真实为正例的比例（了解）召回率(查全率)：真实为正例的样本中预测结果为正例的比例（查的全，对正样本的区分能力）\nF1-score 反应模型稳健型分类评估报告APIsklearn.metrics.classification_report(y_true, y_pred, labels = [], target_names = None)\n\ny_true：真实目标值y_pred：估计器预测目标值labels:指定类别对应的数字target_names：目标类别名称return：每个类别精确率与召回率\n\n例如\nprint(&quot;精确率和召回率为：&quot;, classification_report(y_test, lr.predict(x_test), labels=[2, 4], target_names = [&#x27;良性&#x27;, &#x27;恶性&#x27;]))\nROC曲线与AUC指标ROC曲线ROC曲线的横轴就是FPRate，纵轴就是TPRate，当二者相等时，表示的意义则是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的，此时AUC为0.5\nAUC指标AUC只能用来评价二分类AUC非常适合评价样本不平衡中的分类器性能\nAUC的概率意义是随机取一对正负样本，正样本得分大于负样本的概率AUC的最小值为0.5，最大值为1，取值越高越好AUC&#x3D;1，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。\n\n最终AUC的范围在[0.5, 1]之间，并且越接近1越好\n\nAUC计算APIfrom sklearn.metrics import roc_auc_scoresklearn.metrics.roc_auc_score(y_true, y_score)\n\n计算ROC曲线面积，即AUC值y_true:每个样本的真实类别，必须为0(反例),1(正例)标记y_score:每个样本预测的概率值\n\n例如\n# 0.5~1之间，越接近于1约好y_test = np.where(y_test &gt; 2.5, 1, 0)print(&quot;AUC指标：&quot;, roc_auc_score(y_test, lr.predict(x_test)))\n\n模型保存与加载from sklearn.externals import joblib# 保存joblib.dump(rf, &#x27;test.pkl&#x27;)# 加载estimator = joblib.load(&#x27;test.pkl&#x27;)\n例如\n# 使用线性模型进行预测# 使用正规方程求解lr = LinearRegression()# 此时在干什么？lr.fit(x_train, y_train)# 保存训练完结束的模型joblib.dump(lr, &quot;test.pkl&quot;)\n及\n# 通过已有的模型去预测房价model = joblib.load(&quot;test.pkl&quot;)print(&quot;从文件加载进来的模型预测房价的结果：&quot;,std_y.inverse_transform(model.predict(x_test)))\n\n无监督学习 k-means算法特点分析：采用迭代式算法，直观易懂并且非常实用缺点：容易收敛到局部最优解(多次聚类)\nk-means算法聚类步骤1、随机设置K个特征空间内的点作为初始的聚类中心2、对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别3、接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）4、如果计算得出的新中心点与原中心点一样，那么结束，否则重新进行第二步过程\nAPIsklearn.cluster.KMeans(n_clusters=8,init=‘k-means++’)\n\nk-means聚类n_clusters:开始的聚类中心数量init:初始化方法，默认为’k-means ++’labels_:默认标记的类型，可以和真实值比较（不是值比较）\n\nKmeans性能评估指标轮廓系数及轮廓系数值分析如果b_i&gt;&gt;a_i:趋近于1效果越好， b_i &lt;&lt; a_i:趋近于-1，效果不好。轮廓系数的值是介于 [-1,1] ，越趋近于1代表内聚度和分离度都相对较优。\n轮廓系数APIsklearn.metrics.silhouette_score(X, labels)\n计算所有样本的平均轮廓系数X：特征值labels：被聚类标记的目标值\n用户聚类结果评估silhouette_score(cust, pre)\n\n使用数据处理方法缩小数据范围使用query()方法进行数据挑选如\ndata = data.query(&quot;x &lt; 2.5 &amp; x &gt; 2 &amp; y &lt; 1 &amp; 1&quot;)\n处理时间特征使用pd.to_datatime()如\ntime_value = pd.to_datatime(data[&quot;time&quot;], unit = &quot;s&quot;)\nunit为单位 此处为秒\n为了方便得到时间 可使用pd.DatetimeIndex()例如\ndate = pd.DatetimeIndex(time_value)\n\n分组并统计使用groupby().count()例如\ncount = data.groupby(&quot;place_id&quot;).count()\n对place_id进行统计\n布尔索引place_count[place_count &gt; 3]\n","categories":["学习笔记"],"tags":["机器学习","人工智能","Sklearn"]},{"title":"深度学习-Pytorch","url":"/2023/03/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Pytorch/","content":"此为本人学习深度学习及Pytorch基础知识时所作，可能存在部分错误之处，敬请谅解。\nTensorBoard代码from torch.utils.tensorboard import SummaryWriterimport cv2writer = SummaryWriter(&quot;logs&quot;) # 创建实例，将事件文件储存到logs文件夹下img_path = &quot;./training_dataset/train/ants_image/0013035.jpg&quot;img = cv2.imread(img_path)img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)writer.add_image(&quot;test&quot;, img, 1, dataformats = &quot;HWC&quot;) # 图像工具for i in range(100):    writer.add_scalar(&quot;y = 3x&quot;, 3*i, i) # 画函数工具writer.close()\n其中，对writer.add_image(&quot;test&quot;, img, 1, dataformats = &quot;HWC&quot;) 1为步数，dataformats为格式\nTerminaltensorboard --logdir=logs# 其中logdir=事件文件所在文件夹名\n输出内容为TensorBoard 2.10.0 at http://localhost:6006/ (Press CTRL+C to quit)表示在端口6006训练\\\n可用tensorboard --logdir=logs --port=6007指定端口\nTransForms代码from torchvision import transformsimg_path = &quot;./training_dataset/train/ants_image/0013035.jpg&quot;img = Image.open(img_path)# Totensortrans_totensor = transforms.ToTensor() # 创建对应工具tensor_img = trans_totensor(img) # 转化为tensor数据类型writer.add_image(&quot;ToTensor&quot;, tensor_img)# Normalizetrans_norm = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])img_norm = trans_norm(tensor_img) # 归一化writer.add_image(&quot;Normalize&quot;, img_norm)# Resizetrans_resize = transforms.Resize((512, 512))img_resize = trans_resize(img)img_resize = trans_totensor(img_resize) # 改变大小writer.add_image(&quot;Resize&quot;, img_resize, 0)# Compose - resize - 2trans_resize_2 = transforms.Resize(512)trans_compose = transforms.Compose([trans_resize_2, trans_totensor])img_resize_2 = trans_compose(img) # 按比例改变大小writer.add_image(&quot;Resize2&quot;, img_resize_2, 0)# RandomCroptrans_random = transforms.RandomCrop(512) # 括号内用于指定大小，可分别指定长宽trans_conpose_2 = transforms.Compose([trans_random, trans_totensor])for i in range(10):    img_crop = trans_conpose_2(img)    writer.add_image(&quot;RandomCrop&quot;, img_crop, i) # 随机裁剪writer.close()\n\ntorchvision官方数据集下载train_data = torchvision.datasets.CIFAR10(root = &quot;./dataset_test&quot;, train = True, transform = dataset_transform, download = True)test_set = torchvision.datasets.CIFAR10(root = &quot;./dataset_test&quot;, train = False, transform = dataset_transform, download = True)\nroot为本地下载存放地址train为True为下载训练集 为False为下载测试集transform为图片转化的工具 如dataset_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])download为是否下载该数据集\n数据集内容 例img, target = test_set[0]\n对应输出为(&lt;PIL.Image.Image image mode=RGB size=32x32 at 0x106B06F4E50&gt;, 3)(此处前部分为不经过transform进行变换的默认PIL格式照片)前部分为图片，后部分为该图片对应的对象在classes(test_set.classes)中的下标若为\ntest_set.classes[target]\n则输出对应为cat\ndataloader数据加载器\ntest_loader = DataLoader(dataset = test_data, batch_size = 4, shuffle = True, num_workers = 0, drop_last = False)\ndataset为指定数据集(测试集)batch_size为指定每次从dataset中去除n个数据进行打包shuffle若为True则每次训练会打乱顺序 一般为Truenum_work为主进程数量drop_last为保存最后一次取的数据\n代码# 准备测试集test_data = torchvision.datasets.CIFAR10(root = &quot;./dataset_test&quot;, train = False, transform = torchvision.transforms.ToTensor())test_loader = DataLoader(dataset = test_data, batch_size = 4, shuffle = True, num_workers = 0, drop_last = False)# 测试集中第一张照片及targetimg, target = test_data[0]# 得到总的imgs与targetswriter = SummaryWriter(&quot;dataloader_logs&quot;)step = 0for data in test_loader:    imgs, targets = data    writer.add_images(&quot;test_data&quot;, imgs, step)    step += 1writer.close()\n\nconvolution functional卷积层 代码import torchimport torch.nn.functional as F # 卷积函数input = torch.tensor([[1, 2, 0, 3, 1],                      [0, 1, 2, 3, 1],                      [1, 2, 1, 0, 0],                      [5, 2, 3, 1, 1],                      [2, 1, 0, 1, 1]])    kernel = torch.tensor([[1, 2, 1],                       [0, 1, 0],                       [2, 1, 0]])input = torch.reshape(input,(1, 1, 5, 5)) # 更改尺寸为(1, 1, 5, 5)kernel = torch.reshape(kernel,(1, 1, 3, 3)) # 更改尺寸为(1, 1, 3, 3)output = F.conv2d(input, kernel, stride = 1, padding = 0)print(output)\n对于torch.reshape(input,(1, 1, 5, 5))shape为四通道第一位为channel通道数量第二位为输入channel&#x2F;group(batch_size)三四位分别为高和宽及有dilation 空洞卷积\nF.conv2d意为二维卷积stride为卷积核移动步数，padding为填充情况\nconv2d小历程import torchimport torchvisionfrom torch.utils.data import DataLoaderfrom torch import nnfrom torch.nn import Conv2dfrom torch.utils.tensorboard import SummaryWriterimport cv2dataset = torchvision.datasets.CIFAR10(&quot;./conv2d_dataset&quot;, train = False, transform = torchvision.transforms.ToTensor(),download = True)dataloader = DataLoader(dataset, batch_size = 64)class Fun(nn.Module):    def __init__(self):        super(Fun, self).__init__()        self.conv1 = Conv2d(in_channels = 3, out_channels = 6, kernel_size = 3, stride = 1, padding = 1)    def forward(self, x):        x = self.conv1(x)        return xtest = Fun()writer = SummaryWriter(&quot;con2d_logs&quot;)step = 0for data in dataloader:    imgs, targets = data    output = test(imgs)    writer.add_images(&quot;input&quot;, imgs, step)    output = torch.reshape(output, (-1, 3, 32, 32))    writer.add_images(&quot;output&quot;,output, step)    step += 1\n将数据集中的图片进行卷积操作，即卷积层\n池化层最大池化import torchfrom torch import nnimport torchvisionfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterdataset = torchvision.datasets.CIFAR10(&quot;maxpool_data&quot;, train = False, download = True, transform = torchvision.transforms.ToTensor())dataLoader = DataLoader(dataset, batch_size= 64)class Test(nn.Module):    def __init__(self):        super(Test, self).__init__()        self.maxpool1 = nn.MaxPool2d(kernel_size = 3, ceil_mode = True)    def forward(self,input):        output = self.maxpool1(input)        return outputtest = Test()step = 0writer = SummaryWriter(&quot;maxpool_logs&quot;)for data in dataLoader:    imgs, targets = data    writer.add_images(&quot;input&quot;, imgs, step)    output = test(imgs)    writer.add_images(&quot;output&quot;, output, step)    step += 1\n其中self.maxpool1 = nn.MaxPool2d()(kernel_size = 3, ceil_mode = True)中的ceil_mode 为补全，为True即当kernel加载到不满九个数据的位置时仍然计\n池化可以缩减目标空间 增加运行速度\n非线性激活import torchimport torchvisionfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterdataset = torchvision.datasets.CIFAR10(&quot;maxpool_data&quot;, train = False, download = True, transform = torchvision.transforms.ToTensor())dataloader = DataLoader(dataset, batch_size = 64)class test(torch.nn.Module):    def __init__(self):        super(test, self).__init__()        self.relu1 = torch.nn.ReLU()        self.sigmoid1 = torch.nn.Sigmoid()    def forward(self, input):        output = self.relu1(input)        return outputtest = test()writer = SummaryWriter(&quot;relu_logs&quot;)step = 0for  data in dataloader:    imgs, targets = data    writer.add_images(&quot;input&quot;, imgs, step)    output = test(imgs)    writer.add_images(&quot;output&quot;, output, step)    step += 1writer.close()\n\n线性层from modulefinder import Moduleimport torchvisionfrom torch.utils.data import DataLoaderimport torchdataset = torchvision.datasets.CIFAR10(&quot;maxpool_data&quot;, train = False, download = True, transform = torchvision.transforms.ToTensor())dataloader = DataLoader(dataset, batch_size = 64)class test(torch.nn.Module):    def __init__(self):        super(test, self).__init__()        self.linear1 = torch.nn.Linear(196608, 10)    def forward(self, input):        output = self.linear1(input)        return outputtest = test()for data in dataloader:    imgs, targets = data    print(imgs.shape)    # output = torch.reshape(imgs, (1, 1, 1, -1))    output = torch.flatten(imgs) # 将矩阵展开成一行    print(output.shape)    output = test(output)    print(output.shape)\n也作为全连接层？\nSequential及网络搭建小历程import torchfrom torch.utils.tensorboard import SummaryWriterclass test(torch.nn.Module):    def __init__(self):        super(test, self).__init__()        # self.conv1 = torch.nn.Conv2d(3, 32, 5, padding = 2)        # self.maxpool1 = torch.nn.MaxPool2d(2)        # self.conv2 = torch.nn.Conv2d(32, 32, 5, padding = 2)        # self.maxpool2 = torch.nn.MaxPool2d(2)        # self.conv3 = torch.nn.Conv2d(32, 64, 5, padding = 2)        # self.maxpool3 = torch.nn.MaxPool2d(2)        # self.flatten = torch.nn.Flatten()        # self.linear1 = torch.nn.Linear(1024, 64)        # self.linear2 = torch.nn.Linear(64, 10)        self.model1 = torch.nn.Sequential(                                torch.nn.Conv2d(3, 32, 5, padding = 2),                                torch.nn.MaxPool2d(2),                                torch.nn.Conv2d(32, 32, 5, padding = 2),                                torch.nn.MaxPool2d(2),                                torch.nn.Conv2d(32, 64, 5, padding = 2),                                torch.nn.MaxPool2d(2),                                torch.nn.Flatten(),                                torch.nn.Linear(1024, 64),                                torch.nn.Linear(64, 10)                                )    def forward(self, x):        # x = self.conv1(x)        # x = self.maxpool1(x)        # x = self.conv2(x)        # x = self.maxpool2(x)        # x = self.conv3(x)        # x = self.maxpool3(x)        # x = self.flatten(x)        # x = self.linear1(x)        # x = self.linear2(x)        x = self.model1(x)        return xtest = test()print(test)input = torch.ones((64, 3, 32, 32))output = test(input)print(output.shape)write = SummaryWriter(&quot;seq_logs&quot;)write.add_graph(test, input) # 输出运行的树图write.close()\n\n损失函数inputs = torch.tensor([1, 2, 3], dtype = torch.float32)targets = torch.tensor([1, 2, 5], dtype = torch.float32)inputs = torch.reshape(input, (1, 1, 1, 3))targets = torch.reshape(targets, (1, 1, 3, 1))loss = torch.nn.L1loss(reduction = &#x27;sum&#x27;)result = loss(inputs, targets)","categories":["学习笔记"],"tags":["计算机视觉","深度学习","Pytorch","人工智能"]},{"title":"Conda-常用指令","url":"/2023/03/22/Conda-%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/","content":"conda 环境管理创建环境conda create -n name python=3.x\n\nname为环境名3.x为指定python版本\n\n删除环境conda remove -n name --all\n\n激活环境conda activate name\n\n关闭环境 返回默认环境conda deactivate name\n\n查看当前有哪些环境conda info -e\n或\nconda env list\nconda包管理查看当前环境的包conda list\n\n安装指定package到当前环境conda install package\n\npackage 为所需包名字 可在后加入==指定版本或输入url指定安装源\n\n也可以使用pip等进行安装\n安装package到指定的环境conda install -n name package\n\n更新packageconda update -n name package\n\n移除packageconda remove -n name package\n或\nconda uninstall package\n\nconda版本更新conda版本conda update conda\n\n更新python版本conda update python\n\n假设当前环境是python 3.6 执行命令后conda会将python升级为3.6.x系列的当前最新版本\n\n","categories":["环境配置及相关工具"],"tags":["Conda","Python"]},{"title":"在树莓派上安装Ros","url":"/2023/04/09/%E5%9C%A8%E6%A0%91%E8%8E%93%E6%B4%BE%E4%B8%8A%E5%AE%89%E8%A3%85Ros/","content":"\n参考自https://blog.csdn.net/Kevin555666888/article/details/107207719 \n\n换源\n若源可用或源没问题可不换\n\n更换源信息\n以下为中科大源\n\nsudo sh -c &#x27;. /etc/lsb-release &amp;&amp; echo &quot;deb http://mirrors.ustc.edu.cn/ros/ubuntu/ $DISTRIB_CODENAME main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list&#x27;\n设置keysudo apt-key adv --keyserver &#x27;hkp://keyserver.ubuntu.com:80&#x27; --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654\n进行更新sudo apt-get updatesudo apt-get upgrade\n安装ROSsudo apt-get install ros-melodic-desktop-full\n\n若在此处报错可能是源出了问题 可不断使用sudo apt-get update 和 sudo apt-get upgrade进行更新或更换网络\n\n安装ROS依赖sudo rosdep initrosdep update\n\n若显示rosdep不是内部命令 则\nrosdep update\n\n\n我在安装此处的时候出现的比较诡异的报错\nERROR: cannot download default sources list from:https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/sources.list.d/20-default.listWebsite may be down.\n看过别人的解决(来自https://mp.weixin.qq.com/s/VGs8oWdhHH6XsHcx21lN4Q)\\ 方法如下安装\nsudo pip install rosdepc\n若没有显示pip则可尝试\nsudo apt-get install python3-pip \n如果还是没有 则\nsudo apt-get install python3-pip sudo pip install rosdepc\n在这之后再次运行 应该可用解决\nsudo rosdepc initrosdepc update\n\n和前面的差别是rosdep换成了rosdepc是一个国内大佬做的\n至此 完美解决问题\n\n添加环境变量echo &quot;source /opt/ros/melodic/setup.bash&quot; &gt;&gt; ~/.bashrcsource ~/.bashrc\n安装便利工具sudo apt install python-rosinstall python-rosinstall-generator python-wstool build-essential\n\n验证安装——运行实例\n打开第一个终端 输入：roscore打开第二个终端 输入：rosrun turtlesim turtlesim_node此时会打开一个有一个乌龟的窗口打开第三个终端 输入：rosrun turtlesim turtle_teleop_key选择第三个终端 然后按键盘上的方向键就可以控制小乌龟运动了。\n\n\n如果此时乌龟动起来了 表明安装成功\n\n","categories":["环境配置及相关工具"],"tags":["树莓派","Ros"]},{"title":"Ubuntu22.04换源","url":"/2023/04/09/Ubuntu22.04%E6%8D%A2%E6%BA%90/","content":"\n此为由20.04直接copy而来 未经验证\n\n备份环境变量文件sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak\n\nsources.list 即储存环境变量的文件\n\n更换源sudo vim /etc/apt/sources.list\n\n进入文件后按i或insert启动输入模式 删除原有内容\n\n\n可在进入输入模式前在航首按dd删除当前行 或dG删除光标以后所有内容\n\n删除内容后使用新源进行替换\n阿里源\ndeb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse\n清华源\ndeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse\n中科大源\ndeb https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse\n网易163源\ndeb http://mirrors.163.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiverse\n\n还源完成后\nsudo apt-get updatesudo apt-get upgrade\n让计算机根据源进行更新\n","tags":["Ubuntu22.04","Ubuntu"]},{"title":"git的安装配置","url":"/2023/04/10/git%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","content":"git的安装Windows可在官方网站上下载，网站：https://git-scm.com/\\ 也可在国内镜像源下载，网站：http://npm.taobao.org/mirrors/git-for-windows \nUbuntusudo apt-get updatesudo apt-get upgradesudo apt-get install git\ngithub账号的注册进入github，注册账号，网站：https://github.com/ \n\n在此处要注意记住你注册时的用户名和邮箱\n\ngit的配置找到git命令行输入处方法1-Windows在文件夹中右键，点击 git bash ，没有也没关系，很可能会没有\n方法2-Windows按 win+r 后输入 cmd （在默认路径下呼出）或 在你的目标文件夹下点击上面的框，输入 cmd 然后回车可以在当前路径下呼出 cmd \n方法3-Ubuntu直接在终端中输入 git 命令即可\n配置用户名在命令行中输入\ngit config --global user.name &quot;username&quot;\n\n此处 username 是自己的用户名\n\n配置邮箱在命令行中输入\ngit config --global user.email &quot;username@email.com&quot;\n\n此处 username@email.com 是自己的邮箱\n\n验证配置在命令行中输入\ngit config --global --list \n\n输出内容可以检查你的配置信息是否争取，如有误可以回到前面的配置步骤进行更改\n\n至此，git下载及配置完成\ngit常用命令的学习推荐一个教程网站：https://learngitbranching.js.org/?locale=zh_CN \n","categories":["环境配置及相关工具"],"tags":["git"]},{"title":"启动virtualbox虚拟机发生错误警告","url":"/2023/04/10/%E5%90%AF%E5%8A%A8virtualbox%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8F%91%E7%94%9F%E9%94%99%E8%AF%AF%E8%AD%A6%E5%91%8A/","content":"\n部分问题解决参考自 https://blog.csdn.net/m0_53688587/article/details/125074012 \n\n问题启动virtualbox虚拟机显示Attempted to kill the idle task错误 如下\n问题解决这个问题我出现过两次\n第一次第一次出现这个问题是在刚装 WSL2 后的一段时间，突然的改变让我意识到可能是 WSL2 的安装出了问题\n排除 WSL2 或虚拟机本身问题后查了很多问题 最后发现大部分问题原因出在 hyper-v 的设置上只需启动或关闭 hyper-v 服务即可解决问题\n\n在“控制面板”中，打开“程序和功能” 选择“启用或关闭 Windows 功能” 展开 Hyper-V ，展开 Hyper-V 平台 ，然后清除“Hyper-V 虚拟机监控程序” 复选框。\n\n第二次当我第二次发现这个问题时，距离上次使用虚拟机已经过去和很长时间了，于是我按照第一次的经验，熟练的进行操作耶？竟然不管用于是，我有又开始疯狂查，最后，发现似乎是分配到cpu和内存资源不够解决的操作如下\n\n在 virtualbox 界面下，进入设置，找到系统设置中的处理器分配，把处理器数量加到2及以上，为了放心，我还在下方的显示窗口中将显存分配提高到32以上，至此，问题解决。\n\n\n\n虽然感觉可能问题的解决是在我先前关闭 hyper-v 有关，但增加处理器数和显存分配大小确实解决了我的问题 如果只进行了一般的操作，问题还是没解决，可用参考我的两次经历来回试试看\n\n","categories":["环境配置及相关工具"],"tags":["Ubuntu20.04","Ubuntu22.04","Ubuntu","虚拟机","virtualbox"]},{"title":"Ubuntu自启动脚本","url":"/2023/05/08/Ubuntu%E8%87%AA%E5%8A%A8%E8%84%9A%E6%9C%AC/","content":"任务背景任务背景为在Jetson Orin Nano上使用t265时，需要同时按序开启并执行三个不同终端如下\nroslaunch realsense2_camera rs_t265.launch\n添加权限sudo chmod 777 /dev/ttyAMA0roslaunch mavros acfly.launch fcu_url:=/dev/ttyUSB0:57600\n打开t265文件夹，打开终端source devel/setup.bashroslaunch vision_to_mavros t265_tf_to_mavros.launch\n脚本的写法使用\nsh1 = &quot;/home/c/Library/Cv_for_Orinnano/utils/bash/T265_Start_1.sh&quot;subprocess.Popen([&#x27;gnome-terminal&#x27;, &#x27;--&#x27;, &#x27;bash&#x27;, &#x27;-c&#x27;, sh1, &#x27;--hold&#x27;],                 stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)# sh1为需要在该终端执行的命令\n其中sh1为事先写好的bash脚本，例如\n#!/bin/bash roslaunch realsense2_camera rs_t265.launch\n若有若干命令需要在同一终端中执行，则为\nsh2s = [&quot;echo 123456 | sudo -S chmod +x /home/c/Library/Cv_for_Orinnano/utils/bash/T265_Start_2.sh&quot;,        &quot;sudo chmod 777 /dev/ttyUSB0&quot;,         &quot;/home/c/Library/Cv_for_Orinnano/utils/bash/T265_Start_2.sh&quot;]sh2 = &quot;bash -c &#x27;&#123;&#125;&#x27;&quot;.format(&quot;; &quot;.join(sh2s))subprocess.Popen([&#x27;gnome-terminal&#x27;, &#x27;--&#x27;, &#x27;bash&#x27;, &#x27;-c&#x27;, sh2, &#x27;--hold&#x27;],                 stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n需要注意的是：在一个终端中执行的需要放在同一个中，不能使用 os.system ，使用  os.system 则会回到最初始的终端中执行subprocess.Popen 创建的终端，若终端执行结束或出现报错，则该终端会被杀死消失，可使用 --hold 使其保持开启\n\n所以我的最终启动脚本为\ndef T265_Start():    sh1 = &quot;/home/c/Library/Cv_for_Orinnano/utils/bash/T265_Start_1.sh&quot;    sh2s = [&quot;echo 123456 | sudo -S chmod +x /home/c/Library/Cv_for_Orinnano/utils/bash/T265_Start_2.sh&quot;,            &quot;sudo chmod 777 /dev/ttyUSB0&quot;,             &quot;/home/c/Library/Cv_for_Orinnano/utils/bash/T265_Start_2.sh&quot;]    sh2 = &quot;bash -c &#x27;&#123;&#125;&#x27;&quot;.format(&quot;; &quot;.join(sh2s))    sh3 = &quot;/home/c/Library/Cv_for_Orinnano/utils/bash/T265_Start_3.sh&quot;    subprocess.Popen([&#x27;gnome-terminal&#x27;, &#x27;--&#x27;, &#x27;bash&#x27;, &#x27;-c&#x27;, sh1, &#x27;--hold&#x27;],                     stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)    time.sleep(5)    subprocess.Popen([&#x27;gnome-terminal&#x27;, &#x27;--&#x27;, &#x27;bash&#x27;, &#x27;-c&#x27;, sh2, &#x27;--hold&#x27;],                     stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)    time.sleep(5)    subprocess.Popen([&#x27;gnome-terminal&#x27;, &#x27;--&#x27;, &#x27;bash&#x27;, &#x27;-c&#x27;, sh3, &#x27;--hold&#x27;],                     stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)    time.sleep(5)\n自启动的设置","categories":["环境配置及相关工具"],"tags":["Ubuntu","Jetson Orin Nano"]},{"title":"vnc远程连接jetson","url":"/2023/05/10/vnc%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5jetson/","content":"\n事件背景为使用 windows 端的 vnc viewer 远程连接 jetson orin nano\n\n在nano端安装 vncserversudo apt-get install vncserver\n\n开启vncserver在nano终端使用\nvncserver\n或\nvncserver -geometry 1366x768 :1 # geometry设置vnc屏幕的大小，1为端口\n按照要求设置好密码后，会出现如下\n\n图示为在端口1开启\n\n使用\nps -ef | grep -i vnc\n即可查询在使用vnc的进程\n远程连接打开 windows 端的 vnc，在上方输入 ip:端口号 ，如192.168.1.1:1\n出现的问题一报错如下The connection was refused by the computer\n解决\n原因为nano端的vncserver没开，在终端输入\n\nvncserver\n或\nvncserver -geometry 1366x768 :1 # geometry设置vnc屏幕的大小，1为端口\n重启 windows 的 vnc 即可\n出现问题二报错屏幕显示灰色并且鼠标是×型符号 下方出现unencrypted connection\n解决方式关闭端口vncserver -kill :1# kill 端口为1的进程，注意:1前面要加空格\n修改配置文件打开配置文件\ngedit ~/.vnc/xstartup# 打开配置文件\n修改配置文件为\n#!/bin/sh# Uncomment the following two lines for normal desktop:# unset SESSION_MANAGER# exec /etc/X11/xinit/xinitrc[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresourcesxsetroot -solid greyvncconfig -iconic &amp;x-terminal-emulator -geometry 80x24+10+10 -ls -title &quot;$VNCDESKTOP Desktop&quot; &amp;x-window-manager &amp;#gnome-terminal &amp;sesion-manager &amp; xfdesktop &amp; xfce4-panel &amp;xfce4-menu-plugin &amp;xfsettingsd &amp;xfconfd &amp;xfwm4 &amp;\n之后再打开vnc即可解决\n","categories":["环境配置及相关工具"],"tags":["Ubuntu","Jetson Orin Nano","VNC","远程连接"]},{"title":"acfly-mavros","url":"/2023/06/28/acfly-mavros/","content":"\n此为为Jetson配置Intel T265，以此为acfly飞控提供定位官方参考教程：realsense-ros      acfly-mavros \n\nROS Wrapper\nT265使用所需的packages\n\n安装 ROS\nInstall ROS Kinetic  on Ubuntu 16.04, ROS Melodic  on Ubuntu 18.04, ROS Noetic  on Ubuntu 20.04.可参考autolabor的安装教程 \n\n安装realsense2_camerarealsense2_camera 可作为 ROS 发行版的 debian 软件包使用\nsudo apt-get install ros-$ROS_DISTRO-realsense2-camera\n\n安装mavrossudo apt-get install python-catkin-tools python-rosinstall-generator -y# 如果用的ROS版本是Noetic则使用# sudo apt install python3-catkin-tools python3-rosinstall-generator python3-osrf-pycommon -y# 需要替换你的ROS版本，且以下指令需要在同一个终端执行source /opt/ros/$&#123;你的ROS版本&#125;/setup.bash# 因为acfly增加了自定义mavlink信息，若之前有通过二进制安装过mavros则需要卸载，没有则跳过sudo apt purge ros-$&#123;ROS_DISTRO&#125;-mavlink ros-$&#123;ROS_DISTRO&#125;-mavros# 构建ROS工作空间，可以自行修改路径mkdir -p ~/acfly_ws/src &amp;&amp; cd ~/acfly_wscatkin init# 下载mavlink和acfly-mavroscd srcgit clone -b release/$&#123;ROS_DISTRO&#125;/mavlink/2022.1.5-1 https://gitee.com/LauZanMo/mavlinkgit clone -b acfly-develop https://gitee.com/LauZanMo/acfly-mavros# 以下两个为非官方文档中提供git clone https://github.com/thien94/vision_to_mavros.gitgit clone https://github.com/IntelRealSense/librealsense.git# 安装依赖，如果rosdep update没执行则需要执行成功才能继续cd .. &amp;&amp; rosdep install --from-paths src --ignore-src -y# 安装GeographicLib:./src/acfly-mavros/mavros/scripts/install_geographiclib_datasets.sh# 注意此处可能会报需要root权限（不会标error）出现后在前方加sudo即可# 第一次编译请执行acfly提供的脚本./src/acfly-mavros/update_custom_msg.sh# 后续更改mavros源码只需要执行catkin build# 每一次开启终端都需要设置环境变量source devel/setup.bash\n\n使用# 第一个终端# 打开t265roslaunch realsense2_camera rs_t265.launch# 第二个终端# 添加权限sudo chmod 777 /dev/ttyAMA0roslaunch mavros acfly.launch fcu_url:=/dev/ttyUSB0:57600# 第三个终端# 此处需要先source前一步安装mavros工作空间中的setup.bashsource devel/setup.bashroslaunch vision_to_mavros t265_tf_to_mavros.launch\n\n其他 使用指南\nacfly-mavros 作者提供了使用指南及二次开发指南使用指南 二次开发指南 \n\n关于自启动自启动可看这篇","categories":["无人机"],"tags":["Ros","无人机","双目相机","T265","Jetson"]},{"title":"rplidarA1-gmapping","url":"/2023/06/30/rplidarA1-gmapping/","content":"\n所参考的大佬教程如下 大佬1  大佬2  大佬3 \n\n前情介绍\n任务背景为：要使用思岚A1M8激光雷达实现建图及避障、导航等功能本次为实现建图\n\n\nGmapping是基于滤波SLAM框架的常用开源SLAM算法，在ROS中使用Gmapping建图需要提供 Odometry(里程计信息)和laser(激光数据)，但是只用一个激光雷达也可以进行Gmapping建图\n\n其实我们是有双目相机T265可以提供姿态信息的，但受限于当前知识水平，暂且使用较为方便的Gmapping算法进行操作\n\n\n\n采用的方法就是使用 laser_scan_matcher 功能包，其为增量激光扫描配准工具。该软件包允许扫描连续的 sensor_msgs &#x2F; LaserScan 消息之间的匹配，并将估计的激光位置发布为 geometry_msgs &#x2F; Pose2D 或 tf 变换。该包可以在没有其他传感器提供的任何测距估计的情况下使用。因此，它可以作为独立的里程计算器估算器。\n\n具体步骤创建工作空间# 根据自己习惯创建工作空间mkdir -p ~/rplidar_ws/src &amp;&amp; cd ~/rplidar_ws/src\n\n下载所需的功能包git clone https://github.com/Slamtec/rplidar_ros.gitgit clone https://github.com/CCNYRoboticsLab/scan_tools.git\n\n获取gmapping功能包\n网址为：https://github.com/CCNYRoboticsLab/scan_tools.git  下载或克隆仓库后将其中的gmapping文件夹复制到工作空间下的src中（比如我的就是~/rplidar_ws/src）\n\n接着下载必要功能包# 将melodic替换为自己的ros版本sudo apt-get install ros-melodic-csmsudo apt-get install ros-melodic-gmapping\n\n编译工作空间# 进入工作空间cd ~/rplidar_ws# 编译catkin_make\n\n修改启动launch文件cd ~/Library/rplidar_ws/src/scan_tools-indigo/laser_scan_matcher/demo\n\n这里原先的demo_gmapping.launch文件则为启动launch文件，这里要做的就是修改它以实行自己的设备这里提供我的launch文件\n\n&lt;!-- Example launch file: uses laser_scan_matcher together withslam_gmapping --&gt;&lt;launch&gt;  #### set up data playback from bag #############################  &lt;param name=&quot;/use_sim_time&quot; value=&quot;flase&quot;/&gt;&lt;!-- 因为Gmapping 的simulation 时间是True, 改为false  网上查到的--&gt;  #### rplidar_a2 ################################################  &lt;!--激光雷达的启动文件--&gt; &lt;node name=&quot;rplidarNode&quot;          pkg=&quot;rplidar_ros&quot;  type=&quot;rplidarNode&quot; output=&quot;screen&quot;&gt;  &lt;param name=&quot;serial_port&quot;         type=&quot;string&quot; value=&quot;/dev/ttyUSB0&quot;/&gt;    &lt;param name=&quot;serial_baudrate&quot;     type=&quot;int&quot;    value=&quot;115200&quot;/&gt; &lt;!-- A1波特率 --&gt;  &lt;param name=&quot;frame_id&quot;            type=&quot;string&quot; value=&quot;laser&quot;/&gt;  &lt;param name=&quot;inverted&quot;            type=&quot;bool&quot;   value=&quot;false&quot;/&gt;  &lt;param name=&quot;angle_compensate&quot;    type=&quot;bool&quot;   value=&quot;true&quot;/&gt;  &lt;param name=&quot;scan_mode&quot;           type=&quot;string&quot; value=&quot;Sensitivity&quot;/&gt; &lt;/node&gt;  #### publish an example base_link -&gt; laser transform ###########  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;base_link_to_laser&quot;     args=&quot;0.0 0.0 0.0 0.0 0.0 0.0 /base_link /laser 40&quot; /&gt;  #### start rviz ################################################  &lt;node pkg=&quot;rviz&quot; type=&quot;rviz&quot; name=&quot;rviz&quot;     args=&quot;-d $(find laser_scan_matcher)/demo/demo_gmapping.rviz&quot;/&gt;  #### start the laser scan_matcher ##############################  &lt;node pkg=&quot;laser_scan_matcher&quot; type=&quot;laser_scan_matcher_node&quot;     name=&quot;laser_scan_matcher_node&quot; output=&quot;screen&quot;&gt;    &lt;param name=&quot;fixed_frame&quot; value = &quot;odom&quot;/&gt;    &lt;param name=&quot;max_iterations&quot; value=&quot;10&quot;/&gt;    &lt;param name=&quot;base_frame&quot; value = &quot;base_link&quot;/&gt;    &lt;param name=&quot;use_odom&quot; value=&quot;false&quot;/&gt;    &lt;param name=&quot;publy_pose&quot; value = &quot;true&quot;/&gt;    &lt;param name=&quot;publy_tf&quot; value=&quot;true&quot;/&gt;  &lt;/node&gt;  #### start gmapping ############################################&lt;!--前三个param必须设置修改，要不然tf_tree不完整--&gt;  &lt;node pkg=&quot;gmapping&quot; type=&quot;slam_gmapping&quot; name=&quot;slam_gmapping&quot; output=&quot;screen&quot;&gt;    &lt;param name=&quot;base_frame&quot; value=&quot;/base_link&quot;/&gt; &lt;!--***机器人的坐标系--&gt;    &lt;param name=&quot;odom_frame&quot; value=&quot;/odom&quot; /&gt; &lt;!--***世界坐标系--&gt;    &lt;param name=&quot;map_frame&quot; value=&quot;/map&quot; /&gt; &lt;!--***地图坐标系--&gt;    &lt;param name=&quot;map_udpate_interval&quot; value=&quot;1.0&quot;/&gt;    &lt;param name=&quot;maxUrange&quot; value=&quot;5.0&quot;/&gt;    &lt;param name=&quot;sigma&quot; value=&quot;0.1&quot;/&gt;    &lt;param name=&quot;kernelSize&quot; value=&quot;1&quot;/&gt;    &lt;param name=&quot;lstep&quot; value=&quot;0.15&quot;/&gt;    &lt;param name=&quot;astep&quot; value=&quot;0.15&quot;/&gt;    &lt;param name=&quot;iterations&quot; value=&quot;1&quot;/&gt;    &lt;param name=&quot;lsigma&quot; value=&quot;0.1&quot;/&gt;    &lt;param name=&quot;ogain&quot; value=&quot;3.0&quot;/&gt;    &lt;param name=&quot;lskip&quot; value=&quot;1&quot;/&gt;    &lt;param name=&quot;srr&quot; value=&quot;0.1&quot;/&gt;    &lt;param name=&quot;srt&quot; value=&quot;0.2&quot;/&gt;    &lt;param name=&quot;str&quot; value=&quot;0.1&quot;/&gt;    &lt;param name=&quot;stt&quot; value=&quot;0.2&quot;/&gt;    &lt;param name=&quot;linearUpdate&quot; value=&quot;1.0&quot;/&gt;    &lt;param name=&quot;angularUpdate&quot; value=&quot;0.5&quot;/&gt;    &lt;param name=&quot;temporalUpdate&quot; value=&quot;0.4&quot;/&gt;    &lt;param name=&quot;resampleThreshold&quot; value=&quot;0.5&quot;/&gt;    &lt;param name=&quot;particles&quot; value=&quot;10&quot;/&gt;    &lt;param name=&quot;xmin&quot; value=&quot;-5.0&quot;/&gt;    &lt;param name=&quot;ymin&quot; value=&quot;-5.0&quot;/&gt;    &lt;param name=&quot;xmax&quot; value=&quot;5.0&quot;/&gt;    &lt;param name=&quot;ymax&quot; value=&quot;5.0&quot;/&gt;    &lt;param name=&quot;delta&quot; value=&quot;0.02&quot;/&gt;    &lt;param name=&quot;llsamplerange&quot; value=&quot;0.01&quot;/&gt;    &lt;param name=&quot;llsamplestep&quot; value=&quot;0.05&quot;/&gt;    &lt;param name=&quot;lasamplerange&quot; value=&quot;0.05&quot;/&gt;    &lt;param name=&quot;lasamplestep&quot; value=&quot;0.05&quot;/&gt;  &lt;/node&gt;&lt;/launch&gt;\n其中 重点修改的为\n&lt;node name=&quot;rplidarNode&quot;          pkg=&quot;rplidar_ros&quot;  type=&quot;rplidarNode&quot; output=&quot;screen&quot;&gt;  &lt;param name=&quot;serial_port&quot;         type=&quot;string&quot; value=&quot;/dev/ttyUSB0&quot;/&gt;    &lt;param name=&quot;serial_baudrate&quot;     type=&quot;int&quot;    value=&quot;115200&quot;/&gt; &lt;!-- A1波特率 --&gt;  &lt;param name=&quot;frame_id&quot;            type=&quot;string&quot; value=&quot;laser&quot;/&gt;  &lt;param name=&quot;inverted&quot;            type=&quot;bool&quot;   value=&quot;false&quot;/&gt;  &lt;param name=&quot;angle_compensate&quot;    type=&quot;bool&quot;   value=&quot;true&quot;/&gt;  &lt;param name=&quot;scan_mode&quot;           type=&quot;string&quot; value=&quot;Sensitivity&quot;/&gt; &lt;/node&gt;\n\n第一行的rplidarNode及rplidar_ros需要按照自己的激光雷达启动节点而定第三行的波特率数值需要根据雷达而定 如我的A1M8为115200\n\n运行\n以下需要在同一终端中进行\n\n刷新环境变量source ~/rplidar_ws/devel/setup.bash\n给串口权限可以使用\nls /dev/*\n进行查询，如我的是ttyUSB0则输入\nsudo chmod 777 /dev/ttyUSB0\n运行launch文件roslaunch  laser_scan_matcher demo_gmapping.launch\n\n其中demo_gmapping.launch可以根据自己修改的launch文件而修改\n\n","categories":["无人机"],"tags":["Ros","Jetson","Slam","Gmapping","rplidarA1"]}]