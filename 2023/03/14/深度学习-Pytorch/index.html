<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    <meta name="description" content="Hexo Theme Redefine">
    <meta name="author" content="CGC">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-redefine.png">
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://example.com/2023/03/14/深度学习-pytorch/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    <meta property="og:type" content="article">
    <meta property="og:title" content="深度学习-Pytorch">
    <meta property="og:description" content="Hexo Theme Redefine">
    <meta property="og:url" content="http://example.com2023/03/14/深度学习-Pytorch/">
    
    <meta property="og:site_name" content="CGC">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="深度学习-Pytorch">
    <meta name="twitter:description" content="Hexo Theme Redefine">
    <meta name="twitter:image" content="/images/favicon_cgc.svg">
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/favicon_cgc.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon_cgc.svg">
    <meta name="theme-color" content="#005080">
    <link rel="shortcut icon" href="/images/favicon_cgc.svg">
    
    <title>
        
            深度学习-Pytorch -
        
        CGC
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/assets/fonts.css">

    
    
    
    <script id="hexo-configurations">
    let REDEFINE = window.REDEFINE || {};
    REDEFINE.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    REDEFINE.theme_config = {"toc":{"enable":true,"number":false,"expand_all":true,"init_open":true},"style":{"primary_color":"#005080","avatar":"/images/avatar_cgc.svg","favicon":"/images/favicon_cgc.svg","og_image":{"enable":false,"image_url":null},"article_img_align":"center","right_side_width":"210px","content_max_width":"1000px","nav_color":{"left":"#f78736","right":"#367df7","transparency":35},"hover":{"shadow":true,"scale":false},"first_screen":{"enable":true,"background_image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title_color":{"light":"#fff","dark":"#d1d1b6"},"font_sizes":{"title":"2.8rem","subtitle":"1.5rem"},"line_height":1.2,"title":null,"subtitle":{"enable":true,"list":["是我还是我","不一样的花火"]},"custom_font":{"enable":false,"font_family":null,"font_url":null}},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_block":{"copy":true,"style":"mac","custom_font":{"enable":false,"font_family":null,"font_url":null}},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"1.2.1","friend_links":{"columns":2},"home_article":{"date_format":"auto","category":{"enable":true,"limit":3},"tag":{"enable":true,"limit":3}},"plugins":{"aplayer":{"enable":false,"audio":[{"name":null,"artist":null,"url":null,"cover":null},{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}}};
    REDEFINE.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
    
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="menu-wrapper">
    
    <div class="menu-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                CGC
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="pc">
                <ul class="menu-list">
                    
                        
                            <li class="menu-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        HOME
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="menu-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/archives"  >
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        ARCHIVES
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="menu-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/tags"  >
                                    
                                        
                                            <i class="fa-regular fa-tag"></i>
                                        
                                        TAGS
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="menu-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/categories"  >
                                    
                                        
                                            <i class="fa-regular fa-grid-2"></i>
                                        
                                        CATEGORIES
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="menu-drawer">
        <ul class="drawer-menu-list">
            
                
                    <li class="drawer-menu-item flex-center">
                        <a class="" 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                HOME
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-menu-item flex-center">
                        <a class="" 
                        href="/archives"  >
                             
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                ARCHIVES
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-menu-item flex-center">
                        <a class="" 
                        href="/tags"  >
                             
                                
                                    <i class="fa-regular fa-tag"></i>
                                
                                TAGS
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-menu-item flex-center">
                        <a class="" 
                        href="/categories"  >
                             
                                
                                    <i class="fa-regular fa-grid-2"></i>
                                
                                CATEGORIES
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            
             
                <div class="article-title">         
                    <img src="/../images/pytorch/pytorch.jpg" alt="深度学习-Pytorch" />
                    <h1 class="article-title-cover">深度学习-Pytorch</h1>
                </div>
            
                
            

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/avatar_cgc.svg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">CGC</span>
                            
                                <span class="author-label">lol</span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="pc">2023-03-14 21:29:53</span>
        <span class="mobile">2023-03-14 21:29</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="pc">2023-04-09 15:23:06</span>
            <span class="mobile">2023-04-09 15:23</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Pytorch/">Pytorch</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <p>此为本人学习深度学习及Pytorch基础知识时所作，可能存在部分错误之处，敬请谅解。</p>
<h1 id="TensorBoard"><a href="#TensorBoard" class="headerlink" title="TensorBoard"></a>TensorBoard</h1><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(&quot;logs&quot;) # 创建实例，将事件文件储存到logs文件夹下</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img_path = &quot;./training_dataset/train/ants_image/0013035.jpg&quot;</span><br><span class="line">img = cv2.imread(img_path)</span><br><span class="line">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">writer.add_image(&quot;test&quot;, img, 1, dataformats = &quot;HWC&quot;) # 图像工具</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in range(100):</span><br><span class="line">    writer.add_scalar(&quot;y = 3x&quot;, 3*i, i) # 画函数工具</span><br><span class="line"></span><br><span class="line">writer.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>其中，对<code>writer.add_image(&quot;test&quot;, img, 1, dataformats = &quot;HWC&quot;)</code> <br><code>1</code>为步数，dataformats为格式</p>
<h2 id="Terminal"><a href="#Terminal" class="headerlink" title="Terminal"></a>Terminal</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=logs</span><br><span class="line"># 其中logdir=事件文件所在文件夹名</span><br></pre></td></tr></table></figure></div>
<p>输出内容为<code>TensorBoard 2.10.0 at http://localhost:6006/ (Press CTRL+C to quit)</code><br>表示在端口6006训练\</p>
<p>可用<code>tensorboard --logdir=logs --port=6007</code>指定端口</p>
<h1 id="TransForms"><a href="#TransForms" class="headerlink" title="TransForms"></a>TransForms</h1><h2 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">from torchvision import transforms</span><br><span class="line">img_path = &quot;./training_dataset/train/ants_image/0013035.jpg&quot;</span><br><span class="line">img = Image.open(img_path)</span><br><span class="line"></span><br><span class="line"># Totensor</span><br><span class="line">trans_totensor = transforms.ToTensor() # 创建对应工具</span><br><span class="line">tensor_img = trans_totensor(img) # 转化为tensor数据类型</span><br><span class="line">writer.add_image(&quot;ToTensor&quot;, tensor_img)</span><br><span class="line"></span><br><span class="line"># Normalize</span><br><span class="line">trans_norm = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])</span><br><span class="line">img_norm = trans_norm(tensor_img) # 归一化</span><br><span class="line">writer.add_image(&quot;Normalize&quot;, img_norm)</span><br><span class="line"></span><br><span class="line"># Resize</span><br><span class="line">trans_resize = transforms.Resize((512, 512))</span><br><span class="line">img_resize = trans_resize(img)</span><br><span class="line">img_resize = trans_totensor(img_resize) # 改变大小</span><br><span class="line">writer.add_image(&quot;Resize&quot;, img_resize, 0)</span><br><span class="line"></span><br><span class="line"># Compose - resize - 2</span><br><span class="line">trans_resize_2 = transforms.Resize(512)</span><br><span class="line">trans_compose = transforms.Compose([trans_resize_2, trans_totensor])</span><br><span class="line">img_resize_2 = trans_compose(img) # 按比例改变大小</span><br><span class="line">writer.add_image(&quot;Resize2&quot;, img_resize_2, 0)</span><br><span class="line"></span><br><span class="line"># RandomCrop</span><br><span class="line">trans_random = transforms.RandomCrop(512) # 括号内用于指定大小，可分别指定长宽</span><br><span class="line">trans_conpose_2 = transforms.Compose([trans_random, trans_totensor])</span><br><span class="line">for i in range(10):</span><br><span class="line">    img_crop = trans_conpose_2(img)</span><br><span class="line">    writer.add_image(&quot;RandomCrop&quot;, img_crop, i) # 随机裁剪</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></div>

<h1 id="torchvision"><a href="#torchvision" class="headerlink" title="torchvision"></a>torchvision</h1><h2 id="官方数据集下载"><a href="#官方数据集下载" class="headerlink" title="官方数据集下载"></a>官方数据集下载</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data = torchvision.datasets.CIFAR10(root = &quot;./dataset_test&quot;, train = True, transform = dataset_transform, download = True)</span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root = &quot;./dataset_test&quot;, train = False, transform = dataset_transform, download = True)</span><br></pre></td></tr></table></figure></div>
<p>root为本地下载存放地址<br>train为True为下载训练集 为False为下载测试集<br>transform为图片转化的工具 如<code>dataset_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])</code><br>download为是否下载该数据集</p>
<h2 id="数据集内容-例"><a href="#数据集内容-例" class="headerlink" title="数据集内容 例"></a>数据集内容 例</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img, target = test_set[0]</span><br></pre></td></tr></table></figure></div>
<p>对应输出为<br><code>(&lt;PIL.Image.Image image mode=RGB size=32x32 at 0x106B06F4E50&gt;, 3)</code><br>(此处前部分为不经过transform进行变换的默认PIL格式照片)<br>前部分为图片，后部分为该图片对应的对象在classes(test_set.classes)中的下标<br>若为</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_set.classes[target]</span><br></pre></td></tr></table></figure></div>
<p>则输出对应为<code>cat</code></p>
<h1 id="dataloader"><a href="#dataloader" class="headerlink" title="dataloader"></a>dataloader</h1><p>数据加载器</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_loader = DataLoader(dataset = test_data, batch_size = 4, shuffle = True, num_workers = 0, drop_last = False)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>dataset为指定数据集(测试集)<br>batch_size为指定每次从dataset中去除n个数据进行打包<br>shuffle若为True则每次训练会打乱顺序 一般为True<br>num_work为主进程数量<br>drop_last为保存最后一次取的数据</p>
<h2 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 准备测试集</span><br><span class="line">test_data = torchvision.datasets.CIFAR10(root = &quot;./dataset_test&quot;, train = False, transform = torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(dataset = test_data, batch_size = 4, shuffle = True, num_workers = 0, drop_last = False)</span><br><span class="line"></span><br><span class="line"># 测试集中第一张照片及target</span><br><span class="line">img, target = test_data[0]</span><br><span class="line"></span><br><span class="line"># 得到总的imgs与targets</span><br><span class="line">writer = SummaryWriter(&quot;dataloader_logs&quot;)</span><br><span class="line">step = 0</span><br><span class="line">for data in test_loader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    writer.add_images(&quot;test_data&quot;, imgs, step)</span><br><span class="line">    step += 1</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></div>

<h1 id="convolution-functional"><a href="#convolution-functional" class="headerlink" title="convolution functional"></a>convolution functional</h1><h2 id="卷积层-代码"><a href="#卷积层-代码" class="headerlink" title="卷积层 代码"></a>卷积层 代码</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F # 卷积函数</span><br><span class="line"></span><br><span class="line">input = torch.tensor([[1, 2, 0, 3, 1],</span><br><span class="line">                      [0, 1, 2, 3, 1],</span><br><span class="line">                      [1, 2, 1, 0, 0],</span><br><span class="line">                      [5, 2, 3, 1, 1],</span><br><span class="line">                      [2, 1, 0, 1, 1]])</span><br><span class="line">    </span><br><span class="line">kernel = torch.tensor([[1, 2, 1],</span><br><span class="line">                       [0, 1, 0],</span><br><span class="line">                       [2, 1, 0]])</span><br><span class="line"></span><br><span class="line">input = torch.reshape(input,(1, 1, 5, 5)) # 更改尺寸为(1, 1, 5, 5)</span><br><span class="line">kernel = torch.reshape(kernel,(1, 1, 3, 3)) # 更改尺寸为(1, 1, 3, 3)</span><br><span class="line"></span><br><span class="line">output = F.conv2d(input, kernel, stride = 1, padding = 0)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure></div>
<p>对于<code>torch.reshape(input,(1, 1, 5, 5))</code><br>shape为四通道<br>第一位为channel通道数量<br>第二位为输入channel&#x2F;group(batch_size)<br>三四位分别为高和宽<br>及有dilation 空洞卷积</p>
<p><code>F.conv2d</code>意为二维卷积<br>stride为卷积核移动步数，padding为填充情况</p>
<h2 id="conv2d小历程"><a href="#conv2d小历程" class="headerlink" title="conv2d小历程"></a>conv2d小历程</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Conv2d</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(&quot;./conv2d_dataset&quot;, train = False, transform = torchvision.transforms.ToTensor(),download = True)</span><br><span class="line"></span><br><span class="line">dataloader = DataLoader(dataset, batch_size = 64)</span><br><span class="line"></span><br><span class="line">class Fun(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Fun, self).__init__()</span><br><span class="line">        self.conv1 = Conv2d(in_channels = 3, out_channels = 6, kernel_size = 3, stride = 1, padding = 1)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">test = Fun()</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(&quot;con2d_logs&quot;)</span><br><span class="line">step = 0</span><br><span class="line"></span><br><span class="line">for data in dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = test(imgs)</span><br><span class="line"></span><br><span class="line">    writer.add_images(&quot;input&quot;, imgs, step)</span><br><span class="line"></span><br><span class="line">    output = torch.reshape(output, (-1, 3, 32, 32))</span><br><span class="line">    writer.add_images(&quot;output&quot;,output, step)</span><br><span class="line"></span><br><span class="line">    step += 1</span><br></pre></td></tr></table></figure></div>
<p>将数据集中的图片进行卷积操作，即卷积层</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><h3 id="最大池化"><a href="#最大池化" class="headerlink" title="最大池化"></a>最大池化</h3><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">import torchvision</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(&quot;maxpool_data&quot;, train = False, download = True, transform = torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">dataLoader = DataLoader(dataset, batch_size= 64)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Test(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Test, self).__init__()</span><br><span class="line">        self.maxpool1 = nn.MaxPool2d(kernel_size = 3, ceil_mode = True)</span><br><span class="line"></span><br><span class="line">    def forward(self,input):</span><br><span class="line">        output = self.maxpool1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">test = Test()</span><br><span class="line"></span><br><span class="line">step = 0</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(&quot;maxpool_logs&quot;)</span><br><span class="line">for data in dataLoader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    writer.add_images(&quot;input&quot;, imgs, step)</span><br><span class="line"></span><br><span class="line">    output = test(imgs)</span><br><span class="line">    writer.add_images(&quot;output&quot;, output, step)</span><br><span class="line">    step += 1</span><br></pre></td></tr></table></figure></div>
<p>其中<code>self.maxpool1 = nn.MaxPool2d()(kernel_size = 3, ceil_mode = True)</code>中的<code>ceil_mode</code> 为补全，为True即当kernel加载到不满九个数据的位置时仍然计</p>
<p>池化可以缩减目标空间 增加运行速度</p>
<h2 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(&quot;maxpool_data&quot;, train = False, download = True, transform = torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">dataloader = DataLoader(dataset, batch_size = 64)</span><br><span class="line"></span><br><span class="line">class test(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(test, self).__init__()</span><br><span class="line">        self.relu1 = torch.nn.ReLU()</span><br><span class="line">        self.sigmoid1 = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output = self.relu1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">test = test()</span><br><span class="line">writer = SummaryWriter(&quot;relu_logs&quot;)</span><br><span class="line">step = 0</span><br><span class="line"></span><br><span class="line">for  data in dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    writer.add_images(&quot;input&quot;, imgs, step)</span><br><span class="line">    output = test(imgs)</span><br><span class="line">    writer.add_images(&quot;output&quot;, output, step)</span><br><span class="line">    step += 1</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></div>

<h2 id="线性层"><a href="#线性层" class="headerlink" title="线性层"></a>线性层</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">from modulefinder import Module</span><br><span class="line">import torchvision</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(&quot;maxpool_data&quot;, train = False, download = True, transform = torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">dataloader = DataLoader(dataset, batch_size = 64)</span><br><span class="line"></span><br><span class="line">class test(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(test, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(196608, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output = self.linear1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">test = test()</span><br><span class="line"></span><br><span class="line">for data in dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    print(imgs.shape)</span><br><span class="line">    # output = torch.reshape(imgs, (1, 1, 1, -1))</span><br><span class="line">    output = torch.flatten(imgs) # 将矩阵展开成一行</span><br><span class="line">    print(output.shape)</span><br><span class="line">    output = test(output)</span><br><span class="line">    print(output.shape)</span><br></pre></td></tr></table></figure></div>
<p>也作为全连接层？</p>
<h2 id="Sequential及网络搭建小历程"><a href="#Sequential及网络搭建小历程" class="headerlink" title="Sequential及网络搭建小历程"></a>Sequential及网络搭建小历程</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class test(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(test, self).__init__()</span><br><span class="line">        # self.conv1 = torch.nn.Conv2d(3, 32, 5, padding = 2)</span><br><span class="line">        # self.maxpool1 = torch.nn.MaxPool2d(2)</span><br><span class="line">        # self.conv2 = torch.nn.Conv2d(32, 32, 5, padding = 2)</span><br><span class="line">        # self.maxpool2 = torch.nn.MaxPool2d(2)</span><br><span class="line">        # self.conv3 = torch.nn.Conv2d(32, 64, 5, padding = 2)</span><br><span class="line">        # self.maxpool3 = torch.nn.MaxPool2d(2)</span><br><span class="line">        # self.flatten = torch.nn.Flatten()</span><br><span class="line">        # self.linear1 = torch.nn.Linear(1024, 64)</span><br><span class="line">        # self.linear2 = torch.nn.Linear(64, 10)</span><br><span class="line"></span><br><span class="line">        self.model1 = torch.nn.Sequential(</span><br><span class="line">                                torch.nn.Conv2d(3, 32, 5, padding = 2),</span><br><span class="line">                                torch.nn.MaxPool2d(2),</span><br><span class="line">                                torch.nn.Conv2d(32, 32, 5, padding = 2),</span><br><span class="line">                                torch.nn.MaxPool2d(2),</span><br><span class="line">                                torch.nn.Conv2d(32, 64, 5, padding = 2),</span><br><span class="line">                                torch.nn.MaxPool2d(2),</span><br><span class="line">                                torch.nn.Flatten(),</span><br><span class="line">                                torch.nn.Linear(1024, 64),</span><br><span class="line">                                torch.nn.Linear(64, 10)</span><br><span class="line">                                )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # x = self.conv1(x)</span><br><span class="line">        # x = self.maxpool1(x)</span><br><span class="line">        # x = self.conv2(x)</span><br><span class="line">        # x = self.maxpool2(x)</span><br><span class="line">        # x = self.conv3(x)</span><br><span class="line">        # x = self.maxpool3(x)</span><br><span class="line">        # x = self.flatten(x)</span><br><span class="line">        # x = self.linear1(x)</span><br><span class="line">        # x = self.linear2(x)</span><br><span class="line"></span><br><span class="line">        x = self.model1(x)</span><br><span class="line"></span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">test = test()</span><br><span class="line">print(test)</span><br><span class="line">input = torch.ones((64, 3, 32, 32))</span><br><span class="line">output = test(input)</span><br><span class="line">print(output.shape)</span><br><span class="line"></span><br><span class="line">write = SummaryWriter(&quot;seq_logs&quot;)</span><br><span class="line">write.add_graph(test, input) # 输出运行的树图</span><br><span class="line">write.close()</span><br></pre></td></tr></table></figure></div>

<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([1, 2, 3], dtype = torch.float32)</span><br><span class="line">targets = torch.tensor([1, 2, 5], dtype = torch.float32)</span><br><span class="line"></span><br><span class="line">inputs = torch.reshape(input, (1, 1, 1, 3))</span><br><span class="line">targets = torch.reshape(targets, (1, 1, 3, 1))</span><br><span class="line"></span><br><span class="line">loss = torch.nn.L1loss(reduction = &#x27;sum&#x27;)</span><br><span class="line">result = loss(inputs, targets)</span><br></pre></td></tr></table></figure></div>
            </div>

            
                <div class="post-copyright-info">
                    <div class="article-copyright-info-container">
    <ul>
        <li>Post title：深度学习-Pytorch</li>
        <li>Post author：CGC</li>
        <li>Create time：2023-03-14 21:29:53</li>
        <li>
            Post link：https://redefine.ohevan.com/2023/03/14/深度学习-Pytorch/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">#计算机视觉</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/Pytorch/">#Pytorch</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">#人工智能</a>&nbsp;
                        </li>
                    
                </ul>
            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                            rel="prev"
                            href="/2023/03/14/%E5%85%B3%E4%BA%8E%E8%93%9D%E6%A1%A5%E6%9D%AF/"
                            >
                                <span class="left arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-left"></i>
                                </span>
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">关于蓝桥杯</span>
                                    <span class="post-nav-item">Prev posts</span>
                                </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2023/03/14/Lingo/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">Lingo</span>
                                    <span class="post-nav-item">Next posts</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            


            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">深度学习-Pytorch</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#TensorBoard"><span class="nav-text">TensorBoard</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81"><span class="nav-text">代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Terminal"><span class="nav-text">Terminal</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#TransForms"><span class="nav-text">TransForms</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81-1"><span class="nav-text">代码</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torchvision"><span class="nav-text">torchvision</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%98%E6%96%B9%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD"><span class="nav-text">官方数据集下载</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%86%85%E5%AE%B9-%E4%BE%8B"><span class="nav-text">数据集内容 例</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#dataloader"><span class="nav-text">dataloader</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81-2"><span class="nav-text">代码</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#convolution-functional"><span class="nav-text">convolution functional</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82-%E4%BB%A3%E7%A0%81"><span class="nav-text">卷积层 代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conv2d%E5%B0%8F%E5%8E%86%E7%A8%8B"><span class="nav-text">conv2d小历程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="nav-text">池化层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96"><span class="nav-text">最大池化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB"><span class="nav-text">非线性激活</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%B1%82"><span class="nav-text">线性层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sequential%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA%E5%B0%8F%E5%8E%86%E7%A8%8B"><span class="nav-text">Sequential及网络搭建小历程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-text">损失函数</span></a></li></ol></li></ol>

    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>



        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info">
            &copy;
            
              <span>2022</span>
              -
            
            2023&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">CGC</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">
                        VISITOR COUNT&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">
                        TOTAL PAGE VIEWS&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            <span class="powered-by-container">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a></span>
                <br> 
            <span class="theme-version-container">THEME&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v1.2.1</a>
        </div>
        
        
        
            <div id="start_time_div" style="display:none">
                2022/8/17 11:45:14
            </div>
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
        
            <script async data-pjax>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="unfolded-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="right-bottom-tools tool-scroll-to-top flex-center">
                <i class="fa-regular fa-arrow-up"></i>
            </li>
        

        <li class="right-bottom-tools tool-scroll-to-bottom flex-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="folded-tools-list">
        <li class="right-bottom-tools tool-toggle-show flex-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fa-solid fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fa-solid fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    


</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/layouts/menu-shrink.js"></script>

<script src="/js/tools/go-top-bottom.js"></script>

<script src="/js/tools/dark-light-toggle.js"></script>



    
<script src="/js/tools/local-search.js"></script>




    
<script src="/js/tools/code-block.js"></script>




    
<script src="/js/layouts/lazyload.js"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/layouts/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>







<div class="post-scripts pjax">
    
        
<script src="/js/tools/toc-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/layouts/toc.js"></script>

<script src="/js/plugins/tabs.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            REDEFINE.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            REDEFINE.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            REDEFINE.refresh();
        });
    });
</script>





<!-- 雪花特效 -->
<script type="text/javascript" src="\js\snow.js"></script>

</body>
</html>
