<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="CGC">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://example.com/2023/03/14/机器学习-sklearn/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="机器学习中基于Sklearn库的部分算法实现">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-Sklearn">
<meta property="og:url" content="http://example.com/2023/03/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Sklearn/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="机器学习中基于Sklearn库的部分算法实现">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-03-14T13:20:50.000Z">
<meta property="article:modified_time" content="2023-04-09T02:59:52.732Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="Sklearn">
<meta name="twitter:card" content="summary">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/favicon_cgc.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon_cgc.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/favicon_cgc.svg">
    <!--- Page Info-->
    
    <title>
        
            机器学习-Sklearn -
        
        CGC
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/fonts/fonts.css">

    
<link rel="stylesheet" href="/fonts/Satoshi/satoshi.css">

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">

    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":true},"scroll_progress":{"bar":false,"percentage":true},"busuanzi_counter":{"enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"pjax":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/background/bg1.jpg","dark":"/images/background/bg2.jpg"},"title":"CGC","subtitle":{"text":["是我还是我","不一样的花火"],"hitokoto":{"enable":true,"api":"https://v1.hitokoto.cn/?c=d&c=e&c=h"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":150,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.2rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"links":{"github":"https://github.com/CGC12123","instagram":null,"zhihu":null,"twitter":null,"email":"caiguoci@126.com"}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.2.1","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Article":{"path":"/categories","icon":"fa-regular fa-archive","submenus":{"Archives":"/archives","Tags":"/tags","Categories":"/categories"}},"Links":{"icon":"fa-solid fa-link","path":"/links"},"Photos":{"icon":"fa-solid fa-image","path":"/masonry"}},"search":{"enable":true,"preload":true}},"page_templates":{"friends_column":3,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"right","first_item":"info","announcement":null,"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Tags":{"path":"/tags","icon":"fa-regular fa-tag"},"Categories":{"path":"/categories","icon":"fa-regular fa-grid-2"},"Links":{"icon":"fa-solid fa-link","path":"/links"},"Photos":{"icon":"fa-solid fa-image","path":"/masonry"}}},"article_date_format":"YYYY-MM-DD","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2022/3/17 11:45:14"};
    Global.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    Global.data_config = {"masonry":true};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="main-content-container">

        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                CGC
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        HOME
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        ARTICLE&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a href="/archives">ARCHIVES
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a href="/tags">TAGS
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a href="/categories">CATEGORIES
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/links"  >
                                    
                                        
                                            <i class="fa-solid fa-link"></i>
                                        
                                        LINKS
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/masonry"  >
                                    
                                        
                                            <i class="fa-solid fa-image"></i>
                                        
                                        PHOTOS
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                        <li class="navbar-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div>
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer">
        <ul class="drawer-navbar-list">
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                HOME
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                ARTICLE&nbsp;<i class="fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" href="/archives">ARCHIVES</a>
                            </li>
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" href="/tags">TAGS</a>
                            </li>
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" href="/categories">CATEGORIES</a>
                            </li>
                        
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/links"  >
                             
                                
                                    <i class="fa-solid fa-link"></i>
                                
                                LINKS
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/masonry"  >
                             
                                
                                    <i class="fa-solid fa-image"></i>
                                
                                PHOTOS
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            
            
                <div class="article-title">
                    <h1 class="article-title-regular">机器学习-Sklearn</h1>
                </div>
            
                
            

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="https://avatars.githubusercontent.com/u/93080289?v=4">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">CGC</span>
                            
                                <span class="author-label">Lv3</span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2023-03-14 21:20:50</span>
        <span class="mobile">2023-03-14 21:20</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2023-04-09 10:59:52</span>
            <span class="mobile">2023-04-09 10:59</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Sklearn/">Sklearn</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h1 id="Python中库的调用"><a href="#Python中库的调用" class="headerlink" title="Python中库的调用"></a>Python中库的调用</h1><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span><br></pre></td></tr></table></figure></div>
<h1 id="数据集的划分"><a href="#数据集的划分" class="headerlink" title="数据集的划分"></a>数据集的划分</h1><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.train_test_split(arrays, *options)</span><br></pre></td></tr></table></figure></div>
<p>x 数据集的特征值<br>y 数据集的标签值<br>test_size 测试集的大小，一般为float<br>random_state 随机数种子,不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。<br>return 测试集特征训练集特征值值，训练标签，测试标签(默认随机取)<br>一般使用为</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test = train_test_split(data, target, random_state = <span class="number">22</span>)</span><br></pre></td></tr></table></figure></div>
<p>其中 data为自变量集 target为因变量</p>
<h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><h2 id="字典特征提取"><a href="#字典特征提取" class="headerlink" title="字典特征提取"></a>字典特征提取</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">transfer = DictVectorizer(sparse=<span class="literal">True</span>) <span class="comment"># 实例化转换器类</span></span><br><span class="line">data = transfer.fit_transform(data) <span class="comment"># 类似独热编码</span></span><br></pre></td></tr></table></figure></div>
<p>sparse为True为使用传统独热编码<br>为False为使用向量说明当前位置 用于节省空间 加快运行效率</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_dure = pd.get_dummies(data2, columns=[<span class="string">&#x27;...&#x27;</span>]) <span class="comment"># 独热编码 columns为剔除无关项</span></span><br></pre></td></tr></table></figure></div>
<h2 id="文本特征提取"><a href="#文本特征提取" class="headerlink" title="文本特征提取"></a>文本特征提取</h2><h3 id="英文"><a href="#英文" class="headerlink" title="英文"></a>英文</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">transfer = CountVectorizer() <span class="comment"># 实例化 sparse 默认为True</span></span><br><span class="line">data = transfer.fit_transform(data) <span class="comment"># 调用</span></span><br></pre></td></tr></table></figure></div>
<p>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transfer = CountVectorizer()</span><br><span class="line">data = transfer.fit_transform(data) <span class="comment"># 调用fit_transform</span></span><br></pre></td></tr></table></figure></div>
<p>对于</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="string">&quot;life is short,i like like python&quot;</span>, <span class="string">&quot;life is too long,i dislike python&quot;</span>]</span><br></pre></td></tr></table></figure></div>
<p>输出结果为</p>
<blockquote>
<p>文本特征抽取的结果：<br>[[0 1 1 2 0 1 1 0]<br>[1 1 1 0 1 1 0 1]]<br>返回特征名字：<br>[‘dislike’, ‘is’, ‘life’, ‘like’, ‘long’, ‘python’, &gt; ‘short’, ‘too’]</p>
</blockquote>
<p>即对应字母在句子中出现的次数</p>
<h3 id="中文-jieba分词处理"><a href="#中文-jieba分词处理" class="headerlink" title="中文 jieba分词处理"></a>中文 jieba分词处理</h3><p>对于</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="string">&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。&quot;</span>,<span class="string">&quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;</span>,<span class="string">&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;</span>]</span><br></pre></td></tr></table></figure></div>
<p>对其进行</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text_list = []</span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> data:</span><br><span class="line">    text_list.append(cut_word(sent))</span><br></pre></td></tr></table></figure></div>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&quot; &quot;</span>.join(<span class="built_in">list</span>(jieba.cut(text))) <span class="comment"># 使用jieba对中文字符串进行分词</span></span><br></pre></td></tr></table></figure></div>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transfer = CountVectorizer() <span class="comment"># 实例化转换器</span></span><br><span class="line">data = transfer.fit_transform(text_list)</span><br></pre></td></tr></table></figure></div>
<p>类似地得到</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">文本特征抽取的结果：</span><br><span class="line">[[<span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">4</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br><span class="line">返回特征名字：</span><br><span class="line">[<span class="string">&#x27;一种&#x27;</span>, <span class="string">&#x27;不会&#x27;</span>, <span class="string">&#x27;不要&#x27;</span>, <span class="string">&#x27;之前&#x27;</span>, <span class="string">&#x27;了解&#x27;</span>, <span class="string">&#x27;事物&#x27;</span>, <span class="string">&#x27;今天&#x27;</span>, <span class="string">&#x27;光是在&#x27;</span>, <span class="string">&#x27;几百万年&#x27;</span>, <span class="string">&#x27;发出&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;取决于&#x27;</span>, <span class="string">&#x27;只用&#x27;</span>, <span class="string">&#x27;后天&#x27;</span>, <span class="string">&#x27;含义&#x27;</span>, <span class="string">&#x27;大部分&#x27;</span>, <span class="string">&#x27;如何&#x27;</span>, <span class="string">&#x27;如果&#x27;</span>, <span class="string">&#x27;宇宙&#x27;</span>, <span class="string">&#x27;我们&#x27;</span>, <span class="string">&#x27;所以&#x27;</span>, <span class="string">&#x27;放</span></span><br><span class="line"><span class="string">弃&#x27;</span>, <span class="string">&#x27;方式&#x27;</span>, <span class="string">&#x27;明天&#x27;</span>, <span class="string">&#x27;星系&#x27;</span>, <span class="string">&#x27;晚上&#x27;</span>, <span class="string">&#x27;某样&#x27;</span>, <span class="string">&#x27;残酷&#x27;</span>, <span class="string">&#x27;每个&#x27;</span>, <span class="string">&#x27;看到&#x27;</span>, <span class="string">&#x27;真正&#x27;</span>, <span class="string">&#x27;秘密&#x27;</span>, <span class="string">&#x27;绝</span></span><br><span class="line"><span class="string">对&#x27;</span>, <span class="string">&#x27;美好&#x27;</span>, <span class="string">&#x27;联系&#x27;</span>, <span class="string">&#x27;过去&#x27;</span>, <span class="string">&#x27;还是&#x27;</span>, <span class="string">&#x27;这样&#x27;</span>]</span><br></pre></td></tr></table></figure></div>
<h3 id="Tf-idf文本特征提取"><a href="#Tf-idf文本特征提取" class="headerlink" title="Tf-idf文本特征提取"></a>Tf-idf文本特征提取</h3><p>能够自动获取关键词<br>TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。<br>TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。<br>可提取出更具有分类意义的词<br>对于</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="string">&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。&quot;</span>,</span><br><span class="line"><span class="string">&quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;</span>,</span><br><span class="line"><span class="string">&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;</span>]</span><br></pre></td></tr></table></figure></div>
<p>对其进行</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用jieba处理文本</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">text_list = []</span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> data:</span><br><span class="line">    text_list.append<span class="string">&quot; &quot;</span>.join(<span class="built_in">list</span>(jieba.cut(sent))))</span><br></pre></td></tr></table></figure></div>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">transfer = TfidfVectorizer(stop_words=[<span class="string">&#x27;一种&#x27;</span>, <span class="string">&#x27;不会&#x27;</span>, <span class="string">&#x27;不要&#x27;</span>]) <span class="comment"># 实例化转换器 stop为去掉的词?</span></span><br><span class="line">data = transfer.fit_transform(text_list)</span><br></pre></td></tr></table></figure></div>
<p>其结果为</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">文本特征抽取的结果：</span><br><span class="line">[[ <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.43643578</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span></span><br><span class="line"><span class="number">0.</span> <span class="number">0.</span> <span class="number">0.21821789</span> <span class="number">0.</span> <span class="number">0.21821789</span> <span class="number">0.</span> <span class="number">0.</span></span><br><span class="line"><span class="number">0.</span> <span class="number">0.</span> <span class="number">0.21821789</span> <span class="number">0.21821789</span> <span class="number">0.</span> <span class="number">0.43643578</span></span><br><span class="line"><span class="number">0.</span> <span class="number">0.21821789</span> <span class="number">0.</span> <span class="number">0.43643578</span> <span class="number">0.21821789</span> <span class="number">0.</span> <span class="number">0.</span></span><br><span class="line"><span class="number">0.</span> <span class="number">0.21821789</span> <span class="number">0.21821789</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.21821789</span></span><br><span class="line"><span class="number">0.</span> ]</span><br><span class="line">[ <span class="number">0.2410822</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.2410822</span> <span class="number">0.2410822</span></span><br><span class="line"><span class="number">0.2410822</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span></span><br><span class="line"><span class="number">0.</span> <span class="number">0.2410822</span> <span class="number">0.55004769</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span></span><br><span class="line"><span class="number">0.2410822</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.48216441</span></span><br><span class="line"><span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.2410822</span></span><br><span class="line"><span class="number">0.</span> <span class="number">0.2410822</span> ]</span><br><span class="line">[ <span class="number">0.</span> <span class="number">0.644003</span> <span class="number">0.48300225</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span></span><br><span class="line"><span class="number">0.16100075</span> <span class="number">0.16100075</span> <span class="number">0.</span> <span class="number">0.16100075</span> <span class="number">0.</span> <span class="number">0.16100075</span></span><br><span class="line"><span class="number">0.16100075</span> <span class="number">0.</span> <span class="number">0.12244522</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.16100075</span></span><br><span class="line"><span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.16100075</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span></span><br><span class="line"><span class="number">0.3220015</span> <span class="number">0.16100075</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.16100075</span> <span class="number">0.</span> <span class="number">0.</span></span><br><span class="line"><span class="number">0.</span> ]]</span><br><span class="line">返回特征名字：</span><br><span class="line">[<span class="string">&#x27;之前&#x27;</span>, <span class="string">&#x27;了解&#x27;</span>, <span class="string">&#x27;事物&#x27;</span>, <span class="string">&#x27;今天&#x27;</span>, <span class="string">&#x27;光是在&#x27;</span>, <span class="string">&#x27;几百万年&#x27;</span>, <span class="string">&#x27;发出&#x27;</span>, <span class="string">&#x27;取决于&#x27;</span>, <span class="string">&#x27;只用&#x27;</span>, <span class="string">&#x27;后天&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;含义&#x27;</span>, <span class="string">&#x27;大部分&#x27;</span>, <span class="string">&#x27;如何&#x27;</span>, <span class="string">&#x27;如果&#x27;</span>, <span class="string">&#x27;宇宙&#x27;</span>, <span class="string">&#x27;我们&#x27;</span>, <span class="string">&#x27;所以&#x27;</span>, <span class="string">&#x27;放弃&#x27;</span>, <span class="string">&#x27;方式&#x27;</span>, <span class="string">&#x27;明天&#x27;</span>, <span class="string">&#x27;星</span></span><br><span class="line"><span class="string">系&#x27;</span>, <span class="string">&#x27;晚上&#x27;</span>, <span class="string">&#x27;某样&#x27;</span>, <span class="string">&#x27;残酷&#x27;</span>, <span class="string">&#x27;每个&#x27;</span>, <span class="string">&#x27;看到&#x27;</span>, <span class="string">&#x27;真正&#x27;</span>, <span class="string">&#x27;秘密&#x27;</span>, <span class="string">&#x27;绝对&#x27;</span>, <span class="string">&#x27;美好&#x27;</span>, <span class="string">&#x27;联系&#x27;</span>, <span class="string">&#x27;过</span></span><br><span class="line"><span class="string">去&#x27;</span>, <span class="string">&#x27;还是&#x27;</span>, <span class="string">&#x27;这样&#x27;</span>]</span><br></pre></td></tr></table></figure></div>
<h2 id="特征预处理"><a href="#特征预处理" class="headerlink" title="特征预处理"></a>特征预处理</h2><h3 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h3><p>通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程<br>将数据压缩至一个既定范围内<br>使得特征都能被学习到</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.MinMaxScaler()</span><br></pre></td></tr></table></figure></div>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;dating.txt&quot;</span>)</span><br><span class="line">transfer = MinMaxScaler(feature_range=(<span class="number">2</span>, <span class="number">3</span>)) <span class="comment"># 实例化转换器类</span></span><br><span class="line">data = transfer.fit_transform(data[[<span class="string">&#x27;milage&#x27;</span>, <span class="string">&#x27;Liters&#x27;</span>, <span class="string">&#x27;Consumtime&#x27;</span>]])</span><br></pre></td></tr></table></figure></div>
<h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><p>剔除异常值的影响<br>适合目前大数据场景</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.StandardScaler( )</span><br></pre></td></tr></table></figure></div>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transfer = StandardScaler()</span><br><span class="line">data = transfer.fit_transform(data[[<span class="string">&#x27;milage&#x27;</span>,<span class="string">&#x27;Liters&#x27;</span>,<span class="string">&#x27;Consumtime&#x27;</span>]])</span><br></pre></td></tr></table></figure></div>
<h2 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h2><p>降维是指在某些限定条件下，降低随机变量(特征)个数，得到一组“不相关”主变量的过程<br>降低随机变量的个数</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_selection</span><br></pre></td></tr></table></figure></div>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><h3 id="Filter过滤式"><a href="#Filter过滤式" class="headerlink" title="Filter过滤式"></a>Filter过滤式</h3><p>主要探究特征本身特点、特征与特征和目标值之间关联<br>方差选择法：低方差特征过滤</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_selection.VarianceThreshold(threshold = <span class="number">0.0</span>) <span class="comment"># 删除所有低方差特征</span></span><br></pre></td></tr></table></figure></div>
<p>使用例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transfer = VarianceThreshold(threshold=<span class="number">1</span>)</span><br><span class="line">data = transfer.fit_transform(data.iloc[:, <span class="number">1</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure></div>
<p><code>iloc</code>为指定位置 先行再列</p>
<h3 id="相关系数"><a href="#相关系数" class="headerlink" title="相关系数"></a>相关系数</h3><p>皮尔逊相关系数(Pearson Correlation Coefficient)</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">pearsonr(data[i], data[j])[<span class="number">0</span>])) <span class="comment"># 得到相关系数</span></span><br></pre></td></tr></table></figure></div>
<p>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&quot;factor_returns.csv&quot;</span>)</span><br><span class="line">factor = [<span class="string">&#x27;pe_ratio&#x27;</span>, <span class="string">&#x27;pb_ratio&#x27;</span>, <span class="string">&#x27;market_cap&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;return_on_asset_net_profit&#x27;</span>, <span class="string">&#x27;du_return_on_equity&#x27;</span>, <span class="string">&#x27;ev&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;earnings_per_share&#x27;</span>, <span class="string">&#x27;revenue&#x27;</span>, <span class="string">&#x27;total_expense&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(factor)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, <span class="built_in">len</span>(factor) - <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;指标%s与指标%s之间的相关性大小为%f&quot;</span> % (factor[i], factor[j + <span class="number">1</span>], </span><br><span class="line">        pearsonr(data[factor[i]], data[factor[j + <span class="number">1</span>]])[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure></div>
<p>此处可使用图像进行观察revenue与total_expense的关系</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">100</span>)</span><br><span class="line">plt.scatter(data[<span class="string">&#x27;revenue&#x27;</span>], data[<span class="string">&#x27;total_expense&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p>可得到其相关系数高可以进行合成</p>
<h3 id="主成分分析-PCA-PCA降维"><a href="#主成分分析-PCA-PCA降维" class="headerlink" title="主成分分析(PCA) PCA降维"></a>主成分分析(PCA) PCA降维</h3><p>定义：高维数据转化为低维数据的过程，在此过程中可能会舍弃原有数据、创造新的变量<br>作用：是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息。<br>应用：回归分析或者聚类分析当中</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition.PCA(n_components = <span class="literal">None</span>)</span><br></pre></td></tr></table></figure></div>
<p>对于n_components：<br>小数：表示保留百分之多少的信息<br>整数：减少到多少特征<br>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">transfer = PCA(n_components = <span class="number">0.9</span>) <span class="comment"># 保留90%的信息</span></span><br><span class="line">data1 = transfer.fit_transform(data)</span><br><span class="line">transfer2 = PCA(n_components=<span class="number">3</span>) <span class="comment"># 减少到3个特征</span></span><br><span class="line">data2 = transfer2.fit_transform(data)</span><br></pre></td></tr></table></figure></div>
<h3 id="合并表"><a href="#合并表" class="headerlink" title="合并表"></a>合并表</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">result = pd.merge(csv1, csv2, on = [test1, test2]) <span class="comment"># 将csv1中的tset1和csv2的test2在一张表中 按索引进行合并</span></span><br></pre></td></tr></table></figure></div>
<h2 id="sklearn转换器和预估器"><a href="#sklearn转换器和预估器" class="headerlink" title="sklearn转换器和预估器"></a>sklearn转换器和预估器</h2><h3 id="转换器"><a href="#转换器" class="headerlink" title="转换器"></a>转换器</h3><p>特征工程的接口称之为转换器<br>有以下三种<br><code>fit_transform</code><br><code>fit</code><br><code>transform</code><br>其差别如以下</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">In [<span class="number">2</span>]: std1 = StandardScaler()</span><br><span class="line">In [<span class="number">3</span>]: a = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">In [<span class="number">4</span>]: std1.fit_transform(a)</span><br><span class="line">Out[<span class="number">4</span>]:array([[-<span class="number">1.</span>, -<span class="number">1.</span>, -<span class="number">1.</span>],[ <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line">In [<span class="number">5</span>]: std2 = StandardScaler()</span><br><span class="line">In [<span class="number">6</span>]: std2.fit(a)</span><br><span class="line">Out[<span class="number">6</span>]: StandardScaler(copy=<span class="literal">True</span>, with_mean=<span class="literal">True</span>, with_std=<span class="literal">True</span>)</span><br><span class="line">In [<span class="number">7</span>]: std2.transform(a)</span><br><span class="line">Out[<span class="number">7</span>]:array([[-<span class="number">1.</span>, -<span class="number">1.</span>, -<span class="number">1.</span>],[ <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure></div>
<p>可知fit_transform的作用相当于transform加上fit<br>fit方法可看作训练</p>
<h3 id="估计器"><a href="#估计器" class="headerlink" title="估计器"></a>估计器</h3><p>sklearn机器学习算法的实现<br>调用.fit()进行计算 生成model\</p>
<p>模型评估方法:<br>1)直接对比真实值与预测值\</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="keyword">if</span> y_test == y_predict</span><br></pre></td></tr></table></figure></div>
<p>2)利用公式计算\</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accurary = estimator.score(x_test, y_test)</span><br></pre></td></tr></table></figure></div>
<h1 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h1><h2 id="KNN算法"><a href="#KNN算法" class="headerlink" title="KNN算法"></a>KNN算法</h2><p>核心思想:根据邻居确定类别<br>可能出现的问题:<br>k过小容易收到异常点影响<br>k过大容易收到样本不均匀影响<br>需要做无量纲化处理——标准化</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsClassifier(n_neighbors = <span class="number">5</span>, algorithm = <span class="string">&#x27;auto&#x27;</span>)</span><br></pre></td></tr></table></figure></div>
<p>· n_neighbors：int,可选（默认&#x3D; 5），k_neighbors查询默认使用的邻居数<br>· algorithm：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，可选用于计算最近邻居的算法：‘ball_tree’将会使用 BallTree，‘kd_tree’将使用 KDTree。‘auto’将尝试根据传递给fit方法的值来决定最合适的算法。 (不同实现方式影响效率)</p>
<h3 id="使用案例——鸢尾花分类"><a href="#使用案例——鸢尾花分类" class="headerlink" title="使用案例——鸢尾花分类"></a>使用案例——鸢尾花分类</h3><p>-&gt; knn_demo.ipynb</p>
<h2 id="模型选择和调优"><a href="#模型选择和调优" class="headerlink" title="模型选择和调优"></a>模型选择和调优</h2><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>将拿到的训练数据，分为训练和验证集。以下图为例：将数据分成5份，其中一份作为验证集。然后经过5次(组)的测试，每次都更换不同的验证集。即得到5组模型的结果，取平均值作为最终结果。又称5折交叉验证。<br>交叉验证目的：<strong>为了让被评估的模型更加准确可信</strong></p>
<h3 id="超参数搜索——网格搜索"><a href="#超参数搜索——网格搜索" class="headerlink" title="超参数搜索——网格搜索"></a>超参数搜索——网格搜索</h3><p>获取最佳参数(超参数)-(如KNN中的K值)\</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.GridSearchCV(estimator, param_grid = <span class="literal">None</span>,cv = <span class="literal">None</span>)</span><br></pre></td></tr></table></figure></div>
<p>对估计器的指定参数值进行详尽搜索<br>estimator：估计器对象<br>param_grid：估计器参数(dict){“n_neighbors”:[1,3,5]}<br>cv：指定几折交叉验证 类似epoch<br>fit：输入训练数据<br>score：准确率<br>输出结果为</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bestscore:在交叉验证中验证的最好结果</span><br><span class="line">bestestimator：最好的参数模型</span><br><span class="line">cvresults:每次交叉验证后的验证集准确率结果和训练集准确率结果</span><br></pre></td></tr></table></figure></div>
<p>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">param = &#123;<span class="string">&quot;n_neighbors&quot;</span>: [<span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>]&#125;</span><br><span class="line">gc = GridSearchCV(knn, param_grid=param, cv=<span class="number">2</span>)</span><br><span class="line">gc.fit(x_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择了某个模型测试集当中预测的准确率为：&quot;</span>, gc.score(x_test, y_test))</span><br><span class="line"><span class="comment"># 训练验证集的结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在交叉验证当中验证的最好结果：&quot;</span>, gc.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;gc选择了的模型K值是：&quot;</span>, gc.best_estimator_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每次交叉验证的结果为：&quot;</span>, gc.cv_results_)</span><br></pre></td></tr></table></figure></div>
<h2 id="朴素贝叶斯算法"><a href="#朴素贝叶斯算法" class="headerlink" title="朴素贝叶斯算法"></a>朴素贝叶斯算法</h2><p><code>sklearn.naive_bayes.MultinomialNB(alpha = 1.0)</code><br>朴素贝叶斯分类<br>各结论之间相互独立 使用贝叶斯公式<br>alpha：拉普拉斯平滑系数<br><strong>优点：</strong><br>朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。<br>对缺失数据不太敏感，算法也比较简单，常用于文本分类。<br>分类准确度高，速度快<br><strong>缺点：</strong><br>朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。<br>对缺失数据不太敏感，算法也比较简单，常用于文本分类。<br>分类准确度高，速度快</p>
<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><h3 id="决策树-1"><a href="#决策树-1" class="headerlink" title="决策树"></a>决策树</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.tree.DecisionTreeClassifier(criterion = <span class="string">&#x27;gini&#x27;</span>, max_depth=<span class="literal">None</span>, random_state=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure></div>
<p>criterion:默认是’gini’系数，也可以选择信息增益的熵’entropy’<br>max_depth:树的深度大小<br>random_state:随机数种子<br><em>其中会有些超参数如max_depth:树的深度大小等</em><br><strong>优点：</strong><br>简单的理解和解释，树木可视化。<br>可解释能力强<br><strong>缺点：</strong><br>决策树学习者可以创建不能很好地推广数据的过于复杂的树，这被称为过拟合。</p>
<h3 id="决策树可视化"><a href="#决策树可视化" class="headerlink" title="决策树可视化"></a>决策树可视化</h3><p><code>sklearn.tree.export_graphviz() </code><br>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tree.export_graphviz(estimator,out_file=<span class="string">&#x27;tree.dot&#x27;</span>,feature_names=[<span class="string">&quot;,&quot;</span>])</span><br></pre></td></tr></table></figure></div>
<p>此处可使用<code>graphviz</code>工具进行树可视化<br>ubuntu下使用<code>sudo apt-get install graphviz Mac:brew install graphviz</code><br>使用<code>dot -Tpng tree.dot -o tree.png</code>将dot转换为png或jpg</p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>包含多个决策树的分类器<br><em>训练集随机 特征随机</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.ensemble.RandomForestClassifier(n_estimators=<span class="number">10</span>, criterion = <span class="string">&#x27;gini&#x27;</span>, max_depth = <span class="literal">None</span>, bootstrap = <span class="literal">True</span>, random_state = <span class="literal">None</span>, min_samples_split = <span class="number">2</span>)</span><br></pre></td></tr></table></figure></div>
<p>n_estimators：integer，optional（default &#x3D; 10）森林里的树木数量<br>120,200,300,500,800,1200<br>criteria：string，可选（default &#x3D;“gini”）分割特征的测量方法<br>max_depth：integer或None，可选（默认&#x3D;无）树的最大深度 5,8,15,25,30<br>max_features&#x3D;”auto”,每个决策树的最大特征数量<br>If “auto”, then max_features&#x3D;sqrt(n_features) .<br>If “sqrt”, then max_features&#x3D;sqrt(n_features) (same as “auto”).<br>If “log2”, then max_features&#x3D;log2(n_features) .<br>If None, then max_features&#x3D;n_features .<br>bootstrap：boolean，optional（default &#x3D; True）是否在构建树时使用放回抽样<br>min_samples_split:节点划分最少样本数<br>min_samples_leaf:叶子节点的最小样本数<br><em>其中存在超参数：n_estimator, max_depth, min_samples_split, min_samples_leaf</em><br><strong>优点：</strong><br>在当前所有算法中，具有极好的准确率<br>能够有效地运行在大数据集上，处理具有高维特征的输入样本，而且不需要降维<br>能够评估各个特征在分类问题上的重要性</p>
<h1 id="回归和聚类算法"><a href="#回归和聚类算法" class="headerlink" title="回归和聚类算法"></a>回归和聚类算法</h1><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="线性回归概念"><a href="#线性回归概念" class="headerlink" title="线性回归概念"></a>线性回归概念</h3><p>线性模型：自变量为一次或参数为一次<br><em>但仅参数为一次非线性关系</em><br><strong>线性关系一定为线性模型</strong><br><strong>线性模型不一定为线性关系</strong></p>
<h3 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h3><h3 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h3><p>公式求解<br><strong>缺点：当特征过多过复杂时，求解速度太慢并且得不到结果</strong></p>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p><strong>面对训练数据规模十分庞大的任务 ，能够找到较好的结果</strong></p>
<h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正规方程</span></span><br><span class="line">sklearn.linear_model.LinearRegression(fit_intercept = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure></div>
<p>fit_intercept：是否计算偏置<br>LinearRegression.coef_：回归系数<br>LinearRegression.intercept_：偏置</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 梯度下降</span></span><br><span class="line">sklearn.linear_model.SGDRegressor(loss = <span class="string">&quot;squared_loss&quot;</span>, fit_intercept = <span class="literal">True</span>, learning_rate = <span class="string">&#x27;invscaling&#x27;</span>, eta0=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure></div>
<p>loss:损失类型<br><em>loss&#x3D;”squared_loss”: 普通最小二乘法</em><br>fit_intercept：是否计算偏置<br>learning_rate : string, optional <em>学习率算法</em></p>
<blockquote>
<p>学习率填充：<br>‘constant’: eta &#x3D; eta0<br>‘optimal’: eta &#x3D; 1.0 &#x2F; (alpha * (t + t0)) [default]<br>‘invscaling’: eta &#x3D; eta0 &#x2F; pow(t, power_t) <em>power_t&#x3D;0.25:存在父类当中</em><br>对于一个常数值的学习率来说，可以使用learning_rate&#x3D;’constant’ ，并使用eta0来指定学习率。</p>
</blockquote>
<p>SGDRegressor.coef_：回归系数<br>SGDRegressor.intercept_：偏置</p>
<h3 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.mean_squared_error(y_true, y_pred)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>均方误差回归损失<br>y_true:真实值<br>y_pred:预测值<br>return:浮点数结果</p>
</blockquote>
<p>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mylinearregression</span>():</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">线性回归预测房子价格</span></span><br><span class="line"><span class="string">:return:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">lb = load_boston()</span><br><span class="line"><span class="comment"># print(lb.data)</span></span><br><span class="line"><span class="comment"># print(lb.target)</span></span><br><span class="line"><span class="comment"># 对数据集进行划分</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(lb.data, lb.target,</span><br><span class="line">test_size=<span class="number">0.3</span>, random_state=<span class="number">24</span>)</span><br><span class="line"><span class="comment"># 需要做标准化处理对于特征值处理</span></span><br><span class="line">std_x = StandardScaler()</span><br><span class="line">x_train = std_x.fit_transform(x_train)</span><br><span class="line">x_test = std_x.fit_transform(x_test)</span><br><span class="line"><span class="comment"># print(x_train)</span></span><br><span class="line"><span class="comment"># 对于目标值进行标准化</span></span><br><span class="line">std_y = StandardScaler()</span><br><span class="line">y_train = std_y.fit_transform(y_train)</span><br><span class="line">y_test = std_y.transform(y_test)</span><br><span class="line">y_test = std_y.inverse_transform(y_test)</span><br><span class="line"><span class="comment"># 使用线性模型进行预测</span></span><br><span class="line"><span class="comment"># 使用正规方程求解</span></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment"># # 此时在干什么？</span></span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line">y_lr_predict = std_y.inverse_transform(lr.predict(x_test))</span><br><span class="line"><span class="built_in">print</span>(lr.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;正规方程预测的结果为：&quot;</span>, y_lr_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;正规方程的均方误差为：&quot;</span>, mean_squared_error(y_test, y_lr_predict))</span><br><span class="line"><span class="comment"># 梯度下降进行预测</span></span><br><span class="line">sgd = SGDRegressor()</span><br><span class="line"></span><br><span class="line">sgd.fit(x_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SGD的权重参数为：&quot;</span>, sgd.coef_)</span><br><span class="line"></span><br><span class="line">y_sgd_predict = std_y.inverse_transform(sgd.predict(x_test))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SGD的预测的结果为：&quot;</span>, y_sgd_predict)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SGD的均方误差为：&quot;</span>, mean_squared_error(y_test, y_sgd_predict))</span><br></pre></td></tr></table></figure></div>

<h2 id="欠拟合和过拟合"><a href="#欠拟合和过拟合" class="headerlink" title="欠拟合和过拟合"></a>欠拟合和过拟合</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><h3 id="欠拟合"><a href="#欠拟合" class="headerlink" title="欠拟合"></a>欠拟合</h3><p>一个假设在训练数据上能够获得比其他假设更好的拟合， 但是在测试数据集上却不能很好地拟合数据，此时认为这个假设出现了过拟合的现象。(模型过于复杂)</p>
<h3 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h3><p>一个假设在训练数据上不能获得更好的拟合，并且在测试数据集上也不能很好地拟合数据，此时认为这个假设出现了欠拟合的现象。(模型过于简单)</p>
<h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>L2正则化 - 更常用</p>
<blockquote>
<p>作用：可以使得其中一些W的都很小，都接近于0，削弱某个特征的影响<br>优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象<br>Ridge回归 岭回归</p>
</blockquote>
<p>L1正则化</p>
<blockquote>
<p>作用：可以使得其中一些W的值直接为0，删除这个特征的影响<br>LASSO回归</p>
</blockquote>
<h2 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h2><p>带L2正则化的线性回归</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.Ridge(alpha=<span class="number">1.0</span>, fit_intercept=<span class="literal">True</span>,solver=<span class="string">&quot;auto&quot;</span>, normalize=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>alpha:正则化力度 也叫λ <em>λ取值：0<del>1 1</del>10</em><br>solver:会根据数据自动选择优化方法 <em>sag:如果数据集、特征都比较大，选择该随机梯度下降优化</em><br>normalize:数据是否进行标准化<br>normalize&#x3D;False:可以在fit之前调用preprocessing.StandardScaler标准化数据<br>Ridge.coef_:回归权重<br>Ridge.intercept_:回归偏置</p>
</blockquote>
<h2 id="逻辑回归-分类算法"><a href="#逻辑回归-分类算法" class="headerlink" title="逻辑回归(分类算法)"></a>逻辑回归(分类算法)</h2><h3 id="逻辑回归概念"><a href="#逻辑回归概念" class="headerlink" title="逻辑回归概念"></a>逻辑回归概念</h3><p>逻辑回归是一种分类算法，虽然名字中带有回归，但是它与回归之间有一定的联系。由于算法的简单和高效，在实际中应用非常广泛。<br><strong>利于解决二分类问题</strong><br><em>线性回归的输出作为逻辑回归的输入</em></p>
<h3 id="sigmoid激活函数"><a href="#sigmoid激活函数" class="headerlink" title="sigmoid激活函数"></a>sigmoid激活函数</h3><p>回归的结果输入到sigmoid函数当中<br>输出结果：[0, 1]区间中的一个概率值，默认为0.5为阈值</p>
<blockquote>
<p>逻辑回归最终的分类是通过属于某个类别的概率值来判断是否属于某个类别，并且这个类别默认标记为1(正例),另外的一个类别会标记为0(反例)。（方便损失计算）</p>
</blockquote>
<blockquote>
<p>输出结果解释(重要)：假设有两个类别A，B，并且假设我们的概率值为属于A(1)这个类别的概率值。现在有一个样本的输入到逻辑回归输出结果0.6，那么这个概率值超过0.5，意味着我们训练或者预测的结果就是A(1)类别。</p>
</blockquote>
<h3 id="对数似然损失"><a href="#对数似然损失" class="headerlink" title="对数似然损失"></a>对数似然损失</h3><h3 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.LogisticRegression(solver = <span class="string">&#x27;liblinear&#x27;</span>, penalty=‘l2’, C = <span class="number">1.0</span>)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>solver:优化求解方式（默认开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数） <em>sag：根据数据集自动选择，随机平均梯度下降</em><br>penalty：正则化的种类<br>C：正则化力度</p>
</blockquote>
<h3 id="代码举例"><a href="#代码举例" class="headerlink" title="代码举例"></a>代码举例</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">logisticregression</span>():</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">逻辑回归进行癌症预测</span></span><br><span class="line"><span class="string">:return: None</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 1、读取数据，处理缺失值以及标准化</span></span><br><span class="line">column_name = [<span class="string">&#x27;Sample code number&#x27;</span>, <span class="string">&#x27;Clump Thickness&#x27;</span>, <span class="string">&#x27;Uniformity of Cell</span></span><br><span class="line"><span class="string">Size&#x27;</span>, <span class="string">&#x27;Uniformity of Cell Shape&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Marginal Adhesion&#x27;</span>, <span class="string">&#x27;Single Epithelial Cell Size&#x27;</span>, <span class="string">&#x27;Bare</span></span><br><span class="line"><span class="string">Nuclei&#x27;</span>, <span class="string">&#x27;Bland Chromatin&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Normal Nucleoli&#x27;</span>, <span class="string">&#x27;Mitoses&#x27;</span>, <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line">data = pd.read_csv(<span class="string">&quot;https://archive.ics.uci.edu/ml/machine-learningdatabases/breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;</span>, names=column_name)</span><br><span class="line"><span class="comment"># 删除缺失值</span></span><br><span class="line">data = data.replace(to_replace=<span class="string">&#x27;?&#x27;</span>, value=np.nan)</span><br><span class="line">data = data.dropna()</span><br><span class="line"><span class="comment"># 取出特征值</span></span><br><span class="line">x = data[column_name[<span class="number">1</span>:<span class="number">10</span>]]</span><br><span class="line">y = data[column_name[<span class="number">10</span>]]</span><br><span class="line"><span class="comment"># 分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行标准化</span></span><br><span class="line">std = StandardScaler()</span><br><span class="line">x_train = std.fit_transform(x_train)</span><br><span class="line">x_test = std.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用逻辑回归</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;得出来的权重：&quot;</span>, lr.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测类别</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测的类别：&quot;</span>, lr.predict(x_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 得出准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测的准确率:&quot;</span>, lr.score(x_test, y_test))</span><br><span class="line"><span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure></div>
<h3 id="分类的评估方法"><a href="#分类的评估方法" class="headerlink" title="分类的评估方法"></a>分类的评估方法</h3><h3 id="精确率与召回率"><a href="#精确率与召回率" class="headerlink" title="精确率与召回率"></a>精确率与召回率</h3><h4 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h4><h4 id="精确率-Precision-与召回率-Recall"><a href="#精确率-Precision-与召回率-Recall" class="headerlink" title="精确率(Precision)与召回率(Recall)"></a>精确率(Precision)与召回率(Recall)</h4><p>精确率：预测结果为正例样本中真实为正例的比例（了解）<br>召回率(查全率)：真实为正例的样本中预测结果为正例的比例（查的全，对正样本的区分能力）</p>
<h4 id="F1-score-反应模型稳健型"><a href="#F1-score-反应模型稳健型" class="headerlink" title="F1-score 反应模型稳健型"></a>F1-score 反应模型稳健型</h4><h3 id="分类评估报告API"><a href="#分类评估报告API" class="headerlink" title="分类评估报告API"></a>分类评估报告API</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.classification_report(y_true, y_pred, labels = [], target_names = <span class="literal">None</span>)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>y_true：真实目标值<br>y_pred：估计器预测目标值<br>labels:指定类别对应的数字<br>target_names：目标类别名称<br>return：每个类别精确率与召回率</p>
</blockquote>
<p>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;精确率和召回率为：&quot;</span>, classification_report(y_test, lr.predict(x_test), labels=[<span class="number">2</span>, <span class="number">4</span>], target_names = [<span class="string">&#x27;良性&#x27;</span>, <span class="string">&#x27;恶性&#x27;</span>]))</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<h3 id="ROC曲线与AUC指标"><a href="#ROC曲线与AUC指标" class="headerlink" title="ROC曲线与AUC指标"></a>ROC曲线与AUC指标</h3><h4 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h4><p>ROC曲线的横轴就是FPRate，纵轴就是TPRate，当二者相等时，表示的意义则是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的，此时AUC为0.5</p>
<h4 id="AUC指标"><a href="#AUC指标" class="headerlink" title="AUC指标"></a>AUC指标</h4><p>AUC只能用来评价二分类<br>AUC非常适合评价样本不平衡中的分类器性能</p>
<p>AUC的概率意义是随机取一对正负样本，正样本得分大于负样本的概率<br>AUC的最小值为0.5，最大值为1，取值越高越好<br>AUC&#x3D;1，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。<br>0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</p>
<blockquote>
<p>最终AUC的范围在[0.5, 1]之间，并且越接近1越好</p>
</blockquote>
<h4 id="AUC计算API"><a href="#AUC计算API" class="headerlink" title="AUC计算API"></a>AUC计算API</h4><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">sklearn.metrics.roc_auc_score(y_true, y_score)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>计算ROC曲线面积，即AUC值<br>y_true:每个样本的真实类别，必须为0(反例),1(正例)标记<br>y_score:每个样本预测的概率值</p>
</blockquote>
<p>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0.5~1之间，越接近于1约好</span></span><br><span class="line">y_test = np.where(y_test &gt; <span class="number">2.5</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;AUC指标：&quot;</span>, roc_auc_score(y_test, lr.predict(x_test)))</span><br></pre></td></tr></table></figure></div>

<h2 id="模型保存与加载"><a href="#模型保存与加载" class="headerlink" title="模型保存与加载"></a>模型保存与加载</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"><span class="comment"># 保存</span></span><br><span class="line">joblib.dump(rf, <span class="string">&#x27;test.pkl&#x27;</span>)</span><br><span class="line"><span class="comment"># 加载</span></span><br><span class="line">estimator = joblib.load(<span class="string">&#x27;test.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure></div>
<p>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用线性模型进行预测</span></span><br><span class="line"><span class="comment"># 使用正规方程求解</span></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment"># 此时在干什么？</span></span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># 保存训练完结束的模型</span></span><br><span class="line">joblib.dump(lr, <span class="string">&quot;test.pkl&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<p>及</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过已有的模型去预测房价</span></span><br><span class="line">model = joblib.load(<span class="string">&quot;test.pkl&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;从文件加载进来的模型预测房价的结果：&quot;</span>,</span><br><span class="line">std_y.inverse_transform(model.predict(x_test)))</span><br></pre></td></tr></table></figure></div>

<h2 id="无监督学习-k-means算法"><a href="#无监督学习-k-means算法" class="headerlink" title="无监督学习 k-means算法"></a>无监督学习 k-means算法</h2><p>特点分析：采用迭代式算法，直观易懂并且非常实用<br>缺点：容易收敛到局部最优解(多次聚类)</p>
<h3 id="k-means算法聚类步骤"><a href="#k-means算法聚类步骤" class="headerlink" title="k-means算法聚类步骤"></a>k-means算法聚类步骤</h3><p>1、随机设置K个特征空间内的点作为初始的聚类中心<br>2、对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别<br>3、接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）<br>4、如果计算得出的新中心点与原中心点一样，那么结束，否则重新进行第二步过程</p>
<h3 id="API-2"><a href="#API-2" class="headerlink" title="API"></a>API</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.KMeans(n_clusters=<span class="number">8</span>,init=‘k-means++’)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>k-means聚类<br>n_clusters:开始的聚类中心数量<br>init:初始化方法，默认为’k-means ++’<br>labels_:默认标记的类型，可以和真实值比较（不是值比较）</p>
</blockquote>
<h3 id="Kmeans性能评估指标"><a href="#Kmeans性能评估指标" class="headerlink" title="Kmeans性能评估指标"></a>Kmeans性能评估指标</h3><h3 id="轮廓系数及轮廓系数值分析"><a href="#轮廓系数及轮廓系数值分析" class="headerlink" title="轮廓系数及轮廓系数值分析"></a>轮廓系数及轮廓系数值分析</h3><p>如果b_i&gt;&gt;a_i:趋近于1效果越好， b_i &lt;&lt; a_i:趋近于-1，效果不好。轮廓系数的值是介于 [-1,1] ，越趋近于1代表内聚度和分离度都相对较优。</p>
<h3 id="轮廓系数API"><a href="#轮廓系数API" class="headerlink" title="轮廓系数API"></a>轮廓系数API</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.silhouette_score(X, labels)</span><br></pre></td></tr></table></figure></div>
<p>计算所有样本的平均轮廓系数<br>X：特征值<br>labels：被聚类标记的目标值</p>
<h3 id="用户聚类结果评估"><a href="#用户聚类结果评估" class="headerlink" title="用户聚类结果评估"></a>用户聚类结果评估</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">silhouette_score(cust, pre)</span><br></pre></td></tr></table></figure></div>

<h1 id="使用数据处理方法"><a href="#使用数据处理方法" class="headerlink" title="使用数据处理方法"></a>使用数据处理方法</h1><h2 id="缩小数据范围"><a href="#缩小数据范围" class="headerlink" title="缩小数据范围"></a>缩小数据范围</h2><p>使用<code>query()</code>方法进行数据挑选<br>如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = data.query(<span class="string">&quot;x &lt; 2.5 &amp; x &gt; 2 &amp; y &lt; 1 &amp; 1&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<h2 id="处理时间特征"><a href="#处理时间特征" class="headerlink" title="处理时间特征"></a>处理时间特征</h2><p>使用<code>pd.to_datatime()</code><br>如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time_value = pd.to_datatime(data[<span class="string">&quot;time&quot;</span>], unit = <span class="string">&quot;s&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<p>unit为单位 此处为秒</p>
<p>为了方便得到时间 可使用<br><code>pd.DatetimeIndex()</code><br>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date = pd.DatetimeIndex(time_value)</span><br></pre></td></tr></table></figure></div>

<p>分组并统计使用<code>groupby().count()</code><br>例如</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">count = data.groupby(<span class="string">&quot;place_id&quot;</span>).count()</span><br></pre></td></tr></table></figure></div>
<p>对place_id进行统计</p>
<p>布尔索引<code>place_count[place_count &gt; 3]</code></p>

            </div>

            
                <div class="post-copyright-info">
                    <div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> 机器学习-Sklearn</li>
        <li><strong>Author:</strong> CGC</li>
        <li><strong>Created at:</strong> 2023-03-14 21:20:50</li>
        
            <li>
                <strong>Updated at:</strong> 2023-04-09 10:59:52
            </li>
        
        <li>
            <strong>Link:</strong> https://redefine.ohevan.com/2023/03/14/机器学习-Sklearn/
        </li>
        <li>
            <strong>License:</strong> This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a>.
        </li>
    </ul>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">#人工智能</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/Sklearn/">#Sklearn</a>&nbsp;
                        </li>
                    
                </ul>
            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                            rel="prev"
                            href="/2023/03/14/Matlab/"
                            >
                                <span class="left arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-left"></i>
                                </span>
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">Matlab</span>
                                    <span class="post-nav-item">Prev posts</span>
                                </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2023/03/14/Opencv-python/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">Opencv-python</span>
                                    <span class="post-nav-item">Next posts</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            


            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">机器学习-Sklearn</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Python%E4%B8%AD%E5%BA%93%E7%9A%84%E8%B0%83%E7%94%A8"><span class="nav-text">Python中库的调用</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86"><span class="nav-text">数据集的划分</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="nav-text">特征工程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%97%E5%85%B8%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-text">字典特征提取</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-text">文本特征提取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8B%B1%E6%96%87"><span class="nav-text">英文</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%AD%E6%96%87-jieba%E5%88%86%E8%AF%8D%E5%A4%84%E7%90%86"><span class="nav-text">中文 jieba分词处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tf-idf%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-text">Tf-idf文本特征提取</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-text">特征预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BD%92%E4%B8%80%E5%8C%96"><span class="nav-text">归一化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E5%8C%96"><span class="nav-text">标准化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4"><span class="nav-text">特征降维</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="nav-text">特征选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Filter%E8%BF%87%E6%BB%A4%E5%BC%8F"><span class="nav-text">Filter过滤式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="nav-text">相关系数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA-PCA%E9%99%8D%E7%BB%B4"><span class="nav-text">主成分分析(PCA) PCA降维</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%88%E5%B9%B6%E8%A1%A8"><span class="nav-text">合并表</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sklearn%E8%BD%AC%E6%8D%A2%E5%99%A8%E5%92%8C%E9%A2%84%E4%BC%B0%E5%99%A8"><span class="nav-text">sklearn转换器和预估器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BD%AC%E6%8D%A2%E5%99%A8"><span class="nav-text">转换器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%B0%E8%AE%A1%E5%99%A8"><span class="nav-text">估计器</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="nav-text">分类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#KNN%E7%AE%97%E6%B3%95"><span class="nav-text">KNN算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B%E2%80%94%E2%80%94%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB"><span class="nav-text">使用案例——鸢尾花分类</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%B0%83%E4%BC%98"><span class="nav-text">模型选择和调优</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E2%80%94%E2%80%94%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2"><span class="nav-text">超参数搜索——网格搜索</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95"><span class="nav-text">朴素贝叶斯算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-text">决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91-1"><span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-text">决策树可视化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="nav-text">随机森林</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92%E5%92%8C%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="nav-text">回归和聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-text">线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A6%82%E5%BF%B5"><span class="nav-text">线性回归概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-text">优化算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B"><span class="nav-text">正规方程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-text">梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#API"><span class="nav-text">API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="nav-text">性能评估</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AC%A0%E6%8B%9F%E5%90%88%E5%92%8C%E8%BF%87%E6%8B%9F%E5%90%88"><span class="nav-text">欠拟合和过拟合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A6%82%E5%BF%B5"><span class="nav-text">概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="nav-text">欠拟合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88"><span class="nav-text">过拟合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3"><span class="nav-text">解决</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-text">正则化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B2%AD%E5%9B%9E%E5%BD%92"><span class="nav-text">岭回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="nav-text">逻辑回归(分类算法)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A6%82%E5%BF%B5"><span class="nav-text">逻辑回归概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sigmoid%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-text">sigmoid激活函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E6%8D%9F%E5%A4%B1"><span class="nav-text">对数似然损失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#API-1"><span class="nav-text">API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E4%B8%BE%E4%BE%8B"><span class="nav-text">代码举例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="nav-text">分类的评估方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B2%BE%E7%A1%AE%E7%8E%87%E4%B8%8E%E5%8F%AC%E5%9B%9E%E7%8E%87"><span class="nav-text">精确率与召回率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E8%AF%84%E4%BC%B0%E6%8A%A5%E5%91%8AAPI"><span class="nav-text">分类评估报告API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ROC%E6%9B%B2%E7%BA%BF%E4%B8%8EAUC%E6%8C%87%E6%A0%87"><span class="nav-text">ROC曲线与AUC指标</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD"><span class="nav-text">模型保存与加载</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-k-means%E7%AE%97%E6%B3%95"><span class="nav-text">无监督学习 k-means算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#k-means%E7%AE%97%E6%B3%95%E8%81%9A%E7%B1%BB%E6%AD%A5%E9%AA%A4"><span class="nav-text">k-means算法聚类步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#API-2"><span class="nav-text">API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kmeans%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="nav-text">Kmeans性能评估指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BD%AE%E5%BB%93%E7%B3%BB%E6%95%B0%E5%8F%8A%E8%BD%AE%E5%BB%93%E7%B3%BB%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90"><span class="nav-text">轮廓系数及轮廓系数值分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BD%AE%E5%BB%93%E7%B3%BB%E6%95%B0API"><span class="nav-text">轮廓系数API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%A8%E6%88%B7%E8%81%9A%E7%B1%BB%E7%BB%93%E6%9E%9C%E8%AF%84%E4%BC%B0"><span class="nav-text">用户聚类结果评估</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95"><span class="nav-text">使用数据处理方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%A9%E5%B0%8F%E6%95%B0%E6%8D%AE%E8%8C%83%E5%9B%B4"><span class="nav-text">缩小数据范围</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%84%E7%90%86%E6%97%B6%E9%97%B4%E7%89%B9%E5%BE%81"><span class="nav-text">处理时间特征</span></a></li></ol></li></ol>

    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>
            
            

        </div>

        <div class="main-content-footer">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info">
            &copy;
            
              <span>2022</span>
              -
            
            2023&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">CGC</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">
                        VISITOR COUNT&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">
                        TOTAL PAGE VIEWS&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            <span class="powered-by-container">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a></span>
                <br>
            <span class="theme-version-container">THEME&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.2.1</a>
        </div>
        
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
        
            <script async data-pjax>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fa-solid fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fa-solid fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    


</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/layouts/navbarShrink.js"></script>

<script src="/js/tools/scrollTopBottom.js"></script>

<script src="/js/tools/lightDarkSwitch.js"></script>



    
<script src="/js/tools/localSearch.js"></script>




    
<script src="/js/tools/codeBlock.js"></script>




    
<script src="/js/layouts/lazyload.js"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>






    
<script src="/js/libs/minimasonry.min.js"></script>

    
<script src="/js/plugins/masonry.js"></script>



<div class="post-scripts pjax">
    
        
<script src="/js/tools/tocToggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/layouts/toc.js"></script>

<script src="/js/plugins/tabs.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax',
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            Global.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            Global.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            Global.refresh();
        });
    });
</script>




</body>
</html>
